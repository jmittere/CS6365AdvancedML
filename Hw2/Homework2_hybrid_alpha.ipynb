{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ad058d",
   "metadata": {},
   "source": [
    "# Homework 2. Hybrid News RecSys : CS6365 Fall 2025\n",
    "\n",
    "Justin Mittereder - G49843234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cff8a3a",
   "metadata": {},
   "source": [
    "This approach will use the news article embeddings from the content based approach in Homework2_content.ipynb and the article_article_similarity matrix from Homework2_cf.ipynb to hopefully get better evaluation results on warm and cold users by combining both approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d139777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "col_names  = ['Impression ID', 'User ID', 'Time', 'History', 'Impressions']\n",
    "train_behaviors_df = pd.read_csv('data/MINDsmall_train/behaviors.tsv', sep='\\t', header=None, names=col_names)\n",
    "train_behaviors_df.sort_values(by=['User ID', 'Time'], inplace=True)\n",
    "train_behaviors_df.reset_index(drop=True, inplace=True)\n",
    "val_behaviors_df = pd.read_csv('data/MINDsmall_dev/behaviors.tsv', sep='\\t', header=None, names=col_names)\n",
    "val_behaviors_df.sort_values(by=['User ID', 'Time'], inplace=True)\n",
    "val_behaviors_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "col_names  = ['News ID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'Title Entities', 'Abstract Entities']\n",
    "train_news_df = pd.read_csv('data/MINDsmall_train/news.tsv', sep='\\t', header=None, names=col_names)\n",
    "val_news_df = pd.read_csv('data/MINDsmall_dev/news.tsv', sep='\\t', header=None, names=col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302f78e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training impressions are from between 2019-11-08 19:00:19 and 2019-11-14 18:59:13 . \n",
      "Validation impressions are from between 2019-11-14 19:00:01 and 2019-11-15 18:58:03 . \n"
     ]
    }
   ],
   "source": [
    "train_behaviors_df[\"unix_timestamp\"] = pd.to_datetime(\n",
    "    train_behaviors_df[\"Time\"], \n",
    "    format=\"%m/%d/%Y %I:%M:%S %p\"\n",
    ").astype(\"int64\") // 1_000_000_000\n",
    "\n",
    "val_behaviors_df[\"unix_timestamp\"] = pd.to_datetime(\n",
    "    val_behaviors_df[\"Time\"], \n",
    "    format=\"%m/%d/%Y %I:%M:%S %p\"\n",
    ").astype(\"int64\") // 1_000_000_000\n",
    "\n",
    "earliest_train_time = datetime.datetime.fromtimestamp(train_behaviors_df['unix_timestamp'].min())\n",
    "latest_train_time = datetime.datetime.fromtimestamp(train_behaviors_df['unix_timestamp'].max())\n",
    "earliest_val_time = datetime.datetime.fromtimestamp(val_behaviors_df['unix_timestamp'].min())\n",
    "latest_val_time = datetime.datetime.fromtimestamp(val_behaviors_df['unix_timestamp'].max())\n",
    "\n",
    "print(f\"Training impressions are from between {earliest_train_time} and {latest_train_time} . \")\n",
    "print(f\"Validation impressions are from between {earliest_val_time} and {latest_val_time} . \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08651501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only Considering Clicked on Articles\n",
      "Train: Number of Impressions:  236344\n",
      "Train: Number of articles:  7713\n",
      "Train: Number of Users:  50000\n",
      "    user_id   timestamp article  impression\n",
      "3      U100  1573544052   N7800           1\n",
      "134   U1000  1573686978  N53875           1\n",
      "166   U1000  1573693256  N29739           1\n",
      "180   U1000  1573693256   N7670           1\n",
      "307   U1000  1573771041  N58656           1\n",
      "Only Considering Clicked on Articles\n",
      "Val: Number of Impressions:  111383\n",
      "Val: Number of articles:  2212\n",
      "Val: Number of Users:  50000\n",
      "   user_id   timestamp article  impression\n",
      "1       U1  1573802905  N20036           1\n",
      "13     U10  1573798095  N32536           1\n",
      "59  U10000  1573807178  N31958           1\n",
      "63  U10000  1573811650  N50775           1\n",
      "93  U10000  1573823809  N60215           1\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "#get full df of all user impressions\n",
    "def get_impressions(df, include_history=False):\n",
    "    rows = []\n",
    "    for idx, row in df.iterrows():\n",
    "        user_id = row[\"User ID\"]\n",
    "        time = row[\"unix_timestamp\"]\n",
    "        impressions = row[\"Impressions\"]\n",
    "\n",
    "        # split impressions\n",
    "        for impression in impressions.split():\n",
    "            article, click = impression.split(\"-\")\n",
    "            click = int(click)\n",
    "\n",
    "            rows.append({\n",
    "                \"user_id\": user_id,\n",
    "                \"timestamp\": time,\n",
    "                \"article\": article,\n",
    "                \"impression\": click\n",
    "            })\n",
    "\n",
    "        if(include_history):\n",
    "            # split impressions\n",
    "            history = str(row['History'])\n",
    "            for article in history.split(\" \"):\n",
    "                rows.append({\n",
    "                    \"user_id\": user_id,\n",
    "                    \"timestamp\": \"N/A\",\n",
    "                    \"article\": article,\n",
    "                    \"impression\": 1 \n",
    "                })\n",
    "        \n",
    "    impressions_df = pd.DataFrame(rows)\n",
    "    impressions_df.sort_values(by=['user_id', 'timestamp'], inplace=True)\n",
    "    impressions_df.reset_index(drop=True, inplace=True)\n",
    "    return impressions_df    \n",
    "\n",
    "\n",
    "impressions_df = get_impressions(train_behaviors_df)\n",
    "impressions_df = impressions_df[impressions_df['impression'] == 1]\n",
    "print(\"Only Considering Clicked on Articles\")\n",
    "print(\"Train: Number of Impressions: \", len(impressions_df))\n",
    "print(\"Train: Number of articles: \", impressions_df['article'].nunique())\n",
    "print(\"Train: Number of Users: \", impressions_df['user_id'].nunique())\n",
    "print(impressions_df.head())\n",
    "\n",
    "val_impressions_df = get_impressions(val_behaviors_df)\n",
    "val_impressions_df = val_impressions_df[val_impressions_df['impression'] == 1]\n",
    "print(\"Only Considering Clicked on Articles\")\n",
    "print(\"Val: Number of Impressions: \", len(val_impressions_df))\n",
    "print(\"Val: Number of articles: \", val_impressions_df['article'].nunique())\n",
    "print(\"Val: Number of Users: \", val_impressions_df['user_id'].nunique())\n",
    "print(val_impressions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c390f2a",
   "metadata": {},
   "source": [
    "Load Embeddings for each article in the validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3946d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load generated embeddings\n",
    "val_news_df = pd.read_pickle(\"data/MINDsmall_dev/news_w_embeddings.pkl\")\n",
    "type(val_news_df.loc[0, \"embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a1c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for validation users that have no history, set their History to empty list\n",
    "val_behaviors_df[\"History\"] = val_behaviors_df[\"History\"].fillna(\"\")\n",
    "val_behaviors_df['History'] = val_behaviors_df['History'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4964bed2",
   "metadata": {},
   "source": [
    "Get embeddings for each user that are the average of the embeddings for each article in the user's history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f44eee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_article_emb_dict = dict(zip(val_news_df[\"News ID\"], val_news_df[\"embedding\"]))\n",
    "val_user_embeddings = {}\n",
    "\n",
    "for user, rows in val_behaviors_df.groupby(\"User ID\"):\n",
    "    clicked = rows[\"History\"].sum()  # concatenates all lists of clicked items\n",
    "    clicked_embs = []\n",
    "    for article_id in clicked: \n",
    "        if article_id in val_article_emb_dict: # if we have embedding for this article\n",
    "            clicked_embs.append(val_article_emb_dict[article_id])\n",
    "\n",
    "    if len(clicked_embs) == 0: #no clicked articles in user history\n",
    "        continue\n",
    "    #print(clicked_embs)\n",
    "    val_user_embeddings[user] = np.mean(clicked_embs, axis=0) #gets average of the embeddings of all articles in validation user's history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f10fec",
   "metadata": {},
   "source": [
    "Get User and article similarity by getting the dot product of both embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53806920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all item ids\n",
    "item_ids = list(val_article_emb_dict.keys())\n",
    "#dictionary that maps item ids as keys and index as values\n",
    "item_id_to_index = {item_id: idx for idx, item_id in enumerate(item_ids)}\n",
    "#get all embeddings for each article into a matrix\n",
    "item_matrix = np.vstack([val_article_emb_dict[i] for i in item_ids])  # shape (N_items, embedding_dim)\n",
    "# transpose to (embedding_dim, N_items)\n",
    "item_matrix = item_matrix.T  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dffc982",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_scores = {}\n",
    "\n",
    "for user, user_emb in val_user_embeddings.items():\n",
    "    scores = np.dot(user_emb, item_matrix)    # shape (N_items,)\n",
    "    user_item_scores[user] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb17cc2",
   "metadata": {},
   "source": [
    "Map all User IDs and Article IDs to integers so that we can use them as row and columns in user-article matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8200a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "article_encoder = LabelEncoder()\n",
    "\n",
    "impressions_df['user_idx'] = user_encoder.fit_transform(impressions_df['user_id']) #Map all User IDs to integers so we can use them for the rows in the user-article matrix \n",
    "impressions_df['article_idx'] = article_encoder.fit_transform(impressions_df['article']) #Map all Article IDs to integers so we can use them for the columns in the user-article matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14faf5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Article Matrix Shape:  (50000, 7713)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "num_users = impressions_df['user_idx'].nunique()\n",
    "num_articles = impressions_df['article_idx'].nunique()\n",
    "\n",
    "user_article_matrix = csr_matrix((np.ones(len(impressions_df)),(impressions_df['user_idx'], impressions_df['article_idx'])),shape=(num_users, num_articles))\n",
    "print(\"User Article Matrix Shape: \", user_article_matrix.shape)\n",
    "\n",
    "#calculate the similarity between articles based on which users have interacted with which articles using cosine similarity function on transpose(user-article) matrix -> article-user matrix\n",
    "article_article_sim = cosine_similarity(user_article_matrix.T) #items are similar if they've been clicekd on by similar users/have similar user impression vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d06532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary that maps article Ids to their indices for CF article_article sim matrix\n",
    "article_id_to_index = {\n",
    "    article_id: idx\n",
    "    for idx, article_id in enumerate(article_encoder.classes_)\n",
    "}\n",
    "\n",
    "#dictionary that maps indices to their article Ids , reverse of above\n",
    "index_to_article_id = {\n",
    "    idx: article_id\n",
    "    for idx, article_id in enumerate(article_encoder.classes_)\n",
    "}\n",
    "\n",
    "def to_clicked_ids(clicked_idx):\n",
    "    return [index_to_article_id[i] for i in clicked_idx if i in index_to_article_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf4e8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Impression ID</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>History</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8158</td>\n",
       "      <td>U1</td>\n",
       "      <td>11/15/2019 7:28:25 AM</td>\n",
       "      <td>[N23571, N58267, N25682, N10646, N32607, N5773...</td>\n",
       "      <td>N14637-0 N20036-1</td>\n",
       "      <td>1573802905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71327</td>\n",
       "      <td>U10</td>\n",
       "      <td>11/15/2019 6:08:15 AM</td>\n",
       "      <td>[N27612, N36699, N64777, N9120, N9803, N57967,...</td>\n",
       "      <td>N33397-0 N46917-0 N11930-0 N58612-0 N47612-0 N...</td>\n",
       "      <td>1573798095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5144</td>\n",
       "      <td>U10000</td>\n",
       "      <td>11/15/2019 1:16:49 PM</td>\n",
       "      <td>[N10059, N46978, N53234, N3345, N3345, N9155, ...</td>\n",
       "      <td>N48740-0 N51470-0 N1952-0 N23675-0 N56969-0 N6...</td>\n",
       "      <td>1573823809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41696</td>\n",
       "      <td>U10000</td>\n",
       "      <td>11/15/2019 8:39:38 AM</td>\n",
       "      <td>[N10059, N46978, N53234, N3345, N3345, N9155, ...</td>\n",
       "      <td>N29393-0 N20036-0 N30290-0 N31958-1 N23513-0 N...</td>\n",
       "      <td>1573807178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1307</td>\n",
       "      <td>U10000</td>\n",
       "      <td>11/15/2019 9:54:10 AM</td>\n",
       "      <td>[N10059, N46978, N53234, N3345, N3345, N9155, ...</td>\n",
       "      <td>N50775-1 N31958-0 N53572-0 N5472-0 N58251-0 N3...</td>\n",
       "      <td>1573811650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Impression ID User ID                   Time  \\\n",
       "0           8158      U1  11/15/2019 7:28:25 AM   \n",
       "1          71327     U10  11/15/2019 6:08:15 AM   \n",
       "2           5144  U10000  11/15/2019 1:16:49 PM   \n",
       "3          41696  U10000  11/15/2019 8:39:38 AM   \n",
       "4           1307  U10000  11/15/2019 9:54:10 AM   \n",
       "\n",
       "                                             History  \\\n",
       "0  [N23571, N58267, N25682, N10646, N32607, N5773...   \n",
       "1  [N27612, N36699, N64777, N9120, N9803, N57967,...   \n",
       "2  [N10059, N46978, N53234, N3345, N3345, N9155, ...   \n",
       "3  [N10059, N46978, N53234, N3345, N3345, N9155, ...   \n",
       "4  [N10059, N46978, N53234, N3345, N3345, N9155, ...   \n",
       "\n",
       "                                         Impressions  unix_timestamp  \n",
       "0                                  N14637-0 N20036-1      1573802905  \n",
       "1  N33397-0 N46917-0 N11930-0 N58612-0 N47612-0 N...      1573798095  \n",
       "2  N48740-0 N51470-0 N1952-0 N23675-0 N56969-0 N6...      1573823809  \n",
       "3  N29393-0 N20036-0 N30290-0 N31958-1 N23513-0 N...      1573807178  \n",
       "4  N50775-1 N31958-0 N53572-0 N5472-0 N58251-0 N3...      1573811650  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_behaviors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fd21419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split articles previously clicked by users in validation set\n",
    "#val_behaviors_df[\"History_list\"] = val_behaviors_df[\"History\"].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "val_behaviors_df['History_list'] = val_behaviors_df['History']\n",
    "\n",
    "#take all impressions in validation set that user actually clicked on\n",
    "def get_clicked_articles(impressions_str):\n",
    "    clicks = []\n",
    "    for imp in impressions_str.split():\n",
    "        article, clicked = imp.split(\"-\")\n",
    "        if int(clicked) == 1:\n",
    "            clicks.append(article)\n",
    "    return clicks\n",
    "\n",
    "#create new col in val set called clicked_articles with all articles user viewed\n",
    "val_behaviors_df['clicked_articles'] = val_behaviors_df['Impressions'].apply(get_clicked_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d0ad3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Impression ID</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>History</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>History_list</th>\n",
       "      <th>clicked_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8158</td>\n",
       "      <td>U1</td>\n",
       "      <td>11/15/2019 7:28:25 AM</td>\n",
       "      <td>[N23571, N58267, N25682, N10646, N32607, N5773...</td>\n",
       "      <td>N14637-0 N20036-1</td>\n",
       "      <td>1573802905</td>\n",
       "      <td>[N23571, N58267, N25682, N10646, N32607, N5773...</td>\n",
       "      <td>[N20036]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71327</td>\n",
       "      <td>U10</td>\n",
       "      <td>11/15/2019 6:08:15 AM</td>\n",
       "      <td>[N27612, N36699, N64777, N9120, N9803, N57967,...</td>\n",
       "      <td>N33397-0 N46917-0 N11930-0 N58612-0 N47612-0 N...</td>\n",
       "      <td>1573798095</td>\n",
       "      <td>[N27612, N36699, N64777, N9120, N9803, N57967,...</td>\n",
       "      <td>[N32536]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5144</td>\n",
       "      <td>U10000</td>\n",
       "      <td>11/15/2019 1:16:49 PM</td>\n",
       "      <td>[N10059, N46978, N53234, N3345, N3345, N9155, ...</td>\n",
       "      <td>N48740-0 N51470-0 N1952-0 N23675-0 N56969-0 N6...</td>\n",
       "      <td>1573823809</td>\n",
       "      <td>[N10059, N46978, N53234, N3345, N3345, N9155, ...</td>\n",
       "      <td>[N60215]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41696</td>\n",
       "      <td>U10000</td>\n",
       "      <td>11/15/2019 8:39:38 AM</td>\n",
       "      <td>[N10059, N46978, N53234, N3345, N3345, N9155, ...</td>\n",
       "      <td>N29393-0 N20036-0 N30290-0 N31958-1 N23513-0 N...</td>\n",
       "      <td>1573807178</td>\n",
       "      <td>[N10059, N46978, N53234, N3345, N3345, N9155, ...</td>\n",
       "      <td>[N31958]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1307</td>\n",
       "      <td>U10000</td>\n",
       "      <td>11/15/2019 9:54:10 AM</td>\n",
       "      <td>[N10059, N46978, N53234, N3345, N3345, N9155, ...</td>\n",
       "      <td>N50775-1 N31958-0 N53572-0 N5472-0 N58251-0 N3...</td>\n",
       "      <td>1573811650</td>\n",
       "      <td>[N10059, N46978, N53234, N3345, N3345, N9155, ...</td>\n",
       "      <td>[N50775]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Impression ID User ID                   Time  \\\n",
       "0           8158      U1  11/15/2019 7:28:25 AM   \n",
       "1          71327     U10  11/15/2019 6:08:15 AM   \n",
       "2           5144  U10000  11/15/2019 1:16:49 PM   \n",
       "3          41696  U10000  11/15/2019 8:39:38 AM   \n",
       "4           1307  U10000  11/15/2019 9:54:10 AM   \n",
       "\n",
       "                                             History  \\\n",
       "0  [N23571, N58267, N25682, N10646, N32607, N5773...   \n",
       "1  [N27612, N36699, N64777, N9120, N9803, N57967,...   \n",
       "2  [N10059, N46978, N53234, N3345, N3345, N9155, ...   \n",
       "3  [N10059, N46978, N53234, N3345, N3345, N9155, ...   \n",
       "4  [N10059, N46978, N53234, N3345, N3345, N9155, ...   \n",
       "\n",
       "                                         Impressions  unix_timestamp  \\\n",
       "0                                  N14637-0 N20036-1      1573802905   \n",
       "1  N33397-0 N46917-0 N11930-0 N58612-0 N47612-0 N...      1573798095   \n",
       "2  N48740-0 N51470-0 N1952-0 N23675-0 N56969-0 N6...      1573823809   \n",
       "3  N29393-0 N20036-0 N30290-0 N31958-1 N23513-0 N...      1573807178   \n",
       "4  N50775-1 N31958-0 N53572-0 N5472-0 N58251-0 N3...      1573811650   \n",
       "\n",
       "                                        History_list clicked_articles  \n",
       "0  [N23571, N58267, N25682, N10646, N32607, N5773...         [N20036]  \n",
       "1  [N27612, N36699, N64777, N9120, N9803, N57967,...         [N32536]  \n",
       "2  [N10059, N46978, N53234, N3345, N3345, N9155, ...         [N60215]  \n",
       "3  [N10059, N46978, N53234, N3345, N3345, N9155, ...         [N31958]  \n",
       "4  [N10059, N46978, N53234, N3345, N3345, N9155, ...         [N50775]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_behaviors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c189134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles in validation candidate set: 42416\n"
     ]
    }
   ],
   "source": [
    "print(\"Total articles in validation candidate set:\", len(item_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "234ee841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def to_idx_list(article_list, article_id_to_index):\n",
    "    return [article_id_to_index[a] for a in article_list if a in article_id_to_index]\n",
    "\n",
    "# history and clicked articles as indices\n",
    "val_behaviors_df['history_idx'] = val_behaviors_df['History_list'].apply(lambda x: to_idx_list(x, article_id_to_index))\n",
    "val_behaviors_df['clicked_idx'] = val_behaviors_df['clicked_articles'].apply(lambda x: to_idx_list(x, article_id_to_index))\n",
    "\n",
    "# Pre-filter history indices to only include articles in CF similarity matrix\n",
    "val_behaviors_df['history_idx_cf'] = val_behaviors_df['history_idx'].apply(\n",
    "    lambda idxs: [i for i in idxs if i < article_article_sim.shape[0]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fb28c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.3  # weight for CF vs CB\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in val_behaviors_df.iterrows():\n",
    "    user = row['User ID']\n",
    "    history_idx = row['history_idx_cf']\n",
    "    clicked_idx = row['clicked_idx']\n",
    "\n",
    "    #collaborative filtering scores if there is history in article_article sim matrix for user\n",
    "    cf_scores = []\n",
    "    for item_id in item_ids:  # all validation articles\n",
    "        if item_id in article_id_to_index:  # article exists in CF (training set)\n",
    "            c = article_id_to_index[item_id]  # index in CF matrix\n",
    "            if len(history_idx) > 0:\n",
    "                sims = article_article_sim[c, history_idx]\n",
    "                cf_scores.append(sims.max())\n",
    "            else:\n",
    "                cf_scores.append(0.0)  # user has no CF-known history\n",
    "        else:\n",
    "            cf_scores.append(0.0)  # validation-only article, CF not defined\n",
    "    cf_scores = np.array(cf_scores)\n",
    "\n",
    "    #content based scores using the users embedding and every other article in val set\n",
    "    if user in val_user_embeddings:\n",
    "        user_emb = val_user_embeddings[user]  # mean of history embeddings\n",
    "        cb_scores = np.dot(user_emb, item_matrix)  # dot product with all articles\n",
    "    else:\n",
    "        cb_scores = np.zeros(len(item_ids))  # user has no history at all\n",
    "\n",
    "    #combined score using cf and cb\n",
    "    hybrid_scores = alpha * cf_scores + (1 - alpha) * cb_scores\n",
    "\n",
    "    #rank all articles for recommendations, get top 50 to reduce memory load\n",
    "    top_k = 50  # store top 50 for eval metrics\n",
    "    ranked_idx = np.argpartition(hybrid_scores, -top_k)[-top_k:]\n",
    "    ranked_idx = ranked_idx[np.argsort(hybrid_scores[ranked_idx])[::-1]]\n",
    "    ranked_items = [item_ids[j] for j in ranked_idx]\n",
    "\n",
    "    clicked_ids = to_clicked_ids(clicked_idx) #convert encoded clicked articles back to regular articles for eval metrics\n",
    "\n",
    "    results.append({\n",
    "        'Impression ID': row['Impression ID'],\n",
    "        'ranked_items': ranked_items,\n",
    "        'scores': hybrid_scores[ranked_idx],\n",
    "        'clicked_idx': clicked_ids\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29e66ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_at_k_multi(ranked_items, clicked_idx, k):\n",
    "    return int(any(item in ranked_items[:k] for item in clicked_idx))\n",
    "\n",
    "def reciprocal_rank_multi(ranked_items, clicked_idx):\n",
    "    for rank, item in enumerate(ranked_items, 1):\n",
    "        if item in clicked_idx:\n",
    "            return 1.0 / rank\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at_k_multi(ranked_items, clicked_idx, k):\n",
    "    dcg = 0.0\n",
    "    for rank, item in enumerate(ranked_items[:k], 1):\n",
    "        if item in clicked_idx:\n",
    "            dcg += 1.0 / np.log2(rank + 1)\n",
    "    # ideal DCG\n",
    "    idcg = sum(1.0 / np.log2(i + 1) for i in range(1, min(k, len(clicked_idx)) + 1))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b68253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "MRR: 0.0026\n",
      "HitRate@5: 0.0032\n",
      "HitRate@10: 0.0044\n",
      "nDCG@5: 0.0020\n",
      "nDCG@10: 0.0023\n"
     ]
    }
   ],
   "source": [
    "mrr_list = []\n",
    "hit5_list = []\n",
    "hit10_list = []\n",
    "ndcg5_list = []\n",
    "ndcg10_list = []\n",
    "\n",
    "for row in results:\n",
    "    ranked_items = row['ranked_items']\n",
    "    clicked_idx = row['clicked_idx']\n",
    "\n",
    "    mrr_list.append(reciprocal_rank_multi(ranked_items, clicked_idx))\n",
    "    hit5_list.append(hit_at_k_multi(ranked_items, clicked_idx, 5))\n",
    "    hit10_list.append(hit_at_k_multi(ranked_items, clicked_idx, 10))\n",
    "    ndcg5_list.append(ndcg_at_k_multi(ranked_items, clicked_idx, 5))\n",
    "    ndcg10_list.append(ndcg_at_k_multi(ranked_items, clicked_idx, 10))\n",
    "\n",
    "metrics = {\n",
    "    'MRR': np.mean(mrr_list),\n",
    "    'HitRate@5': np.mean(hit5_list),\n",
    "    'HitRate@10': np.mean(hit10_list),\n",
    "    'nDCG@5': np.mean(ndcg5_list),\n",
    "    'nDCG@10': np.mean(ndcg10_list)\n",
    "}\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
