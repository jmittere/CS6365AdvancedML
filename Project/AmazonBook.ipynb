{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T18:40:24.001682Z",
     "start_time": "2025-11-20T18:40:23.994890Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9128bdbb8e085be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T20:58:50.703286Z",
     "start_time": "2025-11-20T20:58:12.810050Z"
    }
   },
   "outputs": [],
   "source": [
    "train = '/Users/yeji/Desktop/ML Project/Books.train.csv'\n",
    "test = '/Users/yeji/Desktop/ML Project/Books.test.csv'\n",
    "validation = '/Users/yeji/Desktop/ML Project/Books.valid.csv'\n",
    "\n",
    "train = pd.read_csv(train, low_memory=False)\n",
    "test = pd.read_csv(test, low_memory=False)\n",
    "validation = pd.read_csv(validation, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cd474b08625882b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T20:58:53.081413Z",
     "start_time": "2025-11-20T20:58:53.068878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1446304000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1441260345000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1564770672</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1441260365000</td>\n",
       "      <td>1446304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1442450703</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1523093714024</td>\n",
       "      <td>1446304000 1564770672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1780671067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1611623223325</td>\n",
       "      <td>1446304000 1564770672 1442450703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1645671127</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1612044209266</td>\n",
       "      <td>1446304000 1564770672 1442450703 1780671067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id parent_asin  rating      timestamp  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1446304000     5.0  1441260345000   \n",
       "1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1564770672     5.0  1441260365000   \n",
       "2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1442450703     5.0  1523093714024   \n",
       "3  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1780671067     1.0  1611623223325   \n",
       "4  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1645671127     3.0  1612044209266   \n",
       "\n",
       "                                       history  \n",
       "0                                          NaN  \n",
       "1                                   1446304000  \n",
       "2                        1446304000 1564770672  \n",
       "3             1446304000 1564770672 1442450703  \n",
       "4  1446304000 1564770672 1442450703 1780671067  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cae92605ee7998c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T20:59:51.608480Z",
     "start_time": "2025-11-20T20:59:51.603261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1782490671</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1640383495102</td>\n",
       "      <td>1446304000 1564770672 1442450703 1780671067 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGKASBHYZPGTEPO6LWZPVJWB2BVA</td>\n",
       "      <td>0802737803</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1454676232000</td>\n",
       "      <td>0811849783 0803729952 0735336296 1508558884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGXFEGMNVCSTSYYA5UWXDV7AFSXA</td>\n",
       "      <td>1594749310</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1541884305941</td>\n",
       "      <td>1578052009 1477493395 1594747350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFWHJ6O3PV4JC7PVOJH6CPULO2KQ</td>\n",
       "      <td>1633573001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1612225279592</td>\n",
       "      <td>B00INIQVJA 1496407903 1974633225 B07KD27RHM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHXBL3QDWZGJYH7A5CMPFNUPMF7Q</td>\n",
       "      <td>0451450523</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1635710722120</td>\n",
       "      <td>0920668372 1589255208 2764322836 2764330898 00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id parent_asin  rating      timestamp  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1782490671     5.0  1640383495102   \n",
       "1  AGKASBHYZPGTEPO6LWZPVJWB2BVA  0802737803     5.0  1454676232000   \n",
       "2  AGXFEGMNVCSTSYYA5UWXDV7AFSXA  1594749310     5.0  1541884305941   \n",
       "3  AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  1633573001     5.0  1612225279592   \n",
       "4  AHXBL3QDWZGJYH7A5CMPFNUPMF7Q  0451450523     2.0  1635710722120   \n",
       "\n",
       "                                             history  \n",
       "0  1446304000 1564770672 1442450703 1780671067 16...  \n",
       "1        0811849783 0803729952 0735336296 1508558884  \n",
       "2                   1578052009 1477493395 1594747350  \n",
       "3        B00INIQVJA 1496407903 1974633225 B07KD27RHM  \n",
       "4  0920668372 1589255208 2764322836 2764330898 00...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1abaf7682f52d3be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T20:59:10.283752Z",
     "start_time": "2025-11-20T20:59:10.276067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>0593235657</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1640629604904</td>\n",
       "      <td>1446304000 1564770672 1442450703 1780671067 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGKASBHYZPGTEPO6LWZPVJWB2BVA</td>\n",
       "      <td>0803736800</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1454676557000</td>\n",
       "      <td>0811849783 0803729952 0735336296 1508558884 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGXFEGMNVCSTSYYA5UWXDV7AFSXA</td>\n",
       "      <td>1542046599</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1605649719611</td>\n",
       "      <td>1578052009 1477493395 1594747350 1594749310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFWHJ6O3PV4JC7PVOJH6CPULO2KQ</td>\n",
       "      <td>0679450815</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1638987703546</td>\n",
       "      <td>B00INIQVJA 1496407903 1974633225 B07KD27RHM 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHXBL3QDWZGJYH7A5CMPFNUPMF7Q</td>\n",
       "      <td>1250866448</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1669414969335</td>\n",
       "      <td>0920668372 1589255208 2764322836 2764330898 00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id parent_asin  rating      timestamp  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  0593235657     5.0  1640629604904   \n",
       "1  AGKASBHYZPGTEPO6LWZPVJWB2BVA  0803736800     4.0  1454676557000   \n",
       "2  AGXFEGMNVCSTSYYA5UWXDV7AFSXA  1542046599     5.0  1605649719611   \n",
       "3  AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  0679450815     5.0  1638987703546   \n",
       "4  AHXBL3QDWZGJYH7A5CMPFNUPMF7Q  1250866448     5.0  1669414969335   \n",
       "\n",
       "                                             history  \n",
       "0  1446304000 1564770672 1442450703 1780671067 16...  \n",
       "1  0811849783 0803729952 0735336296 1508558884 08...  \n",
       "2        1578052009 1477493395 1594747350 1594749310  \n",
       "3  B00INIQVJA 1496407903 1974633225 B07KD27RHM 16...  \n",
       "4  0920668372 1589255208 2764322836 2764330898 00...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34a42f193557bafd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T20:29:10.439175Z",
     "start_time": "2025-11-20T20:29:05.033545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "                        user_id parent_asin  rating      timestamp\n",
      "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1446304000     5.0  1441260345000\n",
      "1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1564770672     5.0  1441260365000\n",
      "2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1442450703     5.0  1523093714024\n",
      "3  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1780671067     1.0  1611623223325\n",
      "4  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1645671127     3.0  1612044209266\n",
      "\n",
      "Shape: (9488297, 4)\n",
      "\n",
      "Column types:\n",
      "user_id         object\n",
      "parent_asin     object\n",
      "rating         float64\n",
      "timestamp        int64\n",
      "dtype: object\n",
      "\n",
      "Column names:\n",
      "['user_id', 'parent_asin', 'rating', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"/Users/yeji/Desktop/ML Project/Books.csv\"\n",
    "\n",
    "# Load the data (try with low_memory=False to avoid dtype guessing issues)\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "# Preview the data\n",
    "print(\"First few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nShape:\", df.shape)\n",
    "\n",
    "print(\"\\nColumn types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "281f5eb93c005511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T20:29:12.855845Z",
     "start_time": "2025-11-20T20:29:12.851119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           user        item  rating      timestamp\n",
      "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1446304000     5.0  1441260345000\n",
      "1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1564770672     5.0  1441260365000\n",
      "2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1442450703     5.0  1523093714024\n",
      "3  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1780671067     1.0  1611623223325\n",
      "4  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1645671127     3.0  1612044209266\n"
     ]
    }
   ],
   "source": [
    "# Rename for consistency\n",
    "df.columns = [\"user\", \"item\", \"rating\", \"timestamp\"]\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72d2458e8b5455ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T20:29:17.331847Z",
     "start_time": "2025-11-20T20:29:15.852585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique users: 776370\n",
      "Unique items: 495063\n",
      "Total interactions: 9488297\n"
     ]
    }
   ],
   "source": [
    "n_users = df[\"user\"].nunique()\n",
    "n_items = df[\"item\"].nunique()\n",
    "n_interactions = len(df)\n",
    "\n",
    "print(f\"\\nUnique users: {n_users}\")\n",
    "print(f\"Unique items: {n_items}\")\n",
    "print(f\"Total interactions: {n_interactions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40ce97fc9d8437cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T20:30:02.538678Z",
     "start_time": "2025-11-20T20:30:02.468754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique ratings: 5\n"
     ]
    }
   ],
   "source": [
    "n_rating = df['rating'].nunique()\n",
    "print(f\"\\nUnique ratings: {n_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8dd3d796af6ca48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T18:39:15.554931Z",
     "start_time": "2025-11-20T18:39:11.842329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interactions per user (describe):\n",
      "count    776370.000000\n",
      "mean         12.221360\n",
      "std          23.826171\n",
      "min           5.000000\n",
      "25%           6.000000\n",
      "50%           7.000000\n",
      "75%          11.000000\n",
      "max        3134.000000\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many ratings per user?\n",
    "user_freq = df[\"user\"].value_counts()\n",
    "print(\"\\nInteractions per user (describe):\")\n",
    "print(user_freq.describe())\n",
    "\n",
    "# Histogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(user_freq, bins=50, log=True)\n",
    "plt.xlabel(\"Number of interactions per user\")\n",
    "plt.ylabel(\"User count\")\n",
    "plt.title(\"User interaction distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972ef222",
   "metadata": {},
   "source": [
    "1. Content Based model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4094b414-d389-49e3-8a72-f6dc2989bf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_keys dtype: object shape: (494681,)\n",
      "item_vals dtype: int64 shape: (494681,)\n",
      "Sample keys: ['0061058386' '0441008534' '0441009239' '0375826688' '0765362643']\n",
      "Sample vals: [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mp = np.load(\"/home/ubuntu/Advanced_ML/data/mappings.npz\", allow_pickle=True)\n",
    "\n",
    "item_keys = mp[\"item_keys\"]\n",
    "item_vals = mp[\"item_vals\"]\n",
    "\n",
    "print(\"item_keys dtype:\", item_keys.dtype, \"shape:\", item_keys.shape)\n",
    "print(\"item_vals dtype:\", item_vals.dtype, \"shape:\", item_vals.shape)\n",
    "\n",
    "print(\"Sample keys:\", item_keys[:5])\n",
    "print(\"Sample vals:\", item_vals[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "691179fbd2a2379e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in mappings.npz: ['user_keys', 'user_vals', 'item_keys', 'item_vals']\n",
      "item_keys dtype: object shape: (494681,)\n",
      "item_vals dtype: int64 shape: (494681,)\n",
      "Sample keys: ['0061058386' '0441008534' '0441009239' '0375826688' '0765362643']\n",
      "Sample vals: [0 1 2 3 4]\n",
      "Length of item_int2raw: 494681\n",
      "First 5 entries of item_int2raw: ['0061058386' '0441008534' '0441009239' '0375826688' '0765362643']\n",
      "Number of unique ASINs in graph: 494681\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load splits\n",
    "train_df = pd.read_csv(\"/home/ubuntu/Advanced_ML/data/train.csv\")\n",
    "val_df   = pd.read_csv(\"/home/ubuntu/Advanced_ML/data/val.csv\")\n",
    "test_df  = pd.read_csv(\"/home/ubuntu/Advanced_ML/data/test.csv\")\n",
    "\n",
    "# Load mappings\n",
    "mp = np.load(\"/home/ubuntu/Advanced_ML/data/mappings.npz\", allow_pickle=True)\n",
    "print(\"Keys in mappings.npz:\", mp.files)\n",
    "\n",
    "item_keys = mp[\"item_keys\"]  # raw ASIN strings\n",
    "item_vals = mp[\"item_vals\"]  # int IDs\n",
    "\n",
    "print(\"item_keys dtype:\", item_keys.dtype, \"shape:\", item_keys.shape)\n",
    "print(\"item_vals dtype:\", item_vals.dtype, \"shape:\", item_vals.shape)\n",
    "print(\"Sample keys:\", item_keys[:5])\n",
    "print(\"Sample vals:\", item_vals[:5])\n",
    "\n",
    "# Build raw -> int dict first (optional but nice to have)\n",
    "raw2int = dict(zip(item_keys, item_vals))  # raw_asin -> int_id\n",
    "\n",
    "# Now invert to get int -> raw\n",
    "num_items = int(item_vals.max()) + 1       # assumes IDs are 0..num_items-1\n",
    "item_int2raw = [None] * num_items\n",
    "\n",
    "for raw_asin, int_id in raw2int.items():\n",
    "    item_int2raw[int_id] = raw_asin\n",
    "\n",
    "item_int2raw = np.array(item_int2raw)\n",
    "\n",
    "# Sanity check\n",
    "print(\"Length of item_int2raw:\", len(item_int2raw))\n",
    "print(\"First 5 entries of item_int2raw:\", item_int2raw[:5])\n",
    "\n",
    "# Your original asin_set:\n",
    "asin_set = set(str(a) for a in item_int2raw.tolist())\n",
    "print(\"Number of unique ASINs in graph:\", len(asin_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec82415",
   "metadata": {},
   "source": [
    "Load item embeddings into a numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f03987e-97bb-4b1b-8179-4dc80234ae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/ubuntu/advanced_ml_env/lib/python3.12/site-packages (from scikit-learn) (2.3.5)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1c40e05-110b-45a4-ac4b-4228bb9af715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding df shape: (494681, 129)\n",
      "   item_id_int     emb_0     emb_1     emb_2     emb_3     emb_4     emb_5  \\\n",
      "0        71447  0.021240  0.048689  0.018081 -0.038519  0.005805 -0.034636   \n",
      "1       364091  0.005687  0.009901 -0.002689 -0.036152  0.002526 -0.018814   \n",
      "2        81258 -0.010680  0.009522  0.007078 -0.006307 -0.059232 -0.016755   \n",
      "3       335468 -0.037288 -0.042173 -0.047132  0.011618 -0.008416  0.015954   \n",
      "4       111229 -0.040663  0.120124  0.007500 -0.023893  0.015008  0.008697   \n",
      "\n",
      "      emb_6     emb_7     emb_8  ...   emb_118   emb_119   emb_120   emb_121  \\\n",
      "0  0.036180  0.002390  0.017857  ...  0.043356  0.026977 -0.027005 -0.030450   \n",
      "1  0.012948 -0.007484 -0.048425  ...  0.076538  0.030190 -0.054935  0.054905   \n",
      "2  0.018614 -0.000252 -0.004569  ...  0.005983  0.058541  0.033817  0.018643   \n",
      "3  0.070155 -0.016517  0.009566  ...  0.013288 -0.000660 -0.009241 -0.016230   \n",
      "4  0.094907 -0.046244  0.056235  ... -0.016039  0.066872 -0.034263  0.012591   \n",
      "\n",
      "    emb_122   emb_123   emb_124   emb_125   emb_126   emb_127  \n",
      "0 -0.070216  0.028390 -0.047635 -0.035819  0.069240  0.024169  \n",
      "1 -0.002289  0.035356 -0.009833  0.019181 -0.023519  0.011318  \n",
      "2 -0.040500  0.010371  0.005011 -0.051258 -0.006624 -0.028154  \n",
      "3 -0.016868 -0.013387  0.014325  0.003041  0.006610 -0.026860  \n",
      "4  0.016682  0.021078 -0.012764 -0.028376  0.005509 -0.013633  \n",
      "\n",
      "[5 rows x 129 columns]\n",
      "Embedding dim: 128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ITEM_EMB_CSV = \"/home/ubuntu/Advanced_ML/data/item_embeddings_merged.csv\"\n",
    "TRAIN_CSV    = \"/home/ubuntu/Advanced_ML/data/train.csv\"\n",
    "VAL_CSV      = \"/home/ubuntu/Advanced_ML/data/val.csv\"\n",
    "\n",
    "# ---- Load item embeddings ----\n",
    "emb_df = pd.read_csv(ITEM_EMB_CSV)\n",
    "print(\"Embedding df shape:\", emb_df.shape)\n",
    "print(emb_df.head())\n",
    "\n",
    "item_ids = emb_df[\"item_id_int\"].values\n",
    "emb_cols = [c for c in emb_df.columns if c.startswith(\"emb_\")]\n",
    "emb_dim = len(emb_cols)\n",
    "print(\"Embedding dim:\", emb_dim)\n",
    "\n",
    "max_item_id = int(item_ids.max())\n",
    "item_emb = np.zeros((max_item_id + 1, emb_dim), dtype=np.float32)\n",
    "item_emb[item_ids] = emb_df[emb_cols].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e18a9",
   "metadata": {},
   "source": [
    "Build item_emb matrix (id → vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc404b3c-8a11-4238-b31a-6f5e6bff215e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding df shape: (494681, 129)\n",
      "Embedding dim: 128\n",
      "item_emb shape: (494681, 128)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ITEM_EMB_CSV = \"/home/ubuntu/Advanced_ML/data/item_embeddings_merged.csv\"\n",
    "TRAIN_CSV    = \"/home/ubuntu/Advanced_ML/data/train.csv\"\n",
    "VAL_CSV      = \"/home/ubuntu/Advanced_ML/data/val.csv\"\n",
    "\n",
    "# ----\n",
    "\n",
    "# ---- Load item embeddings ----\n",
    "emb_df = pd.read_csv(ITEM_EMB_CSV)\n",
    "print(\"Embedding df shape:\", emb_df.shape)\n",
    "\n",
    "item_ids = emb_df[\"item_id_int\"].values\n",
    "emb_cols = [c for c in emb_df.columns if c.startswith(\"emb_\")]\n",
    "emb_dim = len(emb_cols)\n",
    "print(\"Embedding dim:\", emb_dim)\n",
    "\n",
    "max_item_id = int(item_ids.max())\n",
    "item_emb = np.zeros((max_item_id + 1, emb_dim), dtype=np.float32)\n",
    "item_emb[item_ids] = emb_df[emb_cols].values\n",
    "\n",
    "print(\"item_emb shape:\", item_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6340d0d",
   "metadata": {},
   "source": [
    "Build user embeddings only for validation users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e48b27e9-c1eb-4207-b888-131b40286e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation users: 749045\n",
      "Train history rows for val users: 6499430\n",
      "Users in val: 749045\n",
      "Users with non-empty train history & cb embedding: 749045\n"
     ]
    }
   ],
   "source": [
    "# ---- Load interactions ----\n",
    "train_df = pd.read_csv(TRAIN_CSV)[[\"user_id_int\", \"item_id_int\"]]\n",
    "val_df   = pd.read_csv(VAL_CSV)[[\"user_id_int\", \"item_id_int\"]]\n",
    "\n",
    "val_users = val_df[\"user_id_int\"].unique()\n",
    "print(\"Number of validation users:\", len(val_users))\n",
    "\n",
    "# Filter train history to only those val users\n",
    "train_hist = train_df[train_df[\"user_id_int\"].isin(val_users)]\n",
    "print(\"Train history rows for val users:\", len(train_hist))\n",
    "\n",
    "# user -> list of train items\n",
    "user2train_items = defaultdict(list)\n",
    "for u, i in zip(train_hist[\"user_id_int\"].values, train_hist[\"item_id_int\"].values):\n",
    "    if i <= max_item_id:\n",
    "        user2train_items[u].append(i)\n",
    "\n",
    "# build content-based user embeddings\n",
    "user_emb_cb = {}  # content-based user embeddings\n",
    "for u in val_users:\n",
    "    items = user2train_items.get(u, [])\n",
    "    if len(items) == 0:\n",
    "        continue  # no history, skip in eval\n",
    "\n",
    "    vecs = item_emb[items]  # (n_items_for_u, emb_dim)\n",
    "    user_emb_cb[u] = vecs.mean(axis=0).astype(np.float32)\n",
    "\n",
    "print(\"Users in val:\", len(val_users))\n",
    "print(\"Users with non-empty train history & cb embedding:\", len(user_emb_cb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e4b53",
   "metadata": {},
   "source": [
    "Build validation positives and candidate pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3230374-0f8d-45e7-b3da-148e9391d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique items in validation: 264963\n"
     ]
    }
   ],
   "source": [
    "# positives per user in val\n",
    "user2val_pos = (\n",
    "    val_df.groupby(\"user_id_int\")[\"item_id_int\"]\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "all_val_items = val_df[\"item_id_int\"].unique()\n",
    "print(\"Unique items in validation:\", len(all_val_items))\n",
    "\n",
    "# all items seen per user (train + val)\n",
    "user2all_items = defaultdict(set)\n",
    "for u, i in zip(train_hist[\"user_id_int\"], train_hist[\"item_id_int\"]):\n",
    "    user2all_items[u].add(i)\n",
    "for u, i in zip(val_df[\"user_id_int\"], val_df[\"item_id_int\"]):\n",
    "    user2all_items[u].add(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de230323",
   "metadata": {},
   "source": [
    "Metric helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c9fe35f-73f4-4f6b-aba7-5326dc359f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_at_k(labels, scores, k):\n",
    "    idx = np.argsort(scores)[::-1][:k]\n",
    "    return 1.0 if labels[idx].max() > 0 else 0.0\n",
    "\n",
    "def ndcg_at_k(labels, scores, k):\n",
    "    idx = np.argsort(scores)[::-1][:k]\n",
    "    for rank, j in enumerate(idx):\n",
    "        if labels[j] == 1:\n",
    "            return 1.0 / np.log2(rank + 2)\n",
    "    return 0.0\n",
    "\n",
    "def mrr_single(labels, scores):\n",
    "    idx = np.argsort(scores)[::-1]\n",
    "    for rank, j in enumerate(idx):\n",
    "        if labels[j] == 1:\n",
    "            return 1.0 / (rank + 1)\n",
    "    return 0.0\n",
    "\n",
    "def auc_single(labels, scores):\n",
    "    if labels.sum() == 0 or labels.sum() == len(labels):\n",
    "        return np.nan\n",
    "    return roc_auc_score(labels, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92f62059-5595-4bf6-814a-85c9a2636e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# numpy → torch on GPU\n",
    "item_emb_torch = torch.tensor(item_emb, dtype=torch.float32, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3f6c0a",
   "metadata": {},
   "source": [
    "Evaluate content-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b4dfbda-5340-40e1-9dc9-34f5ff033297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_content_based_gpu(\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    seed=42,\n",
    "    name=\"Val\"\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # users we can evaluate: must have cb embedding and at least 1 val positive\n",
    "    eligible_users = [u for u in user2val_pos.keys() if u in user_emb_cb]\n",
    "    rng.shuffle(eligible_users)\n",
    "    sampled_users = eligible_users[:min(N_USERS_SAMPLE, len(eligible_users))]\n",
    "\n",
    "    hit_vals = {k: [] for k in Ks}\n",
    "    ndcg_vals = {k: [] for k in Ks}\n",
    "    mrr_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    for idx, u in enumerate(sampled_users):\n",
    "        pos_items = user2val_pos[u]\n",
    "        if len(pos_items) == 0:\n",
    "            continue\n",
    "\n",
    "        # choose one positive (e.g. last interaction)\n",
    "        pos_item = pos_items[-1]\n",
    "        if pos_item > max_item_id:\n",
    "            continue\n",
    "\n",
    "        # sample negatives = items in val not seen by this user\n",
    "        user_seen = user2all_items[u]\n",
    "        candidate_negs = [i for i in all_val_items if i not in user_seen and i <= max_item_id]\n",
    "        if len(candidate_negs) == 0:\n",
    "            continue\n",
    "\n",
    "        if len(candidate_negs) > N_NEG:\n",
    "            neg_items = rng.choice(candidate_negs, size=N_NEG, replace=False)\n",
    "        else:\n",
    "            neg_items = np.array(candidate_negs, dtype=np.int64)\n",
    "\n",
    "        candidates = np.concatenate([[pos_item], neg_items])          # (C,)\n",
    "        labels = np.zeros(len(candidates), dtype=np.int32)\n",
    "        labels[0] = 1  # first is positive\n",
    "\n",
    "        # ---- GPU scoring ----\n",
    "        # user embedding → torch on GPU\n",
    "        u_vec_np = user_emb_cb[u]                                      # (D,)\n",
    "        u_vec = torch.tensor(u_vec_np, dtype=torch.float32, device=device)  # (D,)\n",
    "\n",
    "        # candidate item embeddings on GPU: index into item_emb_torch\n",
    "        cand_idx = torch.tensor(candidates, dtype=torch.long, device=device)  # (C,)\n",
    "        item_vecs = item_emb_torch[cand_idx]                                  # (C, D)\n",
    "\n",
    "        # scores on GPU: (C,)\n",
    "        scores_t = item_vecs @ u_vec\n",
    "        scores = scores_t.detach().cpu().numpy()\n",
    "\n",
    "        # ---- metrics on CPU (same as before) ----\n",
    "        for k in Ks:\n",
    "            hit_vals[k].append(hit_at_k(labels, scores, k))\n",
    "            ndcg_vals[k].append(ndcg_at_k(labels, scores, k))\n",
    "\n",
    "        mrr_list.append(mrr_single(labels, scores))\n",
    "        auc_val = auc_single(labels, scores)\n",
    "        if not np.isnan(auc_val):\n",
    "            auc_list.append(auc_val)\n",
    "\n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            print(f\"[Content-based {name}] Processed {idx+1}/{len(sampled_users)} users...\")\n",
    "\n",
    "    # aggregate\n",
    "    mrr = float(np.mean(mrr_list))\n",
    "    auc = float(np.mean(auc_list))\n",
    "    metrics = {\n",
    "        \"MRR\": mrr,\n",
    "        \"AUC\": auc,\n",
    "    }\n",
    "    for k in Ks:\n",
    "        metrics[f\"HR@{k}\"]    = float(np.mean(hit_vals[k]))\n",
    "        metrics[f\"nDCG@{k}\"]  = float(np.mean(ndcg_vals[k]))\n",
    "\n",
    "    print(f\"\\n{name} Metrics: \", metrics)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc1c9b8c-bff4-4021-a87f-311647d8006c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Content-based Val] Processed 1000/10000 users...\n",
      "[Content-based Val] Processed 2000/10000 users...\n",
      "[Content-based Val] Processed 3000/10000 users...\n",
      "[Content-based Val] Processed 4000/10000 users...\n",
      "[Content-based Val] Processed 5000/10000 users...\n",
      "[Content-based Val] Processed 6000/10000 users...\n",
      "[Content-based Val] Processed 7000/10000 users...\n",
      "[Content-based Val] Processed 8000/10000 users...\n",
      "[Content-based Val] Processed 9000/10000 users...\n",
      "[Content-based Val] Processed 10000/10000 users...\n",
      "\n",
      "Val Metrics:  {'MRR': 0.25870898410906196, 'AUC': 0.7612, 'HR@5': 0.3382, 'nDCG@5': 0.25263378941707026, 'HR@10': 0.4503, 'nDCG@10': 0.28877367772646495}\n"
     ]
    }
   ],
   "source": [
    "cb_val_metrics = evaluate_content_based_gpu(\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    name=\"Val\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed7ed2b0-185e-4e02-affa-d87f075b0fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_content_based_gpu(\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    seed=42,\n",
    "    name=\"Val\"\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # users we can evaluate: must have cb embedding and at least 1 val positive\n",
    "    eligible_users = [u for u in user2val_pos.keys() if u in user_emb_cb]\n",
    "    rng.shuffle(eligible_users)\n",
    "    sampled_users = eligible_users[:min(N_USERS_SAMPLE, len(eligible_users))]\n",
    "\n",
    "    hit_vals = {k: [] for k in Ks}\n",
    "    ndcg_vals = {k: [] for k in Ks}\n",
    "    mrr_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    for idx, u in enumerate(sampled_users):\n",
    "        pos_items = user2val_pos[u]\n",
    "        if len(pos_items) == 0:\n",
    "            continue\n",
    "\n",
    "        # choose one positive (e.g. last interaction)\n",
    "        pos_item = pos_items[-1]\n",
    "        if pos_item > max_item_id:\n",
    "            continue\n",
    "\n",
    "        # sample negatives = items in val not seen by this user\n",
    "        user_seen = user2all_items[u]\n",
    "        candidate_negs = [i for i in all_val_items if i not in user_seen and i <= max_item_id]\n",
    "        if len(candidate_negs) == 0:\n",
    "            continue\n",
    "\n",
    "        if len(candidate_negs) > N_NEG:\n",
    "            neg_items = rng.choice(candidate_negs, size=N_NEG, replace=False)\n",
    "        else:\n",
    "            neg_items = np.array(candidate_negs, dtype=np.int64)\n",
    "\n",
    "        candidates = np.concatenate([[pos_item], neg_items])   # (C,)\n",
    "        labels = np.zeros(len(candidates), dtype=np.int32)\n",
    "        labels[0] = 1  # first is positive\n",
    "\n",
    "        # 🔍 DEBUG for first few users\n",
    "        if idx < 5:\n",
    "            print(\"\\n[DEBUG] User:\", u)\n",
    "            print(\"  pos_item:\", pos_item)\n",
    "            print(\"  #candidate_negs:\", len(candidate_negs))\n",
    "            print(\"  sample neg_items:\", neg_items[:10])\n",
    "            pos_norm = np.linalg.norm(item_emb[pos_item])\n",
    "            neg_norms = np.linalg.norm(item_emb[neg_items], axis=1)\n",
    "            print(\"  pos emb norm:\", pos_norm)\n",
    "            print(\"  neg emb norms (first 10):\", neg_norms[:10])\n",
    "            print(\"  zeros among negs:\", np.sum(neg_norms == 0))\n",
    "\n",
    "        # ---- GPU scoring ----\n",
    "        u_vec_np = user_emb_cb[u]  # (D,)\n",
    "        u_vec = torch.tensor(u_vec_np, dtype=torch.float32, device=device)  # (D,)\n",
    "\n",
    "        cand_idx = torch.tensor(candidates, dtype=torch.long, device=device)  # (C,)\n",
    "        item_vecs = item_emb_torch[cand_idx]                                  # (C, D)\n",
    "\n",
    "        scores_t = item_vecs @ u_vec\n",
    "        scores = scores_t.detach().cpu().numpy()\n",
    "\n",
    "        # ---- metrics on CPU ----\n",
    "        for k in Ks:\n",
    "            hit_vals[k].append(hit_at_k(labels, scores, k))\n",
    "            ndcg_vals[k].append(ndcg_at_k(labels, scores, k))\n",
    "\n",
    "        mrr_list.append(mrr_single(labels, scores))\n",
    "        auc_val = auc_single(labels, scores)\n",
    "        if not np.isnan(auc_val):\n",
    "            auc_list.append(auc_val)\n",
    "\n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            print(f\"[Content-based {name}] Processed {idx+1}/{len(sampled_users)} users...\")\n",
    "\n",
    "    # aggregate\n",
    "    mrr = float(np.mean(mrr_list))\n",
    "    auc = float(np.mean(auc_list))\n",
    "    metrics = {\n",
    "        \"MRR\": mrr,\n",
    "        \"AUC\": auc,\n",
    "    }\n",
    "    for k in Ks:\n",
    "        metrics[f\"HR@{k}\"]    = float(np.mean(hit_vals[k]))\n",
    "        metrics[f\"nDCG@{k}\"]  = float(np.mean(ndcg_vals[k]))\n",
    "\n",
    "    print(f\"\\n{name} Metrics: \", metrics)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "877db06f-f51e-4f75-913d-b2f0e61b8467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] User: 308435\n",
      "  pos_item: 123983\n",
      "  #candidate_negs: 264962\n",
      "  sample neg_items: [461253 294717 104027  92913 134565   1360 459072 377372 210242  34647]\n",
      "  pos emb norm: 0.4053675\n",
      "  neg emb norms (first 10): [0.3721055  0.3954569  0.41607237 0.3963344  0.39473218 0.39847854\n",
      " 0.39209926 0.41966444 0.41174522 0.39367318]\n",
      "  zeros among negs: 0\n",
      "\n",
      "[DEBUG] User: 633343\n",
      "  pos_item: 28974\n",
      "  #candidate_negs: 264961\n",
      "  sample neg_items: [244662 180530 160121 478037  76669 115580 361273 100231 453045  29600]\n",
      "  pos emb norm: 0.3804785\n",
      "  neg emb norms (first 10): [0.39133656 0.36710775 0.3968     0.41096574 0.40597937 0.39757818\n",
      " 0.44846484 0.37416047 0.37339726 0.41220772]\n",
      "  zeros among negs: 0\n",
      "\n",
      "[DEBUG] User: 334686\n",
      "  pos_item: 63785\n",
      "  #candidate_negs: 264961\n",
      "  sample neg_items: [153913 281390 469810 327552 470883 178387 182757 134317 357243 375939]\n",
      "  pos emb norm: 0.42443362\n",
      "  neg emb norms (first 10): [0.40463483 0.40135026 0.45051536 0.4501765  0.37486154 0.37752032\n",
      " 0.4132638  0.41101804 0.43695566 0.41475424]\n",
      "  zeros among negs: 0\n",
      "\n",
      "[DEBUG] User: 29488\n",
      "  pos_item: 471012\n",
      "  #candidate_negs: 264959\n",
      "  sample neg_items: [ 92309 360675 366270 399302 221489 388383 153192  92030  94293 391935]\n",
      "  pos emb norm: 0.3839284\n",
      "  neg emb norms (first 10): [0.44494796 0.41088063 0.4561022  0.41202807 0.42299682 0.45054597\n",
      " 0.43524158 0.40564805 0.39456046 0.4150189 ]\n",
      "  zeros among negs: 0\n",
      "\n",
      "[DEBUG] User: 246910\n",
      "  pos_item: 159816\n",
      "  #candidate_negs: 264961\n",
      "  sample neg_items: [ 25015  10057  85881  29255 289201 493137 270844 164092 383341 103637]\n",
      "  pos emb norm: 0.3878936\n",
      "  neg emb norms (first 10): [0.43167645 0.42181322 0.4230396  0.357414   0.37016088 0.44104022\n",
      " 0.39378724 0.41400394 0.41934568 0.40796027]\n",
      "  zeros among negs: 0\n",
      "[Content-based Val] Processed 1000/10000 users...\n",
      "[Content-based Val] Processed 2000/10000 users...\n",
      "[Content-based Val] Processed 3000/10000 users...\n",
      "[Content-based Val] Processed 4000/10000 users...\n",
      "[Content-based Val] Processed 5000/10000 users...\n",
      "[Content-based Val] Processed 6000/10000 users...\n",
      "[Content-based Val] Processed 7000/10000 users...\n",
      "[Content-based Val] Processed 8000/10000 users...\n",
      "[Content-based Val] Processed 9000/10000 users...\n",
      "[Content-based Val] Processed 10000/10000 users...\n",
      "\n",
      "Val Metrics:  {'MRR': 0.25870898410906196, 'AUC': 0.7612, 'HR@5': 0.3382, 'nDCG@5': 0.25263378941707026, 'HR@10': 0.4503, 'nDCG@10': 0.28877367772646495}\n"
     ]
    }
   ],
   "source": [
    "cb_val_metrics = evaluate_content_based_gpu(\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    name=\"Val\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b5c2b2",
   "metadata": {},
   "source": [
    "Random baseline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40b8761a-9c07-4a7d-84eb-e064761f32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_random_baseline(\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    seed=123,\n",
    "    name=\"Random\"\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # users we can evaluate: need at least 1 val positive\n",
    "    eligible_users = [u for u, pos_list in user2val_pos.items() if len(pos_list) > 0]\n",
    "    rng.shuffle(eligible_users)\n",
    "    sampled_users = eligible_users[:min(N_USERS_SAMPLE, len(eligible_users))]\n",
    "\n",
    "    hit_vals = {k: [] for k in Ks}\n",
    "    ndcg_vals = {k: [] for k in Ks}\n",
    "    mrr_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    for idx, u in enumerate(sampled_users):\n",
    "        pos_items = user2val_pos[u]\n",
    "        if len(pos_items) == 0:\n",
    "            continue\n",
    "\n",
    "        # choose one positive (e.g. last interaction)\n",
    "        pos_item = pos_items[-1]\n",
    "        if pos_item > max_item_id:\n",
    "            continue\n",
    "\n",
    "        # sample negatives = items in val not seen by this user\n",
    "        user_seen = user2all_items[u]\n",
    "        candidate_negs = [i for i in all_val_items if i not in user_seen and i <= max_item_id]\n",
    "        if len(candidate_negs) == 0:\n",
    "            continue\n",
    "\n",
    "        if len(candidate_negs) > N_NEG:\n",
    "            neg_items = rng.choice(candidate_negs, size=N_NEG, replace=False)\n",
    "        else:\n",
    "            neg_items = np.array(candidate_negs, dtype=np.int64)\n",
    "\n",
    "        candidates = np.concatenate([[pos_item], neg_items])   # (C,)\n",
    "        labels = np.zeros(len(candidates), dtype=np.int32)\n",
    "        labels[0] = 1  # first is positive\n",
    "\n",
    "        # RANDOM SCORES (no model, no GPU)\n",
    "        scores = rng.normal(size=len(candidates))  # or rng.random(...)\n",
    "\n",
    "        # metrics\n",
    "        for k in Ks:\n",
    "            hit_vals[k].append(hit_at_k(labels, scores, k))\n",
    "            ndcg_vals[k].append(ndcg_at_k(labels, scores, k))\n",
    "\n",
    "        mrr_list.append(mrr_single(labels, scores))\n",
    "        auc_val = auc_single(labels, scores)\n",
    "        if not np.isnan(auc_val):\n",
    "            auc_list.append(auc_val)\n",
    "\n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            print(f\"[{name}] Processed {idx+1}/{len(sampled_users)} users...\")\n",
    "\n",
    "    # aggregate\n",
    "    mrr = float(np.mean(mrr_list))\n",
    "    auc = float(np.mean(auc_list))\n",
    "    metrics = {\n",
    "        \"MRR\": mrr,\n",
    "        \"AUC\": auc,\n",
    "    }\n",
    "    for k in Ks:\n",
    "        metrics[f\"HR@{k}\"]    = float(np.mean(hit_vals[k]))\n",
    "        metrics[f\"nDCG@{k}\"]  = float(np.mean(ndcg_vals[k]))\n",
    "\n",
    "    print(f\"\\n{name} Metrics: \", metrics)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6df5a872-764e-45a2-9577-e037d2993dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Random-ContentBaseline] Processed 1000/10000 users...\n",
      "[Random-ContentBaseline] Processed 2000/10000 users...\n",
      "[Random-ContentBaseline] Processed 3000/10000 users...\n",
      "[Random-ContentBaseline] Processed 4000/10000 users...\n",
      "[Random-ContentBaseline] Processed 5000/10000 users...\n",
      "[Random-ContentBaseline] Processed 6000/10000 users...\n",
      "[Random-ContentBaseline] Processed 7000/10000 users...\n",
      "[Random-ContentBaseline] Processed 8000/10000 users...\n",
      "[Random-ContentBaseline] Processed 9000/10000 users...\n",
      "[Random-ContentBaseline] Processed 10000/10000 users...\n",
      "\n",
      "Random-ContentBaseline Metrics:  {'MRR': 0.05220432365577194, 'AUC': 0.5029808080808081, 'HR@5': 0.051, 'nDCG@5': 0.029671624676158206, 'HR@10': 0.1025, 'nDCG@10': 0.0461887207158008}\n"
     ]
    }
   ],
   "source": [
    "random_val_metrics = evaluate_random_baseline(\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    seed=123,\n",
    "    name=\"Random-ContentBaseline\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109c7ca",
   "metadata": {},
   "source": [
    "Hybrid Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e751dde4",
   "metadata": {},
   "source": [
    "Extract and save LightGCN embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "430dfe4f-abdd-4572-ba88-647668967a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in state_dict: odict_keys(['A_norm', 'user_emb.weight', 'item_emb.weight'])\n",
      "user_cf_emb shape: (749045, 128)\n",
      "item_cf_emb shape: (494681, 128)\n",
      "Saved user_cf_emb.npy and item_cf_emb.npy\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "CKPT_PATH = \"/home/ubuntu/Advanced_ML/ckpt_epoch_019.pt\"\n",
    "\n",
    "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
    "\n",
    "# Use the correct state_dict\n",
    "if \"model_state_dict\" in ckpt:\n",
    "    sd = ckpt[\"model_state_dict\"]\n",
    "elif \"state_dict\" in ckpt:\n",
    "    sd = ckpt[\"state_dict\"]\n",
    "else:\n",
    "    sd = ckpt  # assume it's already a state_dict\n",
    "\n",
    "print(\"Keys in state_dict:\", sd.keys())\n",
    "\n",
    "# Directly grab embeddings\n",
    "user_tensor = sd[\"user_emb.weight\"]   # shape (749045, 128)\n",
    "item_tensor = sd[\"item_emb.weight\"]   # shape (494681, 128)\n",
    "\n",
    "user_cf_emb = user_tensor.cpu().numpy()\n",
    "item_cf_emb = item_tensor.cpu().numpy()\n",
    "\n",
    "print(\"user_cf_emb shape:\", user_cf_emb.shape)\n",
    "print(\"item_cf_emb shape:\", item_cf_emb.shape)\n",
    "\n",
    "# Save to .npy\n",
    "np.save(\"user_cf_emb.npy\", user_cf_emb)\n",
    "np.save(\"item_cf_emb.npy\", item_cf_emb)\n",
    "\n",
    "print(\"Saved user_cf_emb.npy and item_cf_emb.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5db610",
   "metadata": {},
   "source": [
    "Then load them for CF + Hybrid eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c8a6fe5-98d5-4c91-97a8-c7fe183606b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "user_cf_emb shape: (749045, 128)\n",
      "item_cf_emb shape: (494681, 128)\n",
      "CF dims: 749045 494681 128\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# You already have item_emb (content-based item embeddings)\n",
    "item_emb_torch = torch.tensor(item_emb, dtype=torch.float32, device=device)\n",
    "\n",
    "# Load CF embeddings\n",
    "user_cf_emb = np.load(\"user_cf_emb.npy\")   # (749045, 128)\n",
    "item_cf_emb = np.load(\"item_cf_emb.npy\")   # (494681, 128)\n",
    "\n",
    "print(\"user_cf_emb shape:\", user_cf_emb.shape)\n",
    "print(\"item_cf_emb shape:\", item_cf_emb.shape)\n",
    "\n",
    "user_cf_emb_torch = torch.tensor(user_cf_emb, dtype=torch.float32, device=device)\n",
    "item_cf_emb_torch = torch.tensor(item_cf_emb, dtype=torch.float32, device=device)\n",
    "\n",
    "num_users_cf, d_cf = user_cf_emb.shape\n",
    "num_items_cf, _   = item_cf_emb.shape\n",
    "print(\"CF dims:\", num_users_cf, num_items_cf, d_cf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa21ef76-928d-4c8f-9cd1-5eb6f414235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cf_gpu(\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    seed=42,\n",
    "    name=\"CF-Only\"\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # users: must have val positives & be within CF user index range\n",
    "    eligible_users = [\n",
    "        u for u in user2val_pos.keys()\n",
    "        if u < num_users_cf and len(user2val_pos[u]) > 0\n",
    "    ]\n",
    "    rng.shuffle(eligible_users)\n",
    "    sampled_users = eligible_users[:min(N_USERS_SAMPLE, len(eligible_users))]\n",
    "\n",
    "    hit_vals = {k: [] for k in Ks}\n",
    "    ndcg_vals = {k: [] for k in Ks}\n",
    "    mrr_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    for idx, u in enumerate(sampled_users):\n",
    "        pos_items = user2val_pos[u]\n",
    "        if len(pos_items) == 0:\n",
    "            continue\n",
    "\n",
    "        pos_item = pos_items[-1]\n",
    "        if pos_item > max_item_id or pos_item >= num_items_cf:\n",
    "            continue\n",
    "\n",
    "        user_seen = user2all_items[u]\n",
    "        candidate_negs = [\n",
    "            i for i in all_val_items\n",
    "            if i not in user_seen and i <= max_item_id and i < num_items_cf\n",
    "        ]\n",
    "        if len(candidate_negs) == 0:\n",
    "            continue\n",
    "\n",
    "        if len(candidate_negs) > N_NEG:\n",
    "            neg_items = rng.choice(candidate_negs, size=N_NEG, replace=False)\n",
    "        else:\n",
    "            neg_items = np.array(candidate_negs, dtype=np.int64)\n",
    "\n",
    "        candidates = np.concatenate([[pos_item], neg_items])\n",
    "        labels = np.zeros(len(candidates), dtype=np.int32)\n",
    "        labels[0] = 1\n",
    "\n",
    "        cand_idx = torch.tensor(candidates, dtype=torch.long, device=device)\n",
    "        item_cf_vecs = item_cf_emb_torch[cand_idx]   # (C, D)\n",
    "        u_cf_vec = user_cf_emb_torch[u]              # (D,)\n",
    "        scores_t = item_cf_vecs @ u_cf_vec           # (C,)\n",
    "        scores = scores_t.detach().cpu().numpy()\n",
    "\n",
    "        for k in Ks:\n",
    "            hit_vals[k].append(hit_at_k(labels, scores, k))\n",
    "            ndcg_vals[k].append(ndcg_at_k(labels, scores, k))\n",
    "\n",
    "        mrr_list.append(mrr_single(labels, scores))\n",
    "        auc_val = auc_single(labels, scores)\n",
    "        if not np.isnan(auc_val):\n",
    "            auc_list.append(auc_val)\n",
    "\n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            print(f\"[{name}] Processed {idx+1}/{len(sampled_users)} users...\")\n",
    "\n",
    "    mrr = float(np.mean(mrr_list))\n",
    "    auc = float(np.mean(auc_list))\n",
    "    metrics = {\n",
    "        \"MRR\": mrr,\n",
    "        \"AUC\": auc,\n",
    "    }\n",
    "    for k in Ks:\n",
    "        metrics[f\"HR@{k}\"]   = float(np.mean(hit_vals[k]))\n",
    "        metrics[f\"nDCG@{k}\"] = float(np.mean(ndcg_vals[k]))\n",
    "\n",
    "    print(f\"\\n{name} Metrics: \", metrics)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13bbc480-c918-4bbb-8cee-543bc6e18c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hybrid_gpu(\n",
    "    alpha=0.5,\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    seed=42,\n",
    "    name=None\n",
    "):\n",
    "    if name is None:\n",
    "        name = f\"Hybrid alpha={alpha}\"\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # need both CB user emb and CF user emb & val positives\n",
    "    eligible_users = [\n",
    "        u for u in user2val_pos.keys()\n",
    "        if u in user_emb_cb and u < num_users_cf and len(user2val_pos[u]) > 0\n",
    "    ]\n",
    "    rng.shuffle(eligible_users)\n",
    "    sampled_users = eligible_users[:min(N_USERS_SAMPLE, len(eligible_users))]\n",
    "\n",
    "    hit_vals = {k: [] for k in Ks}\n",
    "    ndcg_vals = {k: [] for k in Ks}\n",
    "    mrr_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    for idx, u in enumerate(sampled_users):\n",
    "        pos_items = user2val_pos[u]\n",
    "        if len(pos_items) == 0:\n",
    "            continue\n",
    "\n",
    "        pos_item = pos_items[-1]\n",
    "        if pos_item > max_item_id or pos_item >= num_items_cf:\n",
    "            continue\n",
    "\n",
    "        user_seen = user2all_items[u]\n",
    "        candidate_negs = [\n",
    "            i for i in all_val_items\n",
    "            if i not in user_seen and i <= max_item_id and i < num_items_cf\n",
    "        ]\n",
    "        if len(candidate_negs) == 0:\n",
    "            continue\n",
    "\n",
    "        if len(candidate_negs) > N_NEG:\n",
    "            neg_items = rng.choice(candidate_negs, size=N_NEG, replace=False)\n",
    "        else:\n",
    "            neg_items = np.array(candidate_negs, dtype=np.int64)\n",
    "\n",
    "        candidates = np.concatenate([[pos_item], neg_items])\n",
    "        labels = np.zeros(len(candidates), dtype=np.int32)\n",
    "        labels[0] = 1\n",
    "\n",
    "        cand_idx = torch.tensor(candidates, dtype=torch.long, device=device)\n",
    "\n",
    "        # Content-based score\n",
    "        u_cb_vec_np = user_emb_cb[u]\n",
    "        u_cb_vec = torch.tensor(u_cb_vec_np, dtype=torch.float32, device=device)\n",
    "        item_cb_vecs = item_emb_torch[cand_idx]\n",
    "        scores_cb_t = item_cb_vecs @ u_cb_vec\n",
    "\n",
    "        # CF score\n",
    "        u_cf_vec = user_cf_emb_torch[u]\n",
    "        item_cf_vecs = item_cf_emb_torch[cand_idx]\n",
    "        scores_cf_t = item_cf_vecs @ u_cf_vec\n",
    "\n",
    "        # Hybrid\n",
    "        scores_t = alpha * scores_cf_t + (1.0 - alpha) * scores_cb_t\n",
    "        scores = scores_t.detach().cpu().numpy()\n",
    "\n",
    "        for k in Ks:\n",
    "            hit_vals[k].append(hit_at_k(labels, scores, k))\n",
    "            ndcg_vals[k].append(ndcg_at_k(labels, scores, k))\n",
    "\n",
    "        mrr_list.append(mrr_single(labels, scores))\n",
    "        auc_val = auc_single(labels, scores)\n",
    "        if not np.isnan(auc_val):\n",
    "            auc_list.append(auc_val)\n",
    "\n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            print(f\"[{name}] Processed {idx+1}/{len(sampled_users)} users...\")\n",
    "\n",
    "    mrr = float(np.mean(mrr_list))\n",
    "    auc = float(np.mean(auc_list))\n",
    "    metrics = {\n",
    "        \"MRR\": mrr,\n",
    "        \"AUC\": auc,\n",
    "    }\n",
    "    for k in Ks:\n",
    "        metrics[f\"HR@{k}\"]   = float(np.mean(hit_vals[k]))\n",
    "        metrics[f\"nDCG@{k}\"] = float(np.mean(ndcg_vals[k]))\n",
    "\n",
    "    print(f\"\\n{name} Metrics: \", metrics)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8281998-3c7c-49df-9b8d-ead53ded69e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CF-Only] Processed 1000/10000 users...\n",
      "[CF-Only] Processed 2000/10000 users...\n",
      "[CF-Only] Processed 3000/10000 users...\n",
      "[CF-Only] Processed 4000/10000 users...\n",
      "[CF-Only] Processed 5000/10000 users...\n",
      "[CF-Only] Processed 6000/10000 users...\n",
      "[CF-Only] Processed 7000/10000 users...\n",
      "[CF-Only] Processed 8000/10000 users...\n",
      "[CF-Only] Processed 9000/10000 users...\n",
      "[CF-Only] Processed 10000/10000 users...\n",
      "\n",
      "CF-Only Metrics:  {'MRR': 0.33104519361797174, 'AUC': 0.8514828282828283, 'HR@5': 0.462, 'nDCG@5': 0.3367716032689453, 'HR@10': 0.6043, 'nDCG@10': 0.3827617463751393}\n"
     ]
    }
   ],
   "source": [
    "cf_val_metrics = evaluate_cf_gpu(\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    seed=42,\n",
    "    name=\"CF-Only\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea3dbfb3-b82a-4fb7-8376-b2931773aead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hybrid alpha=0.5] Processed 1000/10000 users...\n",
      "[Hybrid alpha=0.5] Processed 2000/10000 users...\n",
      "[Hybrid alpha=0.5] Processed 3000/10000 users...\n",
      "[Hybrid alpha=0.5] Processed 4000/10000 users...\n",
      "[Hybrid alpha=0.5] Processed 5000/10000 users...\n",
      "[Hybrid alpha=0.5] Processed 6000/10000 users...\n",
      "[Hybrid alpha=0.5] Processed 7000/10000 users...\n",
      "[Hybrid alpha=0.5] Processed 8000/10000 users...\n",
      "[Hybrid alpha=0.5] Processed 9000/10000 users...\n",
      "[Hybrid alpha=0.5] Processed 10000/10000 users...\n",
      "\n",
      "Hybrid alpha=0.5 Metrics:  {'MRR': 0.332668373300345, 'AUC': 0.8519636363636364, 'HR@5': 0.4645, 'nDCG@5': 0.33876840811704356, 'HR@10': 0.6056, 'nDCG@10': 0.38437122165451937}\n"
     ]
    }
   ],
   "source": [
    "hyb_05 = evaluate_hybrid_gpu(\n",
    "    alpha=0.5,\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    seed=42,\n",
    "    name=\"Hybrid alpha=0.5\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4dcd03ac-02cd-4b22-9f04-ff29fcc25729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-based max_item_id: 494680\n",
      "CF num_items: 494681\n",
      "Val unique items: 264963\n",
      "Max item in val: 494102\n"
     ]
    }
   ],
   "source": [
    "print(\"Content-based max_item_id:\", max_item_id)\n",
    "print(\"CF num_items:\", num_items_cf)\n",
    "print(\"Val unique items:\", len(all_val_items))\n",
    "print(\"Max item in val:\", max(all_val_items))\n",
    "\n",
    "# Check alignment\n",
    "if max_item_id != num_items_cf - 1:\n",
    "    print(\"WARNING: Embedding dimension mismatch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9774cc25-79b2-4d29-83f4-032d7d7e583e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-based max_item_id: 494680\n",
      "CF num_items: 494681\n",
      "Val unique items: 264963\n",
      "Max item in val: 494102\n"
     ]
    }
   ],
   "source": [
    "print(\"Content-based max_item_id:\", max_item_id)\n",
    "print(\"CF num_items:\", num_items_cf)\n",
    "print(\"Val unique items:\", len(all_val_items))\n",
    "print(\"Max item in val:\", max(all_val_items))\n",
    "\n",
    "# Check alignment\n",
    "if max_item_id != num_items_cf - 1:\n",
    "    print(\"WARNING: Embedding dimension mismatch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b08c2fb-9426-4a41-bf35-a47ca79cdf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val items within CF range: 264963\n"
     ]
    }
   ],
   "source": [
    "# The CF checkpoint should have been trained ONLY on train.csv\n",
    "# Not on val.csv or test.csv\n",
    "\n",
    "# Check if CF model \"knows\" about validation items\n",
    "val_items_in_cf = [i for i in all_val_items if i < num_items_cf]\n",
    "print(f\"Val items within CF range: {len(val_items_in_cf)}\")\n",
    "\n",
    "# If CF was trained properly, it should NOT have seen \n",
    "# val interactions during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7aa3597d-3833-41cb-8286-a4c1152371ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SCORE DISTRIBUTION CHECK\n",
      "============================================================\n",
      "\n",
      "For user 0 on 100 random items:\n",
      "CF scores:      min=-6.203, max=7.830, range=14.033\n",
      "Content scores: min=-0.007, max=0.062, range=0.069\n",
      "\n",
      "Range ratio (CF/Content): 203.35x\n",
      "⚠️  WARNING: Scores have different scales!\n",
      "   Consider normalizing before combining\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quick score distribution check\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCORE DISTRIBUTION CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sample one user\n",
    "test_user = list(user_emb_cb.keys())[0]\n",
    "test_items = np.random.choice(all_val_items, size=100, replace=False)\n",
    "\n",
    "# Get CF scores\n",
    "u_cf = user_cf_emb[test_user]\n",
    "items_cf = item_cf_emb[test_items]\n",
    "cf_scores = items_cf @ u_cf\n",
    "\n",
    "# Get content scores  \n",
    "u_cb = user_emb_cb[test_user]\n",
    "items_cb = item_emb[test_items]\n",
    "cb_scores = items_cb @ u_cb\n",
    "\n",
    "print(f\"\\nFor user {test_user} on 100 random items:\")\n",
    "print(f\"CF scores:      min={cf_scores.min():.3f}, max={cf_scores.max():.3f}, range={cf_scores.max()-cf_scores.min():.3f}\")\n",
    "print(f\"Content scores: min={cb_scores.min():.3f}, max={cb_scores.max():.3f}, range={cb_scores.max()-cb_scores.min():.3f}\")\n",
    "\n",
    "ratio = (cf_scores.max() - cf_scores.min()) / (cb_scores.max() - cb_scores.min() + 1e-8)\n",
    "print(f\"\\nRange ratio (CF/Content): {ratio:.2f}x\")\n",
    "\n",
    "if ratio > 2.0 or ratio < 0.5:\n",
    "    print(\"⚠️  WARNING: Scores have different scales!\")\n",
    "    print(\"   Consider normalizing before combining\")\n",
    "else:\n",
    "    print(\"Scores appear to be on similar scales\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c0f6c-2e1a-48ed-842a-71db814dc2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARING BROKEN vs FIXED HYBRID\n",
      "======================================================================\n",
      "\n",
      "1. Your ORIGINAL hybrid (without normalization):\n",
      "   This is BROKEN - CF dominates due to 203x score difference\n",
      "[Hybrid-BROKEN α=0.5] Processed 1000/10000 users...\n",
      "[Hybrid-BROKEN α=0.5] Processed 2000/10000 users...\n",
      "[Hybrid-BROKEN α=0.5] Processed 3000/10000 users...\n",
      "[Hybrid-BROKEN α=0.5] Processed 4000/10000 users...\n",
      "[Hybrid-BROKEN α=0.5] Processed 5000/10000 users...\n",
      "[Hybrid-BROKEN α=0.5] Processed 6000/10000 users...\n",
      "[Hybrid-BROKEN α=0.5] Processed 7000/10000 users...\n",
      "[Hybrid-BROKEN α=0.5] Processed 8000/10000 users...\n",
      "[Hybrid-BROKEN α=0.5] Processed 9000/10000 users...\n",
      "[Hybrid-BROKEN α=0.5] Processed 10000/10000 users...\n",
      "\n",
      "Hybrid-BROKEN α=0.5 Metrics:  {'MRR': 0.332668373300345, 'AUC': 0.8519636363636364, 'HR@5': 0.4645, 'nDCG@5': 0.33876840811704356, 'HR@10': 0.6056, 'nDCG@10': 0.38437122165451937}\n",
      "\n",
      "2. FIXED hybrid (with min-max normalization):\n",
      "   This properly balances CF and content contributions\n",
      "[Hybrid-FIXED α=0.5] Processed 1000/10000 users...\n",
      "[Hybrid-FIXED α=0.5] Processed 2000/10000 users...\n",
      "[Hybrid-FIXED α=0.5] Processed 3000/10000 users...\n",
      "[Hybrid-FIXED α=0.5] Processed 4000/10000 users...\n",
      "[Hybrid-FIXED α=0.5] Processed 5000/10000 users...\n",
      "[Hybrid-FIXED α=0.5] Processed 6000/10000 users...\n",
      "[Hybrid-FIXED α=0.5] Processed 7000/10000 users...\n",
      "[Hybrid-FIXED α=0.5] Processed 8000/10000 users...\n",
      "[Hybrid-FIXED α=0.5] Processed 9000/10000 users...\n",
      "[Hybrid-FIXED α=0.5] Processed 10000/10000 users...\n",
      "\n",
      "Hybrid-FIXED α=0.5 Metrics:  {'MRR': 0.39150917279707936, 'AUC': 0.8593989898989899, 'HR@5': 0.5169, 'nDCG@5': 0.39929595199386825, 'HR@10': 0.6402, 'nDCG@10': 0.43902691659345894}\n",
      "\n",
      "======================================================================\n",
      "COMPARISON\n",
      "======================================================================\n",
      "Model                     HR@10      nDCG@10    Difference     \n",
      "----------------------------------------------------------------------\n",
      "Content-Only              0.4503     0.2888    \n",
      "CF-Only                   0.6043     0.3828    \n",
      "Hybrid-BROKEN (α=0.5)     0.6056     0.3844     ← Just CF!     \n",
      "Hybrid-FIXED (α=0.5)      0.6402     0.4390     ← Actual hybrid!\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "FINDING BEST ALPHA (using FIXED hybrid)\n",
      "======================================================================\n",
      "\n",
      "Testing alpha=0.0...\n",
      "[Hybrid-FIXED α=0.0] Processed 1000/10000 users...\n",
      "[Hybrid-FIXED α=0.0] Processed 2000/10000 users...\n",
      "[Hybrid-FIXED α=0.0] Processed 3000/10000 users...\n",
      "[Hybrid-FIXED α=0.0] Processed 4000/10000 users...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_hybrid_gpu_FIXED(\n",
    "    alpha=0.5,\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    seed=42,\n",
    "    name=None\n",
    "):\n",
    "    \"\"\"\n",
    "    FIXED hybrid model with min-max normalization.\n",
    "    This ensures CF and content contributions are balanced.\n",
    "    \"\"\"\n",
    "    if name is None:\n",
    "        name = f\"Hybrid-Fixed α={alpha}\"\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    eligible_users = [\n",
    "        u for u in user2val_pos.keys()\n",
    "        if u in user_emb_cb and u < num_users_cf and len(user2val_pos[u]) > 0\n",
    "    ]\n",
    "    rng.shuffle(eligible_users)\n",
    "    sampled_users = eligible_users[:min(N_USERS_SAMPLE, len(eligible_users))]\n",
    "    \n",
    "    hit_vals = {k: [] for k in Ks}\n",
    "    ndcg_vals = {k: [] for k in Ks}\n",
    "    mrr_list = []\n",
    "    auc_list = []\n",
    "    \n",
    "    for idx, u in enumerate(sampled_users):\n",
    "        pos_items = user2val_pos[u]\n",
    "        if len(pos_items) == 0:\n",
    "            continue\n",
    "        \n",
    "        pos_item = pos_items[-1]\n",
    "        if pos_item > max_item_id or pos_item >= num_items_cf:\n",
    "            continue\n",
    "        \n",
    "        user_seen = user2all_items[u]\n",
    "        candidate_negs = [\n",
    "            i for i in all_val_items\n",
    "            if i not in user_seen and i <= max_item_id and i < num_items_cf\n",
    "        ]\n",
    "        if len(candidate_negs) == 0:\n",
    "            continue\n",
    "        \n",
    "        if len(candidate_negs) > N_NEG:\n",
    "            neg_items = rng.choice(candidate_negs, size=N_NEG, replace=False)\n",
    "        else:\n",
    "            neg_items = np.array(candidate_negs, dtype=np.int64)\n",
    "        \n",
    "        candidates = np.concatenate([[pos_item], neg_items])\n",
    "        labels = np.zeros(len(candidates), dtype=np.int32)\n",
    "        labels[0] = 1\n",
    "        \n",
    "        cand_idx = torch.tensor(candidates, dtype=torch.long, device=device)\n",
    "        \n",
    "        # ---- Content-based scores ----\n",
    "        u_cb_vec = torch.tensor(user_emb_cb[u], dtype=torch.float32, device=device)\n",
    "        item_cb_vecs = item_emb_torch[cand_idx]\n",
    "        scores_cb_t = item_cb_vecs @ u_cb_vec\n",
    "        scores_cb = scores_cb_t.detach().cpu().numpy()\n",
    "        \n",
    "        # ---- CF scores ----\n",
    "        u_cf_vec = user_cf_emb_torch[u]\n",
    "        item_cf_vecs = item_cf_emb_torch[cand_idx]\n",
    "        scores_cf_t = item_cf_vecs @ u_cf_vec\n",
    "        scores_cf = scores_cf_t.detach().cpu().numpy()\n",
    "        \n",
    "        # ---- MIN-MAX NORMALIZATION (CRITICAL!) ----\n",
    "        # Scale both to [0, 1] so they contribute equally\n",
    "        \n",
    "        cf_min, cf_max = scores_cf.min(), scores_cf.max()\n",
    "        if cf_max > cf_min:\n",
    "            scores_cf_norm = (scores_cf - cf_min) / (cf_max - cf_min)\n",
    "        else:\n",
    "            scores_cf_norm = np.zeros_like(scores_cf)\n",
    "        \n",
    "        cb_min, cb_max = scores_cb.min(), scores_cb.max()\n",
    "        if cb_max > cb_min:\n",
    "            scores_cb_norm = (scores_cb - cb_min) / (cb_max - cb_min)\n",
    "        else:\n",
    "            scores_cb_norm = np.zeros_like(scores_cb)\n",
    "        \n",
    "        # ---- COMBINE (now both are on [0, 1] scale!) ----\n",
    "        scores = alpha * scores_cf_norm + (1.0 - alpha) * scores_cb_norm\n",
    "        \n",
    "        # ---- Metrics ----\n",
    "        for k in Ks:\n",
    "            hit_vals[k].append(hit_at_k(labels, scores, k))\n",
    "            ndcg_vals[k].append(ndcg_at_k(labels, scores, k))\n",
    "        \n",
    "        mrr_list.append(mrr_single(labels, scores))\n",
    "        auc_val = auc_single(labels, scores)\n",
    "        if not np.isnan(auc_val):\n",
    "            auc_list.append(auc_val)\n",
    "        \n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            print(f\"[{name}] Processed {idx+1}/{len(sampled_users)} users...\")\n",
    "    \n",
    "    mrr = float(np.mean(mrr_list)) if mrr_list else 0.0\n",
    "    auc = float(np.mean(auc_list)) if auc_list else 0.0\n",
    "    \n",
    "    metrics = {\n",
    "        \"MRR\": mrr,\n",
    "        \"AUC\": auc,\n",
    "    }\n",
    "    for k in Ks:\n",
    "        metrics[f\"HR@{k}\"] = float(np.mean(hit_vals[k])) if hit_vals[k] else 0.0\n",
    "        metrics[f\"nDCG@{k}\"] = float(np.mean(ndcg_vals[k])) if ndcg_vals[k] else 0.0\n",
    "    \n",
    "    print(f\"\\n{name} Metrics: \", metrics)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# COMPARE: BROKEN vs FIXED\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARING BROKEN vs FIXED HYBRID\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. Your ORIGINAL hybrid (without normalization):\")\n",
    "print(\"   This is BROKEN - CF dominates due to 203x score difference\")\n",
    "hyb_broken = evaluate_hybrid_gpu(\n",
    "    alpha=0.5,\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    seed=42,\n",
    "    name=\"Hybrid-BROKEN α=0.5\"\n",
    ")\n",
    "\n",
    "print(\"\\n2. FIXED hybrid (with min-max normalization):\")\n",
    "print(\"   This properly balances CF and content contributions\")\n",
    "hyb_fixed = evaluate_hybrid_gpu_FIXED(\n",
    "    alpha=0.5,\n",
    "    N_USERS_SAMPLE=10000,\n",
    "    N_NEG=99,\n",
    "    Ks=(5, 10),\n",
    "    seed=42,\n",
    "    name=\"Hybrid-FIXED α=0.5\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<25} {'HR@10':<10} {'nDCG@10':<10} {'Difference':<15}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Content-Only':<25} {0.4503:<10.4f} {0.2888:<10.4f}\")\n",
    "print(f\"{'CF-Only':<25} {0.6043:<10.4f} {0.3828:<10.4f}\")\n",
    "print(f\"{'Hybrid-BROKEN (α=0.5)':<25} {hyb_broken['HR@10']:<10.4f} {hyb_broken['nDCG@10']:<10.4f} {'← Just CF!':<15}\")\n",
    "print(f\"{'Hybrid-FIXED (α=0.5)':<25} {hyb_fixed['HR@10']:<10.4f} {hyb_fixed['nDCG@10']:<10.4f} {'← Actual hybrid!':<15}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prediction: BROKEN will be ≈0.60 (same as CF)\n",
    "#             FIXED will be ≈0.52-0.58 (actually between CF and content)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FIND BEST ALPHA (with FIXED version)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINDING BEST ALPHA (using FIXED hybrid)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "alphas = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(f\"\\nTesting alpha={alpha:.1f}...\")\n",
    "    metrics = evaluate_hybrid_gpu_FIXED(\n",
    "        alpha=alpha,\n",
    "        N_USERS_SAMPLE=10000,\n",
    "        N_NEG=99,\n",
    "        Ks=(5, 10),\n",
    "        seed=42,\n",
    "        name=f\"Hybrid-FIXED α={alpha:.1f}\"\n",
    "    )\n",
    "    results.append({\n",
    "        'alpha': alpha,\n",
    "        'HR@10': metrics['HR@10'],\n",
    "        'nDCG@10': metrics['nDCG@10'],\n",
    "        'MRR': metrics['MRR']\n",
    "    })\n",
    "\n",
    "# Print results table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALPHA SENSITIVITY ANALYSIS (FIXED HYBRID)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Alpha':<10} {'HR@10':<12} {'nDCG@10':<12} {'MRR':<12} {'Notes':<20}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "best_hr = max(results, key=lambda x: x['HR@10'])\n",
    "\n",
    "for r in results:\n",
    "    marker = \" ← BEST\" if r == best_hr else \"\"\n",
    "    note = \"\"\n",
    "    if r['alpha'] == 0.0:\n",
    "        note = \"(Content only)\"\n",
    "    elif r['alpha'] == 1.0:\n",
    "        note = \"(CF only)\"\n",
    "    \n",
    "    print(f\"{r['alpha']:<10.1f} \"\n",
    "          f\"{r['HR@10']:<12.4f} \"\n",
    "          f\"{r['nDCG@10']:<12.4f} \"\n",
    "          f\"{r['MRR']:<12.4f} \"\n",
    "          f\"{note:<20}{marker}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n✅ Best alpha: {best_hr['alpha']:.1f} with HR@10 = {best_hr['HR@10']:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5283e296-ade1-46ae-b3a4-9e8b79136afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
