{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a48670",
   "metadata": {},
   "source": [
    "### Leave-Last-Out Splitting\n",
    "A data-splitting strategy to pick up the lastest two item interactions for evaluation. This strategy is widely used in many recommendation papers.\n",
    "\n",
    "Specially, given a chronological user interaction sequence of length N:\n",
    "\n",
    "Training part: the first N-2 items;\n",
    "\n",
    "Validation part: the (N-1)-th item;\n",
    "\n",
    "Testing part: the N-th item. In this case N = 5. \n",
    "\n",
    "\n",
    "Using the presupplied Train, Validation and Test sets encourages consistent RecSys benchmarks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6307d",
   "metadata": {},
   "source": [
    "Notes: Must combine train, eval, and test sets in this order for the SasRecDataSet() initialization to work. The initialization with a filename expects the train, eval and test data to be in one tsv file. It will take the last item as the test item for a given user and the second to last as the validation item for that user. \n",
    "<br>\n",
    "recommender requires that you have specific versions of certain packages, so you have to use a virtual environment to have the right package versions. For ex, tensorflow needs to be version 2.12.0. Python needs to be a version less than 3.11.9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2b58f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1446304000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1441260345000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1564770672</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1441260365000</td>\n",
       "      <td>1446304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1442450703</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1523093714024</td>\n",
       "      <td>1446304000 1564770672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1780671067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1611623223325</td>\n",
       "      <td>1446304000 1564770672 1442450703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1645671127</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1612044209266</td>\n",
       "      <td>1446304000 1564770672 1442450703 1780671067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id parent_asin  rating      timestamp  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1446304000     5.0  1441260345000   \n",
       "1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1564770672     5.0  1441260365000   \n",
       "2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1442450703     5.0  1523093714024   \n",
       "3  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1780671067     1.0  1611623223325   \n",
       "4  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1645671127     3.0  1612044209266   \n",
       "\n",
       "                                       history  \n",
       "0                                          NaN  \n",
       "1                                   1446304000  \n",
       "2                        1446304000 1564770672  \n",
       "3             1446304000 1564770672 1442450703  \n",
       "4  1446304000 1564770672 1442450703 1780671067  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "book_test_df = pd.read_csv('data/Books.test.csv.gz', compression='gzip', sep=',', header=0)\n",
    "book_val_df = pd.read_csv('data/Books.valid.csv.gz', compression='gzip', sep=',', header=0)\n",
    "book_train_df = pd.read_csv('data/Books.train.csv.gz', compression='gzip', sep=',', header=0)\n",
    "\n",
    "book_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4ce42c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (7935557, 5)\n",
      "Val Set:  (776370, 5)\n",
      "Test Set:  (776370, 5)\n",
      "                        user_id parent_asin  rating      timestamp  \\\n",
      "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  0593235657     5.0  1640629604904   \n",
      "1  AGKASBHYZPGTEPO6LWZPVJWB2BVA  0803736800     4.0  1454676557000   \n",
      "2  AGXFEGMNVCSTSYYA5UWXDV7AFSXA  1542046599     5.0  1605649719611   \n",
      "3  AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  0679450815     5.0  1638987703546   \n",
      "4  AHXBL3QDWZGJYH7A5CMPFNUPMF7Q  1250866448     5.0  1669414969335   \n",
      "\n",
      "                                             history  \n",
      "0  1446304000 1564770672 1442450703 1780671067 16...  \n",
      "1  0811849783 0803729952 0735336296 1508558884 08...  \n",
      "2        1578052009 1477493395 1594747350 1594749310  \n",
      "3  B00INIQVJA 1496407903 1974633225 B07KD27RHM 16...  \n",
      "4  0920668372 1589255208 2764322836 2764330898 00...  \n",
      "\n",
      "                        user_id parent_asin  rating      timestamp  \\\n",
      "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1782490671     5.0  1640383495102   \n",
      "1  AGKASBHYZPGTEPO6LWZPVJWB2BVA  0802737803     5.0  1454676232000   \n",
      "2  AGXFEGMNVCSTSYYA5UWXDV7AFSXA  1594749310     5.0  1541884305941   \n",
      "3  AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  1633573001     5.0  1612225279592   \n",
      "4  AHXBL3QDWZGJYH7A5CMPFNUPMF7Q  0451450523     2.0  1635710722120   \n",
      "\n",
      "                                             history  \n",
      "0  1446304000 1564770672 1442450703 1780671067 16...  \n",
      "1        0811849783 0803729952 0735336296 1508558884  \n",
      "2                   1578052009 1477493395 1594747350  \n",
      "3        B00INIQVJA 1496407903 1974633225 B07KD27RHM  \n",
      "4  0920668372 1589255208 2764322836 2764330898 00...  \n",
      "Unique Users:  776370\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set: \", book_train_df.shape)\n",
    "print(\"Val Set: \", book_val_df.shape)\n",
    "print(\"Test Set: \", book_test_df.shape)\n",
    "print(book_test_df.head())\n",
    "print()\n",
    "print(book_val_df.head())\n",
    "print(\"Unique Users: \", book_train_df['user_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4de3d1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
      "Tensorflow version: 2.12.0\n",
      "tensorflow version should be 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.datasets.amazon_reviews import get_review_data\n",
    "from recommenders.datasets.split_utils import filter_k_core\n",
    "from recommenders.models.sasrec.model import SASREC\n",
    "from recommenders.models.sasrec.ssept import SSEPT\n",
    "from recommenders.models.sasrec.sampler import WarpSampler\n",
    "from recommenders.models.sasrec.util import SASRecDataSet\n",
    "from recommenders.utils.notebook_utils import store_metadata\n",
    "from recommenders.utils.timer import Timer\n",
    "\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(\"tensorflow version should be 2.12.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db3802c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all interactions\n",
    "merged_df = pd.concat([book_train_df, book_val_df, book_test_df], ignore_index=True)\n",
    "\n",
    "# Make sure user/item IDs are integers starting from 1\n",
    "user_set = set(merged_df['user_id'])\n",
    "item_set = set(merged_df['parent_asin'])\n",
    "\n",
    "user_map = dict()\n",
    "item_map = dict()\n",
    "\n",
    "for u, user in enumerate(user_set):\n",
    "    user_map[user] = u+1\n",
    "\n",
    "for i, item in enumerate(item_set):\n",
    "    item_map[item] = i+1\n",
    "\n",
    "merged_df['user_id'] = merged_df['user_id'].map(user_map)\n",
    "merged_df['parent_asin'] = merged_df['parent_asin'].map(item_map)\n",
    "\n",
    "# Sort by user and timestamp\n",
    "merged_df = merged_df.sort_values(['user_id', 'timestamp'])\n",
    "\n",
    "# Keep only the columns SASRecDataset expects\n",
    "merged_df = merged_df[['user_id', 'parent_asin']]\n",
    "\n",
    "# Save to a single TSV\n",
    "merged_df.to_csv(\"data/book_all.tsv\", sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#combine prebuilt benchmarking test, train and eval sets to change user_id strings to actual integers \n",
    "merged_df = pd.concat([book_train_df, book_val_df, book_test_df], ignore_index=True)\n",
    "\n",
    "user_set, item_set = set(merged_df['user_id'].unique()), set(merged_df['parent_asin'].unique())\n",
    "\n",
    "user_map = dict()\n",
    "item_map = dict()\n",
    "\n",
    "for u, user in enumerate(user_set):\n",
    "    user_map[user] = u+1\n",
    "for i, item in enumerate(item_set):\n",
    "    item_map[item] = i+1\n",
    "\n",
    "#changing each user_id column in each dataset to its integer mapping\n",
    "book_train_df['user_id'] = book_train_df['user_id'].apply(lambda x: user_map[x])\n",
    "book_train_df['parent_asin'] = book_train_df['parent_asin'].apply(lambda x: item_map[x])\n",
    "book_val_df['user_id'] = book_val_df['user_id'].apply(lambda x: user_map[x])\n",
    "book_val_df['parent_asin'] = book_val_df['parent_asin'].apply(lambda x: item_map[x])\n",
    "book_test_df['user_id'] = book_test_df['user_id'].apply(lambda x: user_map[x])\n",
    "book_test_df['parent_asin'] = book_test_df['parent_asin'].apply(lambda x: item_map[x])\n",
    "\n",
    "book_train_df = book_train_df.sort_values(by=[\"user_id\", \"timestamp\"])\n",
    "book_val_df = book_val_df.sort_values(by=[\"user_id\", \"timestamp\"])\n",
    "book_test_df = book_test_df.sort_values(by=[\"user_id\", \"timestamp\"])\n",
    "\n",
    "book_train_df.drop(columns=[\"timestamp\", \"history\", \"rating\"], inplace=True)\n",
    "book_val_df.drop(columns=[\"timestamp\", \"history\", \"rating\"], inplace=True)\n",
    "book_test_df.drop(columns=[\"timestamp\", \"history\", \"rating\"], inplace=True)\n",
    "\n",
    "book_train_df.to_csv(\"data/book_train.tsv\", sep = \"\\t\", header=False, index=False)\n",
    "book_val_df.to_csv(\"data/book_val.tsv\", sep = \"\\t\", header=False, index=False)\n",
    "book_test_df.to_csv(\"data/book_test.tsv\", sep = \"\\t\", header=False, index=False)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f0f7670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 776370\n",
      "Number of items: 495063\n",
      "Number of valid users for evaluation: 776370\n"
     ]
    }
   ],
   "source": [
    "from recommenders.models.sasrec.util import SASRecDataSet\n",
    "from recommenders.models.sasrec.model import SASREC\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "seed = 100  # Set None for non-deterministic result\n",
    "\n",
    "lr = 0.001             # learning rate\n",
    "maxlen = 50            # maximum sequence length for each user\n",
    "num_blocks = 2         # number of transformer blocks\n",
    "hidden_units = 100     # number of units in the attention calculation\n",
    "num_heads = 1          # number of attention heads\n",
    "dropout_rate = 0.1     # dropout rate\n",
    "l2_emb = 0.0           # L2 regularization coefficient\n",
    "num_neg_test = 100     # number of negative examples per positive example\n",
    "\n",
    "dataset = SASRecDataSet(filename=\"data/book_all.tsv\", col_sep=\"\\t\")\n",
    "dataset.split()\n",
    "\n",
    "model = SASREC(item_num=dataset.itemnum,\n",
    "                   seq_max_len=maxlen,\n",
    "                   num_blocks=num_blocks,\n",
    "                   embedding_dim=hidden_units,\n",
    "                   attention_dim=hidden_units,\n",
    "                   attention_num_heads=num_heads,\n",
    "                   dropout_rate=dropout_rate,\n",
    "                   conv_dims = [100, 100],\n",
    "                   l2_reg=l2_emb,\n",
    "                   num_neg_test=num_neg_test\n",
    ")\n",
    "\n",
    "print(\"Number of users:\", dataset.usernum)\n",
    "print(\"Number of items:\", dataset.itemnum)\n",
    "print(\"Number of valid users for evaluation:\", len(dataset.user_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0b4a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WarpSampler(dataset.user_train, dataset.usernum, dataset.itemnum, batch_size=batch_size, maxlen=maxlen, n_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8afb9ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Timer() \u001b[38;5;28;01mas\u001b[39;00m train_time:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     t_test = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mTime cost for training is \u001b[39m\u001b[38;5;132;01m{0:.2f}\u001b[39;00m\u001b[33m mins\u001b[39m\u001b[33m'\u001b[39m.format(train_time.interval/\u001b[32m60.0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\recommenders\\models\\sasrec\\model.py:701\u001b[39m, in \u001b[36mSASREC.train\u001b[39m\u001b[34m(self, dataset, sampler, **kwargs)\u001b[39m\n\u001b[32m    697\u001b[39m     u, seq, pos, neg = sampler.next_batch()\n\u001b[32m    699\u001b[39m     inputs, target = \u001b[38;5;28mself\u001b[39m.create_combined_dataset(u, seq, pos, neg)\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m     loss = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m     step_loss.append(loss)\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch % val_epoch == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    891\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    897\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    923\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    924\u001b[39m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[32m    925\u001b[39m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    928\u001b[39m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[32m    929\u001b[39m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[32m    930\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[39m, in \u001b[36mTracingCompiler.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m    141\u001b[39m   (concrete_function,\n\u001b[32m    142\u001b[39m    filtered_flat_args) = \u001b[38;5;28mself\u001b[39m._maybe_define_function(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconcrete_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, args, captured_inputs, cancellation_manager)\u001b[39m\n\u001b[32m   1753\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1755\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1756\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1757\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1758\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1759\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1760\u001b[39m     args,\n\u001b[32m   1761\u001b[39m     possible_gradient_type,\n\u001b[32m   1762\u001b[39m     executing_eagerly)\n\u001b[32m   1763\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[39m, in \u001b[36m_EagerDefinedFunction.call\u001b[39m\u001b[34m(self, ctx, args, cancellation_manager)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    380\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m     outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    388\u001b[39m     outputs = execute.execute_with_cancellation(\n\u001b[32m    389\u001b[39m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.signature.name),\n\u001b[32m    390\u001b[39m         num_outputs=\u001b[38;5;28mself\u001b[39m._num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m    393\u001b[39m         ctx=ctx,\n\u001b[32m    394\u001b[39m         cancellation_manager=cancellation_manager)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     51\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     55\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    t_test = model.train(dataset, sampler, num_epochs=num_epochs, batch_size=batch_size, lr=lr, val_epoch=6)\n",
    "\n",
    "print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cd37789",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res_syn = {\u001b[33m\"\u001b[39m\u001b[33mndcg@10\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mt_test\u001b[49m[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mHit@10\u001b[39m\u001b[33m\"\u001b[39m: t_test[\u001b[32m1\u001b[39m]}\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(res_syn)\n",
      "\u001b[31mNameError\u001b[39m: name 't_test' is not defined"
     ]
    }
   ],
   "source": [
    "res_syn = {\"ndcg@10\": t_test[0], \"Hit@10\": t_test[1]}\n",
    "print(res_syn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
