{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a48670",
   "metadata": {},
   "source": [
    "### Leave-Last-Out Splitting\n",
    "A data-splitting strategy to pick up the lastest two item interactions for evaluation. This strategy is widely used in many recommendation papers.\n",
    "\n",
    "Specially, given a chronological user interaction sequence of length N:\n",
    "\n",
    "Training part: the first N-2 items;\n",
    "\n",
    "Validation part: the (N-1)-th item;\n",
    "\n",
    "Testing part: the N-th item. In this case N = 5. \n",
    "\n",
    "\n",
    "Using the presupplied Train, Validation and Test sets encourages consistent RecSys benchmarks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6307d",
   "metadata": {},
   "source": [
    "Notes: Must combine train, eval, and test sets in this order for the SasRecDataSet() initialization to work. The initialization with a filename expects the train, eval and test data to be in one tsv file. It will take the last item as the test item for a given user and the second to last as the validation item for that user. \n",
    "<br>\n",
    "recommender requires that you have specific versions of certain packages, so you have to use a virtual environment to have the right package versions. For ex, tensorflow needs to be version 2.12.0. Python needs to be a version less than 3.11.9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad2b58f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1446304000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1441260345000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1564770672</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1441260365000</td>\n",
       "      <td>1446304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1442450703</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1523093714024</td>\n",
       "      <td>1446304000 1564770672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1780671067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1611623223325</td>\n",
       "      <td>1446304000 1564770672 1442450703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1645671127</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1612044209266</td>\n",
       "      <td>1446304000 1564770672 1442450703 1780671067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id parent_asin  rating      timestamp  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1446304000     5.0  1441260345000   \n",
       "1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1564770672     5.0  1441260365000   \n",
       "2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1442450703     5.0  1523093714024   \n",
       "3  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1780671067     1.0  1611623223325   \n",
       "4  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1645671127     3.0  1612044209266   \n",
       "\n",
       "                                       history  \n",
       "0                                          NaN  \n",
       "1                                   1446304000  \n",
       "2                        1446304000 1564770672  \n",
       "3             1446304000 1564770672 1442450703  \n",
       "4  1446304000 1564770672 1442450703 1780671067  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "book_test_df = pd.read_csv('data/Books.test.csv.gz', compression='gzip', sep=',', header=0)\n",
    "book_val_df = pd.read_csv('data/Books.valid.csv.gz', compression='gzip', sep=',', header=0)\n",
    "book_train_df = pd.read_csv('data/Books.train.csv.gz', compression='gzip', sep=',', header=0)\n",
    "\n",
    "book_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a4ce42c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (7935557, 5)\n",
      "Val Set:  (776370, 5)\n",
      "Test Set:  (776370, 5)\n",
      "                        user_id parent_asin  rating      timestamp  \\\n",
      "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  0593235657     5.0  1640629604904   \n",
      "1  AGKASBHYZPGTEPO6LWZPVJWB2BVA  0803736800     4.0  1454676557000   \n",
      "2  AGXFEGMNVCSTSYYA5UWXDV7AFSXA  1542046599     5.0  1605649719611   \n",
      "3  AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  0679450815     5.0  1638987703546   \n",
      "4  AHXBL3QDWZGJYH7A5CMPFNUPMF7Q  1250866448     5.0  1669414969335   \n",
      "\n",
      "                                             history  \n",
      "0  1446304000 1564770672 1442450703 1780671067 16...  \n",
      "1  0811849783 0803729952 0735336296 1508558884 08...  \n",
      "2        1578052009 1477493395 1594747350 1594749310  \n",
      "3  B00INIQVJA 1496407903 1974633225 B07KD27RHM 16...  \n",
      "4  0920668372 1589255208 2764322836 2764330898 00...  \n",
      "\n",
      "                        user_id parent_asin  rating      timestamp  \\\n",
      "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1782490671     5.0  1640383495102   \n",
      "1  AGKASBHYZPGTEPO6LWZPVJWB2BVA  0802737803     5.0  1454676232000   \n",
      "2  AGXFEGMNVCSTSYYA5UWXDV7AFSXA  1594749310     5.0  1541884305941   \n",
      "3  AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  1633573001     5.0  1612225279592   \n",
      "4  AHXBL3QDWZGJYH7A5CMPFNUPMF7Q  0451450523     2.0  1635710722120   \n",
      "\n",
      "                                             history  \n",
      "0  1446304000 1564770672 1442450703 1780671067 16...  \n",
      "1        0811849783 0803729952 0735336296 1508558884  \n",
      "2                   1578052009 1477493395 1594747350  \n",
      "3        B00INIQVJA 1496407903 1974633225 B07KD27RHM  \n",
      "4  0920668372 1589255208 2764322836 2764330898 00...  \n",
      "Unique Users in Train set:  776370\n",
      "Unique Users in Test set:  776370\n",
      "Unique Users in eval set:  776370\n",
      "                             user_id parent_asin  rating      timestamp  \\\n",
      "776365  AGNKVZGDVXCB2VUXSEZELY22WICA  1449007945     5.0  1257527532000   \n",
      "776366  AFQ5IENJ2URIIK4A6HW7GDUIBGZQ  0399162097     5.0  1383957911000   \n",
      "776367  AEWDTEKLGUAZYBTDQDED4WZ5PECQ  0471190454     1.0  1190542653000   \n",
      "776368  AGVUBY43MX4PETNFTXL2CBGLJJSQ  1849701903     5.0  1369038019000   \n",
      "776369  AGZ44L7OCCLE76RJOZ3VGKOEKLFQ  0500016909     2.0  1103970985000   \n",
      "\n",
      "                                            history  \n",
      "776365             0060734973 0312340990 034549962X  \n",
      "776366             0761536604 160239055X 0061874337  \n",
      "776367  0812575717 0375421815 0130661899 0140143599  \n",
      "776368  1849700893 1849701822 1849701539 1849703477  \n",
      "776369             0743259823 0891230513 0891230483  \n",
      "                             user_id parent_asin  rating      timestamp  \\\n",
      "776365  AGNKVZGDVXCB2VUXSEZELY22WICA  074326357X     5.0  1257528066000   \n",
      "776366  AFQ5IENJ2URIIK4A6HW7GDUIBGZQ  1401941044     5.0  1383958713000   \n",
      "776367  AEWDTEKLGUAZYBTDQDED4WZ5PECQ  0985420391     5.0  1496795397000   \n",
      "776368  AGVUBY43MX4PETNFTXL2CBGLJJSQ  161614839X     5.0  1407998866000   \n",
      "776369  AGZ44L7OCCLE76RJOZ3VGKOEKLFQ  0890963908     5.0  1103974463000   \n",
      "\n",
      "                                                  history  \n",
      "776365        0060734973 0312340990 034549962X 1449007945  \n",
      "776366        0761536604 160239055X 0061874337 0399162097  \n",
      "776367  0812575717 0375421815 0130661899 0140143599 04...  \n",
      "776368  1849700893 1849701822 1849701539 1849703477 18...  \n",
      "776369        0743259823 0891230513 0891230483 0500016909  \n"
     ]
    }
   ],
   "source": [
    "print(\"Training set: \", book_train_df.shape)\n",
    "print(\"Val Set: \", book_val_df.shape)\n",
    "print(\"Test Set: \", book_test_df.shape)\n",
    "print(book_test_df.head())\n",
    "print()\n",
    "print(book_val_df.head())\n",
    "print(\"Unique Users in Train set: \", book_train_df['user_id'].nunique())\n",
    "print(\"Unique Users in Test set: \", book_test_df['user_id'].nunique())\n",
    "print(\"Unique Users in eval set: \", book_val_df['user_id'].nunique())\n",
    "print(book_val_df.tail())\n",
    "print(book_test_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4de3d1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]\n",
      "Tensorflow version: 2.12.0\n",
      "tensorflow version should be 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.datasets.split_utils import filter_k_core\n",
    "from recommenders.models.sasrec.model import SASREC\n",
    "from recommenders.models.sasrec.sampler import WarpSampler\n",
    "from recommenders.models.sasrec.util import SASRecDataSet\n",
    "from recommenders.utils.timer import Timer\n",
    "\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(\"tensorflow version should be 2.12.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db3802c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id  parent_asin  rating      timestamp  \\\n",
      "8788732   511536       339407     4.0  1370651952000   \n",
      "981274    511536       478989     5.0  1326679671000   \n",
      "981273    511536        75444     5.0  1320025983000   \n",
      "981272    511536       136532     5.0  1318089668000   \n",
      "981271    511536        33860     5.0  1259456701000   \n",
      "\n",
      "                                                   history  \n",
      "8788732  0061058386 0441008534 0441009239 0375826688 B0...  \n",
      "981274   0061058386 0441008534 0441009239 0375826688 B0...  \n",
      "981273   0061058386 0441008534 0441009239 0375826688 B0...  \n",
      "981272   0061058386 0441008534 0441009239 0375826688 B0...  \n",
      "981271   0061058386 0441008534 0441009239 0375826688 B0...  \n"
     ]
    }
   ],
   "source": [
    "# Combine all interactions\n",
    "merged_df = pd.concat([book_train_df, book_val_df, book_test_df], ignore_index=True)\n",
    "\n",
    "merged_df.rename(columns={'user_id': 'userID', 'parent_asin': 'itemID'}, inplace=True) #filter_k_core function needs these column names\n",
    "merged_df = filter_k_core(merged_df, core_num=5)  # filter for users & items with less than 5 interactions\n",
    "merged_df.rename(columns={'userID': 'user_id', 'itemID': 'parent_asin'}, inplace=True) #change column names back\n",
    "\n",
    "# Make sure user/item IDs are integers starting from 1\n",
    "user_set = set(merged_df['user_id'].unique())\n",
    "item_set = set(merged_df['parent_asin'].unique())\n",
    "\n",
    "user_map = dict()\n",
    "item_map = dict()\n",
    "\n",
    "for u, user in enumerate(user_set):\n",
    "    user_map[user] = u+1\n",
    "\n",
    "for i, item in enumerate(item_set):\n",
    "    item_map[item] = i+1\n",
    "\n",
    "merged_df['user_id'] = merged_df['user_id'].map(user_map)\n",
    "merged_df['parent_asin'] = merged_df['parent_asin'].map(item_map)\n",
    "print(merged_df.head())\n",
    "\n",
    "# Sort by user and timestamp\n",
    "merged_df = merged_df.sort_values(['user_id', 'timestamp'])\n",
    "\n",
    "# Keep only the columns SASRecDataset expects\n",
    "merged_df = merged_df[['user_id', 'parent_asin']]\n",
    "\n",
    "# Save to a single TSV\n",
    "merged_df.to_csv(\"data/book_all.tsv\", sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c52e66db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id  parent_asin\n",
      "809923         1       239875\n",
      "809924         1       379341\n",
      "809925         1       145023\n",
      "809926         1       457361\n",
      "809927         1        12560\n",
      "7999344        1       412574\n",
      "8775714        1        83393\n",
      "5081006        2       471080\n",
      "5081007        2       223094\n",
      "5081008        2       136158\n"
     ]
    }
   ],
   "source": [
    "#print(\"Merged Df Length: \", len(merged_df))\n",
    "print(merged_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f0f7670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 776370\n",
      "Number of items: 495063\n",
      "Number of valid users for evaluation: 776370\n",
      "776370 Users and 495063 items\n",
      "average sequence length: 10.22\n"
     ]
    }
   ],
   "source": [
    "from recommenders.models.sasrec.util import SASRecDataSet\n",
    "from recommenders.models.sasrec.model import SASREC\n",
    "\n",
    "num_epochs = 1\n",
    "batch_size = 128\n",
    "\n",
    "lr = 0.001             # learning rate\n",
    "maxlen = 5            # maximum sequence length for each user\n",
    "num_blocks = 2         # number of transformer blocks\n",
    "hidden_units = 25     # number of units in the attention calculation\n",
    "num_heads = 1          # number of attention heads\n",
    "dropout_rate = 0.1     # dropout rate\n",
    "l2_emb = 0.0           # L2 regularization coefficient\n",
    "num_neg_test = 3     # number of negative examples per positive example\n",
    "\n",
    "dataset = SASRecDataSet(filename=\"data/book_all.tsv\", col_sep=\"\\t\")\n",
    "dataset.split()\n",
    "\n",
    "model = SASREC(item_num=dataset.itemnum,\n",
    "                   seq_max_len=maxlen,\n",
    "                   num_blocks=num_blocks,\n",
    "                   embedding_dim=hidden_units,\n",
    "                   attention_dim=hidden_units,\n",
    "                   attention_num_heads=num_heads,\n",
    "                   dropout_rate=dropout_rate,\n",
    "                   conv_dims = [25, 25],\n",
    "                   l2_reg=l2_emb,\n",
    "                   num_neg_test=num_neg_test\n",
    ")\n",
    "\n",
    "print(\"Number of users:\", dataset.usernum)\n",
    "print(\"Number of items:\", dataset.itemnum)\n",
    "print(\"Number of valid users for evaluation:\", len(dataset.user_valid))\n",
    "\n",
    "# some statistics\n",
    "num_steps = int(len(dataset.user_train) / batch_size)\n",
    "cc = 0.0\n",
    "for u in dataset.user_train:\n",
    "    cc += len(dataset.user_train[u])\n",
    "print('%g Users and %g items' % (dataset.usernum, dataset.itemnum))\n",
    "print('average sequence length: %.2f' % (cc / len(dataset.user_train)))\n",
    "\n",
    "sampler = WarpSampler(dataset.user_train, dataset.usernum, dataset.itemnum, batch_size=batch_size, maxlen=5, n_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8afb9ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1, test (NDCG@10: 0.8043065594663199, HR@10: 1.0)\n",
      "Time cost for training is 13.88 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    t_test = model.train(dataset, sampler, num_epochs=num_epochs, batch_size=batch_size, lr=lr, val_epoch=5)\n",
    "\n",
    "print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3cd37789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ndcg@10': 0.8043065594663199, 'Hit@10': 1.0}\n"
     ]
    }
   ],
   "source": [
    "res_syn = {\"ndcg@10\": t_test[0], \"Hit@10\": t_test[1]}\n",
    "print(res_syn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3340037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8163455807267926, 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "print(model.evaluate_valid(dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sasenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
