{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a48670",
   "metadata": {},
   "source": [
    "### Leave-Last-Out Splitting\n",
    "A data-splitting strategy to pick up the lastest two item interactions for evaluation. This strategy is widely used in many recommendation papers.\n",
    "\n",
    "Specially, given a chronological user interaction sequence of length N:\n",
    "\n",
    "Training part: the first N-2 items;\n",
    "\n",
    "Validation part: the (N-1)-th item;\n",
    "\n",
    "Testing part: the N-th item. In this case N = 5. \n",
    "\n",
    "\n",
    "Using the presupplied Train, Validation and Test sets encourages consistent RecSys benchmarks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad2b58f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1446304000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1441260345000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1564770672</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1441260365000</td>\n",
       "      <td>1446304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1442450703</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1523093714024</td>\n",
       "      <td>1446304000 1564770672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1780671067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1611623223325</td>\n",
       "      <td>1446304000 1564770672 1442450703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1645671127</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1612044209266</td>\n",
       "      <td>1446304000 1564770672 1442450703 1780671067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id parent_asin  rating      timestamp  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1446304000     5.0  1441260345000   \n",
       "1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1564770672     5.0  1441260365000   \n",
       "2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1442450703     5.0  1523093714024   \n",
       "3  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1780671067     1.0  1611623223325   \n",
       "4  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1645671127     3.0  1612044209266   \n",
       "\n",
       "                                       history  \n",
       "0                                          NaN  \n",
       "1                                   1446304000  \n",
       "2                        1446304000 1564770672  \n",
       "3             1446304000 1564770672 1442450703  \n",
       "4  1446304000 1564770672 1442450703 1780671067  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "book_test_df = pd.read_csv('data/Books.test.csv.gz', compression='gzip', sep=',', header=0)\n",
    "book_val_df = pd.read_csv('data/Books.valid.csv.gz', compression='gzip', sep=',', header=0)\n",
    "book_train_df = pd.read_csv('data/Books.train.csv.gz', compression='gzip', sep=',', header=0)\n",
    "\n",
    "book_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4ce42c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (7935557, 5)\n",
      "Val Set:  (776370, 5)\n",
      "Test Set:  (776370, 5)\n",
      "                        user_id parent_asin  rating      timestamp  \\\n",
      "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  0593235657     5.0  1640629604904   \n",
      "1  AGKASBHYZPGTEPO6LWZPVJWB2BVA  0803736800     4.0  1454676557000   \n",
      "2  AGXFEGMNVCSTSYYA5UWXDV7AFSXA  1542046599     5.0  1605649719611   \n",
      "3  AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  0679450815     5.0  1638987703546   \n",
      "4  AHXBL3QDWZGJYH7A5CMPFNUPMF7Q  1250866448     5.0  1669414969335   \n",
      "\n",
      "                                             history  \n",
      "0  1446304000 1564770672 1442450703 1780671067 16...  \n",
      "1  0811849783 0803729952 0735336296 1508558884 08...  \n",
      "2        1578052009 1477493395 1594747350 1594749310  \n",
      "3  B00INIQVJA 1496407903 1974633225 B07KD27RHM 16...  \n",
      "4  0920668372 1589255208 2764322836 2764330898 00...  \n",
      "\n",
      "                        user_id parent_asin  rating      timestamp  \\\n",
      "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1782490671     5.0  1640383495102   \n",
      "1  AGKASBHYZPGTEPO6LWZPVJWB2BVA  0802737803     5.0  1454676232000   \n",
      "2  AGXFEGMNVCSTSYYA5UWXDV7AFSXA  1594749310     5.0  1541884305941   \n",
      "3  AFWHJ6O3PV4JC7PVOJH6CPULO2KQ  1633573001     5.0  1612225279592   \n",
      "4  AHXBL3QDWZGJYH7A5CMPFNUPMF7Q  0451450523     2.0  1635710722120   \n",
      "\n",
      "                                             history  \n",
      "0  1446304000 1564770672 1442450703 1780671067 16...  \n",
      "1        0811849783 0803729952 0735336296 1508558884  \n",
      "2                   1578052009 1477493395 1594747350  \n",
      "3        B00INIQVJA 1496407903 1974633225 B07KD27RHM  \n",
      "4  0920668372 1589255208 2764322836 2764330898 00...  \n",
      "Unique Users:  776370\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set: \", book_train_df.shape)\n",
    "print(\"Val Set: \", book_val_df.shape)\n",
    "print(\"Test Set: \", book_test_df.shape)\n",
    "print(book_test_df.head())\n",
    "print()\n",
    "print(book_val_df.head())\n",
    "print(\"Unique Users: \", book_train_df['user_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4de3d1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
      "Tensorflow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.datasets.amazon_reviews import get_review_data\n",
    "from recommenders.datasets.split_utils import filter_k_core\n",
    "from recommenders.models.sasrec.model import SASREC\n",
    "from recommenders.models.sasrec.ssept import SSEPT\n",
    "from recommenders.models.sasrec.sampler import WarpSampler\n",
    "from recommenders.models.sasrec.util import SASRecDataSet\n",
    "from recommenders.utils.notebook_utils import store_metadata\n",
    "from recommenders.utils.timer import Timer\n",
    "\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db3802c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all interactions\n",
    "merged_df = pd.concat([book_train_df, book_val_df, book_test_df], ignore_index=True)\n",
    "\n",
    "# Make sure user/item IDs are integers starting from 1\n",
    "user_set = set(merged_df['user_id'])\n",
    "item_set = set(merged_df['parent_asin'])\n",
    "\n",
    "user_map = dict()\n",
    "item_map = dict()\n",
    "\n",
    "for u, user in enumerate(user_set):\n",
    "    user_map[user] = u+1\n",
    "\n",
    "for i, item in enumerate(item_set):\n",
    "    item_map[item] = i+1\n",
    "\n",
    "merged_df['user_id'] = merged_df['user_id'].map(user_map)\n",
    "merged_df['parent_asin'] = merged_df['parent_asin'].map(item_map)\n",
    "\n",
    "# Sort by user and timestamp\n",
    "merged_df = merged_df.sort_values(['user_id', 'timestamp'])\n",
    "\n",
    "# Keep only the columns SASRecDataset expects\n",
    "merged_df = merged_df[['user_id', 'parent_asin']]\n",
    "\n",
    "# Save to a single TSV\n",
    "merged_df.to_csv(\"data/book_all.tsv\", sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#combine prebuilt benchmarking test, train and eval sets to change user_id strings to actual integers \n",
    "merged_df = pd.concat([book_train_df, book_val_df, book_test_df], ignore_index=True)\n",
    "\n",
    "user_set, item_set = set(merged_df['user_id'].unique()), set(merged_df['parent_asin'].unique())\n",
    "\n",
    "user_map = dict()\n",
    "item_map = dict()\n",
    "\n",
    "for u, user in enumerate(user_set):\n",
    "    user_map[user] = u+1\n",
    "for i, item in enumerate(item_set):\n",
    "    item_map[item] = i+1\n",
    "\n",
    "#changing each user_id column in each dataset to its integer mapping\n",
    "book_train_df['user_id'] = book_train_df['user_id'].apply(lambda x: user_map[x])\n",
    "book_train_df['parent_asin'] = book_train_df['parent_asin'].apply(lambda x: item_map[x])\n",
    "book_val_df['user_id'] = book_val_df['user_id'].apply(lambda x: user_map[x])\n",
    "book_val_df['parent_asin'] = book_val_df['parent_asin'].apply(lambda x: item_map[x])\n",
    "book_test_df['user_id'] = book_test_df['user_id'].apply(lambda x: user_map[x])\n",
    "book_test_df['parent_asin'] = book_test_df['parent_asin'].apply(lambda x: item_map[x])\n",
    "\n",
    "book_train_df = book_train_df.sort_values(by=[\"user_id\", \"timestamp\"])\n",
    "book_val_df = book_val_df.sort_values(by=[\"user_id\", \"timestamp\"])\n",
    "book_test_df = book_test_df.sort_values(by=[\"user_id\", \"timestamp\"])\n",
    "\n",
    "book_train_df.drop(columns=[\"timestamp\", \"history\", \"rating\"], inplace=True)\n",
    "book_val_df.drop(columns=[\"timestamp\", \"history\", \"rating\"], inplace=True)\n",
    "book_test_df.drop(columns=[\"timestamp\", \"history\", \"rating\"], inplace=True)\n",
    "\n",
    "book_train_df.to_csv(\"data/book_train.tsv\", sep = \"\\t\", header=False, index=False)\n",
    "book_val_df.to_csv(\"data/book_val.tsv\", sep = \"\\t\", header=False, index=False)\n",
    "book_test_df.to_csv(\"data/book_test.tsv\", sep = \"\\t\", header=False, index=False)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f0f7670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 776370\n",
      "Number of items: 495063\n",
      "Number of valid users for evaluation: 776370\n"
     ]
    }
   ],
   "source": [
    "from recommenders.models.sasrec.util import SASRecDataSet\n",
    "from recommenders.models.sasrec.model import SASREC\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "seed = 100  # Set None for non-deterministic result\n",
    "\n",
    "lr = 0.001             # learning rate\n",
    "maxlen = 50            # maximum sequence length for each user\n",
    "num_blocks = 2         # number of transformer blocks\n",
    "hidden_units = 100     # number of units in the attention calculation\n",
    "num_heads = 1          # number of attention heads\n",
    "dropout_rate = 0.1     # dropout rate\n",
    "l2_emb = 0.0           # L2 regularization coefficient\n",
    "num_neg_test = 100     # number of negative examples per positive example\n",
    "\n",
    "dataset = SASRecDataSet(filename=\"data/book_all.tsv\", col_sep=\"\\t\")\n",
    "dataset.split()\n",
    "\n",
    "model = SASREC(item_num=dataset.itemnum,\n",
    "                   seq_max_len=maxlen,\n",
    "                   num_blocks=num_blocks,\n",
    "                   embedding_dim=hidden_units,\n",
    "                   attention_dim=hidden_units,\n",
    "                   attention_num_heads=num_heads,\n",
    "                   dropout_rate=dropout_rate,\n",
    "                   conv_dims = [110, 110],\n",
    "                   l2_reg=l2_emb,\n",
    "                   num_neg_test=num_neg_test\n",
    ")\n",
    "\n",
    "print(\"Number of users:\", dataset.usernum)\n",
    "print(\"Number of items:\", dataset.itemnum)\n",
    "print(\"Number of valid users for evaluation:\", len(dataset.user_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0b4a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WarpSampler(dataset.user_train, dataset.usernum, dataset.itemnum, batch_size=batch_size, maxlen=maxlen, n_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8afb9ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 0/6065 [00:00<?, ?b/s]c:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:1493: UserWarning: Layer 'sasrec_9' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: True (of type <class 'bool'>)''\n",
      "  warnings.warn(\n",
      "c:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'sasrec_9', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "                                                                      \r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\recommenders\\models\\sasrec\\model.py\", line 676, in train_step  *\n        pos_logits, neg_logits, loss_mask = self(inp, training=True)\n    File \"c:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\recommenders\\models\\sasrec\\model.py\", line 492, in call\n        seq_attention = self.encoder(seq_attention, training, mask)\n\n    ValueError: Exception encountered when calling SASREC.call().\n    \n    \u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: True (of type <class 'bool'>)\u001b[0m\n    \n    Arguments received by SASREC.call():\n      • x={'users': 'tf.Tensor(shape=(None, 1), dtype=int64)', 'input_seq': 'tf.Tensor(shape=(None, 50), dtype=int64)', 'positive': 'tf.Tensor(shape=(None, 50), dtype=int64)', 'negative': 'tf.Tensor(shape=(None, 50), dtype=int64)'}\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Timer() \u001b[38;5;28;01mas\u001b[39;00m train_time:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     t_test = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mTime cost for training is \u001b[39m\u001b[38;5;132;01m{0:.2f}\u001b[39;00m\u001b[33m mins\u001b[39m\u001b[33m'\u001b[39m.format(train_time.interval/\u001b[32m60.0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\recommenders\\models\\sasrec\\model.py:701\u001b[39m, in \u001b[36mSASREC.train\u001b[39m\u001b[34m(self, dataset, sampler, **kwargs)\u001b[39m\n\u001b[32m    697\u001b[39m     u, seq, pos, neg = sampler.next_batch()\n\u001b[32m    699\u001b[39m     inputs, target = \u001b[38;5;28mself\u001b[39m.create_combined_dataset(u, seq, pos, neg)\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m     loss = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m     step_loss.append(loss)\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch % val_epoch == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\__autograph_generated_filew6etwqlr.py:15\u001b[39m, in \u001b[36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[39m\u001b[34m(inp, tar)\u001b[39m\n\u001b[32m     13\u001b[39m retval_ = ag__.UndefinedReturnValue()\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ag__.ld(tf).GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     pos_logits, neg_logits, loss_mask = \u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     loss = ag__.converted_call(ag__.ld(loss_function), (ag__.ld(pos_logits), ag__.ld(neg_logits), ag__.ld(loss_mask)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[32m     17\u001b[39m gradients = ag__.converted_call(ag__.ld(tape).gradient, (ag__.ld(loss), ag__.ld(\u001b[38;5;28mself\u001b[39m).trainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\recommenders\\models\\sasrec\\model.py:492\u001b[39m, in \u001b[36mSASREC.call\u001b[39m\u001b[34m(self, x, training)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# --- ATTENTION BLOCKS ---\u001b[39;00m\n\u001b[32m    491\u001b[39m seq_attention = seq_embeddings\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m seq_attention = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_attention\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m seq_attention = \u001b[38;5;28mself\u001b[39m.layer_normalization(seq_attention)  \u001b[38;5;66;03m# (b, s, d)\u001b[39;00m\n\u001b[32m    495\u001b[39m \u001b[38;5;66;03m# --- PREDICTION LAYER ---\u001b[39;00m\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# user's sequence embedding\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: in user code:\n\n    File \"c:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\recommenders\\models\\sasrec\\model.py\", line 676, in train_step  *\n        pos_logits, neg_logits, loss_mask = self(inp, training=True)\n    File \"c:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\justi\\dev\\CS6365AdvancedML\\rec-env\\Lib\\site-packages\\recommenders\\models\\sasrec\\model.py\", line 492, in call\n        seq_attention = self.encoder(seq_attention, training, mask)\n\n    ValueError: Exception encountered when calling SASREC.call().\n    \n    \u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: True (of type <class 'bool'>)\u001b[0m\n    \n    Arguments received by SASREC.call():\n      • x={'users': 'tf.Tensor(shape=(None, 1), dtype=int64)', 'input_seq': 'tf.Tensor(shape=(None, 50), dtype=int64)', 'positive': 'tf.Tensor(shape=(None, 50), dtype=int64)', 'negative': 'tf.Tensor(shape=(None, 50), dtype=int64)'}\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    t_test = model.train(dataset, sampler, num_epochs=num_epochs, batch_size=batch_size, lr=lr, val_epoch=6)\n",
    "\n",
    "print('Time cost for training is {0:.2f} mins'.format(train_time.interval/60.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
