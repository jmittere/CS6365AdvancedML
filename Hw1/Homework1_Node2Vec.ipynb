{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ad058d",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3922f1",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35076694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57dd73a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'label'], dtype='object')\n",
      "   id    label\n",
      "0   0  Dataset\n",
      "1   1  Dataset\n",
      "2   2  Dataset\n",
      "3   3  Dataset\n",
      "4   4  Dataset\n",
      "\n",
      "label\n",
      "Publication       2584\n",
      "ScienceKeyword    1609\n",
      "Dataset           1300\n",
      "Platform           142\n",
      "Instrument          83\n",
      "Project             44\n",
      "DataCenter           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "relationship_type\n",
      "HAS_SCIENCEKEYWORD    4015\n",
      "USES_DATASET          3623\n",
      "SUBCATEGORY_OF        1823\n",
      "HAS_PLATFORM          1519\n",
      "OF_PROJECT            1325\n",
      "HAS_DATASET           1300\n",
      "HAS_INSTRUMENT         215\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of training examples:  13820\n",
      "Number of validation examples:  860\n",
      "Number of test examples:  861\n"
     ]
    }
   ],
   "source": [
    "#import nodes and edges\n",
    "node_df = pd.read_csv('data/nodes.csv')\n",
    "edge_df = pd.read_csv('data/train_edges.csv')\n",
    "val_links = pd.read_csv('data/val_links.csv')\n",
    "test_links = pd.read_csv('data/test_links.csv')\n",
    "\n",
    "#print(node_df.head())\n",
    "#print(node_df['label'].unique())\n",
    "#print(edge_df.head())\n",
    "#print(edge_df['relationship_type'].unique())\n",
    "\n",
    "#node_df[\"properties\"] = node_df[\"properties\"].apply(ast.literal_eval)\n",
    "#print(type(node_df['properties'].iloc[0]))\n",
    "\n",
    "#drop properties column because won't be used\n",
    "node_df = node_df.drop('properties', axis=1)\n",
    "#remove quotes and brackets so labels are simpler\n",
    "node_df['label'] = node_df['label'].str.replace(\"['\", \"\")\n",
    "node_df['label'] = node_df['label'].str.replace(\"']\", \"\")\n",
    "print(node_df.columns)\n",
    "print(node_df.head())\n",
    "print()\n",
    "print(node_df['label'].value_counts())\n",
    "\n",
    "print()\n",
    "print(edge_df['relationship_type'].value_counts())\n",
    "\n",
    "print()\n",
    "print(\"Number of training examples: \", len(edge_df))\n",
    "print(\"Number of validation examples: \", len(val_links))\n",
    "print(\"Number of test examples: \", len(test_links))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a7604",
   "metadata": {},
   "source": [
    "**Important: - `val_links.csv`: Contains `HAS_SCIENCEKEYWORD` edges for validation.`test_links.csv`: Contains `HAS_SCIENCEKEYWORD` edges for testing.** <br>\n",
    "So, the validation and test sets are only looking at relationship type Dataset -> ScienceKeyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd02e0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 860])\n",
      "torch.Size([2, 861])\n",
      "Data(x=[5763, 1], edge_index=[2, 13820])\n"
     ]
    }
   ],
   "source": [
    "# Map node IDs to contiguous indices for PyG\n",
    "node_df['idx'] = range(len(node_df))\n",
    "id_to_idx = dict(zip(node_df['id'], node_df['idx']))\n",
    "\n",
    "ones = torch.ones((len(node_df), 1))  # dummy node features for each node\n",
    "# Map node IDs to indices\n",
    "edge_df['source'] = edge_df['source'].map(id_to_idx)\n",
    "edge_df['target'] = edge_df['target'].map(id_to_idx)\n",
    "\n",
    "val_links['source'] = val_links['source'].map(id_to_idx)\n",
    "val_links['target'] = val_links['target'].map(id_to_idx)\n",
    "\n",
    "test_links['source'] = test_links['source'].map(id_to_idx)\n",
    "test_links['target'] = test_links['target'].map(id_to_idx)\n",
    "\n",
    "\n",
    "# Create edge_index tensor\n",
    "edge_index = torch.tensor(edge_df[['source', 'target']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "val_index = torch.tensor(val_links[['source', 'target']].values, dtype=torch.long).t().contiguous()\n",
    "test_index = torch.tensor(test_links[['source', 'target']].values, dtype=torch.long).t().contiguous()\n",
    "#shape must be (2 , num_edges)\n",
    "print(val_index.size())\n",
    "print(test_index.size())\n",
    "\n",
    "\n",
    "data = Data(x=ones, edge_index=edge_index)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e39c0c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nodes:  5763\n",
      "Number of Node features:  1\n",
      "\n",
      "Number of Edges:  13820\n",
      "\n",
      "Has Isolated Nodes:  False\n",
      "Has Self Loops:  False\n"
     ]
    }
   ],
   "source": [
    "#Summary of Dataset Structure and Key Statistics for Part 1\n",
    "print(\"Number of Nodes: \", data.num_nodes)\n",
    "print(\"Number of Node features: \", data.num_node_features)\n",
    "print()\n",
    "print(\"Number of Edges: \", data.num_edges)\n",
    "print()\n",
    "print(\"Has Isolated Nodes: \" , data.has_isolated_nodes())\n",
    "print(\"Has Self Loops: \", data.has_self_loops())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240188c",
   "metadata": {},
   "source": [
    "## Part 2: Link Prediction\n",
    "### Method #1: Embedding-Based Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70bc828",
   "metadata": {},
   "source": [
    "Task: Apply an embedding-based method for link prediction. ○ Description: Train a model that generates node embeddings, then use those embeddings to predict links. Print relevant metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c16c65",
   "metadata": {},
   "source": [
    "\"The primary goal of the NASA Knowledge Graph is to bridge scientific publications with the datasets they reference, facilitating deeper insights and research opportunities within NASA's scientific and data ecosystem. By organizing these interconnections within a graph structure, this dataset enables advanced analyses, such as discovering influential datasets, understanding research trends, and exploring scientific collaborations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b34057",
   "metadata": {},
   "source": [
    "https://pytorch-geometric.readthedocs.io/en/2.6.0/tutorial/shallow_node_embeddings.\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.MetaPath2Vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "721d7820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node2Vec(5763, 128)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import Node2Vec\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Node2Vec(data.edge_index, embedding_dim=128, walk_length=10, context_size=5, walks_per_node=10).to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "loader = model.loader(batch_size=32, shuffle=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43cd7fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1007.7121\n",
      "Epoch 2, Loss: 734.0953\n",
      "Epoch 3, Loss: 536.2362\n",
      "Epoch 4, Loss: 399.0610\n",
      "Epoch 5, Loss: 308.6581\n",
      "Epoch 6, Loss: 247.1568\n",
      "Epoch 7, Loss: 206.3326\n",
      "Epoch 8, Loss: 180.2015\n",
      "Epoch 9, Loss: 163.8000\n",
      "Epoch 10, Loss: 154.0092\n",
      "Epoch 11, Loss: 147.8088\n",
      "Epoch 12, Loss: 144.0666\n",
      "Epoch 13, Loss: 141.4387\n",
      "Epoch 14, Loss: 139.9338\n",
      "Epoch 15, Loss: 138.8192\n",
      "Epoch 16, Loss: 138.2774\n",
      "Epoch 17, Loss: 137.7419\n",
      "Epoch 18, Loss: 137.4934\n",
      "Epoch 19, Loss: 137.3682\n",
      "Epoch 20, Loss: 137.3345\n",
      "Epoch 21, Loss: 137.2834\n",
      "Epoch 22, Loss: 137.2292\n",
      "Epoch 23, Loss: 137.4433\n",
      "Epoch 24, Loss: 137.5447\n",
      "Epoch 25, Loss: 137.5329\n",
      "Epoch 26, Loss: 137.7108\n",
      "Epoch 27, Loss: 137.6426\n",
      "Epoch 28, Loss: 137.6790\n",
      "Epoch 29, Loss: 137.8137\n",
      "Epoch 30, Loss: 137.7188\n",
      "Epoch 31, Loss: 137.8506\n",
      "Epoch 32, Loss: 137.8430\n",
      "Epoch 33, Loss: 137.8541\n",
      "Epoch 34, Loss: 137.7113\n",
      "Epoch 35, Loss: 137.7094\n",
      "Epoch 36, Loss: 137.7095\n",
      "Epoch 37, Loss: 137.6874\n",
      "Epoch 38, Loss: 137.6003\n",
      "Epoch 39, Loss: 137.5961\n",
      "Epoch 40, Loss: 137.7175\n",
      "Epoch 41, Loss: 137.6074\n",
      "Epoch 42, Loss: 137.6893\n",
      "Epoch 43, Loss: 137.6243\n",
      "Epoch 44, Loss: 137.6529\n",
      "Epoch 45, Loss: 137.7216\n",
      "Epoch 46, Loss: 137.7394\n",
      "Epoch 47, Loss: 137.5440\n",
      "Epoch 48, Loss: 137.6042\n",
      "Epoch 49, Loss: 137.6307\n",
      "Epoch 50, Loss: 137.6240\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw, neg_rw)  # negative samples are neg_rw\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "656a27b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_index.size(1):  860\n",
      "test_index.size(1):  861\n",
      "model.size(0):  5763\n",
      "tensor([[4485, 4224, 3492,  ..., 1521, 5278, 3069],\n",
      "        [4587, 1524,   11,  ..., 1206, 1551, 5461]])\n",
      "neg_val_edge_index.shape:  torch.Size([2, 860])\n",
      "tensor([[1019, 4078, 4482,  ..., 4131, 4606, 3181],\n",
      "        [5360, 3467, 2482,  ...,  818, 5596, 5306]])\n",
      "neg_test_edge_index.shape:  torch.Size([2, 860])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "print(\"val_index.size(1): \", val_index.size(1))\n",
    "print(\"test_index.size(1): \", test_index.size(1))\n",
    "print(\"model.size(0): \", model.num_nodes)\n",
    "\n",
    "neg_val_index = negative_sampling(\n",
    "    edge_index=data.edge_index, \n",
    "    num_nodes=model.num_nodes,\n",
    "    num_neg_samples=val_index.size(1)\n",
    ")\n",
    "\n",
    "neg_test_index = negative_sampling(\n",
    "    edge_index=data.edge_index,\n",
    "    num_nodes=model.num_nodes,\n",
    "    num_neg_samples=test_index.size(1)\n",
    ")\n",
    "\n",
    "print(neg_val_index)\n",
    "print(\"neg_val_edge_index.shape: \", neg_val_index.shape)\n",
    "print(neg_test_index)\n",
    "print(\"neg_test_edge_index.shape: \", neg_val_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aec2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Negative Edges\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "num_nodes = data.num_nodes\n",
    "\n",
    "def gen_neg_edges(negative_edges_goal, edge_index, num_nodes):\n",
    "    existing_edges = set([tuple(e) for e in edge_index.t().tolist()])\n",
    "    neg_edges = set()\n",
    "    while len(neg_edges) < negative_edges_goal:\n",
    "        u = np.random.randint(0, num_nodes)\n",
    "        v = np.random.randint(0, num_nodes)\n",
    "        if u == v: \n",
    "            continue  # skip self-loops\n",
    "        if (u,v) in existing_edges or (v,u) in existing_edges:\n",
    "            continue\n",
    "        neg_edges.add((u,v))\n",
    "    return np.array(list(neg_edges))\n",
    "\n",
    "val_neg = gen_neg_edges(len(val_links), data.edge_index, num_nodes)\n",
    "test_neg = gen_neg_edges(len(test_links), data.edge_index, num_nodes)\n",
    "\n",
    "# Combine positive and negative edges\n",
    "val_pos = val_links[['source','target']].values\n",
    "val_edges = np.vstack([val_pos, val_neg])\n",
    "val_labels = np.hstack([np.ones(len(val_pos)), np.zeros(len(val_neg))])\n",
    "\n",
    "test_pos = test_links[['source','target']].values\n",
    "test_edges = np.vstack([test_pos, test_neg])\n",
    "test_labels = np.hstack([np.ones(len(test_pos)), np.zeros(len(test_neg))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ef3d6e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_true_labels.shape:  torch.Size([1720])\n",
      "test_true_labels.shape:  torch.Size([1722])\n",
      "pos_val_pred.shape:  torch.Size([860])\n",
      "neg_val_pred.shape:  torch.Size([860])\n"
     ]
    }
   ],
   "source": [
    "embeddings = model()\n",
    "#gets actual link predictions \n",
    "def predict_links(node_embeddings, edge_index):\n",
    "    src, dst = edge_index\n",
    "    score = (node_embeddings[src] * node_embeddings[dst]).sum(dim=1)  # dot product of two node embeddings\n",
    "    #print(type(score))\n",
    "    #print(\"Score: \", score)\n",
    "    prob = torch.sigmoid(score) #make prob between 0 and 1\n",
    "    threshold = 0.7\n",
    "    pred = (prob > threshold).int()\n",
    "    return pred\n",
    "\n",
    "#gets scores from dot product of two node embeddings\n",
    "def get_scores(node_embeddings, edge_index):\n",
    "    src, dst = edge_index\n",
    "    scores = (node_embeddings[src] * node_embeddings[dst]).sum(dim=1)  # dot product of two node embeddings\n",
    "    return scores\n",
    "\n",
    "\n",
    "#assemble true label tensors\n",
    "val_true_labels = torch.cat([torch.ones(val_index.size(1)), torch.zeros(neg_val_index.size(1))])\n",
    "test_true_labels = torch.cat([torch.ones(test_index.size(1)), torch.zeros(neg_test_index.size(1))])\n",
    "print(\"val_true_labels.shape: \" , val_true_labels.size())\n",
    "print(\"test_true_labels.shape: \", test_true_labels.size())\n",
    "\n",
    "#get presence of link predictions for validation and test sets\n",
    "pos_val_pred = predict_links(embeddings, val_index)\n",
    "neg_val_pred = predict_links(embeddings, neg_val_index)\n",
    "#print(val_true_labels)\n",
    "print(\"pos_val_pred.shape: \", pos_val_pred.shape)\n",
    "print(\"neg_val_pred.shape: \", neg_val_pred.shape)\n",
    "pos_test_pred = predict_links(embeddings, test_index)\n",
    "neg_test_pred = predict_links(embeddings, neg_test_index)\n",
    "\n",
    "#assemble predicted label tensors\n",
    "val_pred_labels = torch.cat([pos_val_pred, neg_val_pred])\n",
    "test_pred_labels = torch.cat([pos_test_pred, neg_test_pred])\n",
    "\n",
    "#get score predictions for validation and test sets\n",
    "pos_val_scores = get_scores(embeddings, val_index)\n",
    "neg_val_scores = get_scores(embeddings, neg_val_index)\n",
    "\n",
    "pos_test_scores = get_scores(embeddings, test_index)\n",
    "neg_test_scores = get_scores(embeddings, neg_test_index)\n",
    "\n",
    "#assemble validation and test score tensors\n",
    "val_scores = torch.cat([pos_val_scores, neg_val_scores])\n",
    "test_scores = torch.cat([pos_test_scores, neg_test_scores])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "adaa88b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.702906976744186\n",
      "Test Accuracy:  0.7049941927990708\n",
      "\n",
      "Validation ROC AUC: 0.6544, Val Avg Precision: 0.7654\n",
      "Test ROC AUC: 0.6642, Test Avg Precision: 0.7555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "validation_accuracy = accuracy_score(val_true_labels, val_pred_labels)\n",
    "test_accuracy = accuracy_score(test_true_labels, test_pred_labels)\n",
    "print(\"Validation Accuracy: \", validation_accuracy)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "print()\n",
    "val_roc_auc = roc_auc_score(val_true_labels.cpu(), val_scores.detach().numpy())\n",
    "test_roc_auc = roc_auc_score(test_true_labels.cpu(), test_scores.detach().numpy())\n",
    "val_avg_prec = average_precision_score(val_true_labels.cpu(), val_scores.detach().numpy())\n",
    "test_avg_prec = average_precision_score(test_true_labels.cpu(), test_scores.detach().numpy())\n",
    "print(f\"Validation ROC AUC: {val_roc_auc:.4f}, Val Avg Precision: {val_avg_prec:.4f}\")\n",
    "print(f\"Test ROC AUC: {test_roc_auc:.4f}, Test Avg Precision: {test_avg_prec:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac4148",
   "metadata": {},
   "source": [
    "Accuracy in predicting the presence of an edge on was about 70% in the validation and test sets using the dot products of two nodee embeddings to get a score which was then passed through a sigmoid() function to get a probability between 0 and 1. Testing different thresholds, the best performance was found at a threshold of about 0.7. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376f921",
   "metadata": {},
   "source": [
    "### Method 2: Alternative Approach \n",
    "Task: Choose and implement another link prediction method. ○ Description: This method should not use embeddings. You can use any approach of your choice. Compare the performance of this method with the embedding-based method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e483b1a5",
   "metadata": {},
   "source": [
    "Going to use Jaccard's Coefficient to measure local neighborhood overlap and predict links between Datasets that have ScienceKeywords that don't exist in the graph. Rather than using common neighbors which doesn't consider the size of the neighborhood set, Jaccard's coefficient normalizes for node degree; therefore, having more mutual links relative to the total number of unique links will be more influential in determining whether there is a link. <br>\n",
    "For example, consider a Dataset (node A) that connects to 10 different science keywords. If you have a science keyword (node B) that is a subcategory of many other ScienceKeywords that this Dataset connects with, it is likely that the Dataset (node A) should be connected with node (node B)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3e48cd",
   "metadata": {},
   "source": [
    "https://networkx.org/documentation/stable/reference/classes/graph.html#networkx.Graph <br>\n",
    "https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_pandas_edgelist.html <br>\n",
    "https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_prediction.jaccard_coefficient.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f664aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014705882352941176\n",
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m val_precision \u001b[38;5;241m=\u001b[39m average_precision_score(val_labels, val_scores)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(val_labels)\n\u001b[1;32m---> 31\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m accuracy_score(test_labels, test_scores)\n\u001b[0;32m     33\u001b[0m test_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(test_labels, test_scores)\n",
      "File \u001b[1;32mc:\\Users\\justi\\dev\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\justi\\dev\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:359\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m    358\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[1;32m--> 359\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\justi\\dev\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:106\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    103\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    108\u001b[0m             type_true, type_pred\n\u001b[0;32m    109\u001b[0m         )\n\u001b[0;32m    110\u001b[0m     )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    113\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "#Non-Embedding Method for link prediction\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "\n",
    "#print(edge_df.head())\n",
    "G = nx.from_pandas_edgelist(edge_df, source='source', target='target', edge_attr=\"relationship_type\", create_using=nx.Graph())\n",
    "\n",
    "#validation edges \n",
    "#print(val_links.head())\n",
    "\n",
    "def compute_jaccard(G, edges):\n",
    "    scores = []\n",
    "    for u, v in edges:\n",
    "        try:\n",
    "            preds = list(nx.jaccard_coefficient(G, [(u, v)]))\n",
    "            scores.append(preds[0][2])\n",
    "        except nx.NetworkXError:\n",
    "            scores.append(0.0)\n",
    "    return np.array(scores)\n",
    "\n",
    "#Use val_edges, test_edges, val_labels and test_labels from earlier negative sampling\n",
    "val_scores = compute_jaccard(G, val_edges)\n",
    "test_scores = compute_jaccard(G, test_edges)\n",
    "\n",
    "print(test_scores[0])\n",
    "\n",
    "val_auc = roc_auc_score(val_labels, val_scores)\n",
    "val_precision = average_precision_score(val_labels, val_scores)\n",
    "print(val_labels)\n",
    "val_acc = accuracy_score(val_labels, val_scores)\n",
    "test_acc = accuracy_score(test_labels, test_scores)\n",
    "test_auc = roc_auc_score(test_labels, test_scores)\n",
    "test_precision = average_precision_score(test_labels, test_scores)\n",
    "\n",
    "print(f\"Validation  AUC: {val_auc:.4f}, AP: {val_precision:.4f}\")\n",
    "print(f\"Test        AUC: {test_auc:.4f}, AP: {test_precision:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
