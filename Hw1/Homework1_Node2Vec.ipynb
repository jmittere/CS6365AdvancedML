{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ad058d",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3922f1",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "35076694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "57dd73a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'label'], dtype='object')\n",
      "   id    label\n",
      "0   0  Dataset\n",
      "1   1  Dataset\n",
      "2   2  Dataset\n",
      "3   3  Dataset\n",
      "4   4  Dataset\n",
      "\n",
      "label\n",
      "Publication       2584\n",
      "ScienceKeyword    1609\n",
      "Dataset           1300\n",
      "Platform           142\n",
      "Instrument          83\n",
      "Project             44\n",
      "DataCenter           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "relationship_type\n",
      "HAS_SCIENCEKEYWORD    4015\n",
      "USES_DATASET          3623\n",
      "SUBCATEGORY_OF        1823\n",
      "HAS_PLATFORM          1519\n",
      "OF_PROJECT            1325\n",
      "HAS_DATASET           1300\n",
      "HAS_INSTRUMENT         215\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of training examples:  13820\n",
      "Number of validation examples:  860\n",
      "Number of test examples:  861\n"
     ]
    }
   ],
   "source": [
    "#import nodes and edges\n",
    "node_df = pd.read_csv('data/nodes.csv')\n",
    "edge_df = pd.read_csv('data/train_edges.csv')\n",
    "val_links = pd.read_csv('data/val_links.csv')\n",
    "test_links = pd.read_csv('data/test_links.csv')\n",
    "\n",
    "#print(node_df.head())\n",
    "#print(node_df['label'].unique())\n",
    "#print(edge_df.head())\n",
    "#print(edge_df['relationship_type'].unique())\n",
    "\n",
    "#node_df[\"properties\"] = node_df[\"properties\"].apply(ast.literal_eval)\n",
    "#print(type(node_df['properties'].iloc[0]))\n",
    "\n",
    "#drop properties column because won't be used\n",
    "node_df = node_df.drop('properties', axis=1)\n",
    "#remove quotes and brackets so labels are simpler\n",
    "node_df['label'] = node_df['label'].str.replace(\"['\", \"\")\n",
    "node_df['label'] = node_df['label'].str.replace(\"']\", \"\")\n",
    "print(node_df.columns)\n",
    "print(node_df.head())\n",
    "print()\n",
    "print(node_df['label'].value_counts())\n",
    "\n",
    "print()\n",
    "print(edge_df['relationship_type'].value_counts())\n",
    "\n",
    "print()\n",
    "print(\"Number of training examples: \", len(edge_df))\n",
    "print(\"Number of validation examples: \", len(val_links))\n",
    "print(\"Number of test examples: \", len(test_links))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a7604",
   "metadata": {},
   "source": [
    "**Important: - `val_links.csv`: Contains `HAS_SCIENCEKEYWORD` edges for validation.`test_links.csv`: Contains `HAS_SCIENCEKEYWORD` edges for testing.** <br>\n",
    "So, the validation and test sets are only looking at relationship type Dataset -> ScienceKeyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "dd02e0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 860])\n",
      "torch.Size([2, 861])\n",
      "Data(x=[5763, 1], edge_index=[2, 13820])\n"
     ]
    }
   ],
   "source": [
    "# Map node IDs to contiguous indices for PyG\n",
    "node_df['idx'] = range(len(node_df))\n",
    "id_to_idx = dict(zip(node_df['id'], node_df['idx']))\n",
    "\n",
    "ones = torch.ones((len(node_df), 1))  # dummy node features for each node\n",
    "# Map node IDs to indices\n",
    "edge_df['source'] = edge_df['source'].map(id_to_idx)\n",
    "edge_df['target'] = edge_df['target'].map(id_to_idx)\n",
    "\n",
    "val_links['source'] = val_links['source'].map(id_to_idx)\n",
    "val_links['target'] = val_links['target'].map(id_to_idx)\n",
    "\n",
    "test_links['source'] = test_links['source'].map(id_to_idx)\n",
    "test_links['target'] = test_links['target'].map(id_to_idx)\n",
    "\n",
    "# Create edge_index tensor\n",
    "edge_index = torch.tensor(edge_df[['source', 'target']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "val_index = torch.tensor(val_links[['source', 'target']].values, dtype=torch.long).t().contiguous()\n",
    "test_index = torch.tensor(test_links[['source', 'target']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "all_pos_edges = torch.cat([edge_index, val_index, test_index], dim=1) #for neg sampling later\n",
    "\n",
    "#shape should be (2 , num_edges)\n",
    "print(val_index.size())\n",
    "print(test_index.size())\n",
    "\n",
    "data = Data(x=ones, edge_index=edge_index)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e39c0c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nodes:  5763\n",
      "Number of Node features:  1\n",
      "\n",
      "Number of Edges:  13820\n",
      "\n",
      "Has Isolated Nodes:  False\n",
      "Has Self Loops:  False\n"
     ]
    }
   ],
   "source": [
    "#Summary of Dataset Structure and Key Statistics for Part 1\n",
    "print(\"Number of Nodes: \", data.num_nodes)\n",
    "print(\"Number of Node features: \", data.num_node_features)\n",
    "print()\n",
    "print(\"Number of Edges: \", data.num_edges)\n",
    "print()\n",
    "print(\"Has Isolated Nodes: \" , data.has_isolated_nodes())\n",
    "print(\"Has Self Loops: \", data.has_self_loops())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240188c",
   "metadata": {},
   "source": [
    "## Part 2: Link Prediction\n",
    "### Method #1: Embedding-Based Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70bc828",
   "metadata": {},
   "source": [
    "Task: Apply an embedding-based method for link prediction. ○ Description: Train a model that generates node embeddings, then use those embeddings to predict links. Print relevant metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c16c65",
   "metadata": {},
   "source": [
    "\"The primary goal of the NASA Knowledge Graph is to bridge scientific publications with the datasets they reference, facilitating deeper insights and research opportunities within NASA's scientific and data ecosystem. By organizing these interconnections within a graph structure, this dataset enables advanced analyses, such as discovering influential datasets, understanding research trends, and exploring scientific collaborations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b34057",
   "metadata": {},
   "source": [
    "https://pytorch-geometric.readthedocs.io/en/2.6.0/tutorial/shallow_node_embeddings.\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.MetaPath2Vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "721d7820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node2Vec(5763, 128)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import Node2Vec\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Node2Vec(data.edge_index, embedding_dim=128, walk_length=10, context_size=5, walks_per_node=10).to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "loader = model.loader(batch_size=32, shuffle=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "43cd7fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1014.1090\n",
      "Epoch 2, Loss: 738.0273\n",
      "Epoch 3, Loss: 539.8921\n",
      "Epoch 4, Loss: 400.7843\n",
      "Epoch 5, Loss: 309.3749\n",
      "Epoch 6, Loss: 247.8519\n",
      "Epoch 7, Loss: 206.4895\n",
      "Epoch 8, Loss: 180.5931\n",
      "Epoch 9, Loss: 164.4508\n",
      "Epoch 10, Loss: 154.0343\n",
      "Epoch 11, Loss: 147.9625\n",
      "Epoch 12, Loss: 144.1547\n",
      "Epoch 13, Loss: 141.6751\n",
      "Epoch 14, Loss: 140.0216\n",
      "Epoch 15, Loss: 138.8665\n",
      "Epoch 16, Loss: 138.0608\n",
      "Epoch 17, Loss: 137.6561\n",
      "Epoch 18, Loss: 137.4128\n",
      "Epoch 19, Loss: 137.3406\n",
      "Epoch 20, Loss: 137.3614\n",
      "Epoch 21, Loss: 137.2899\n",
      "Epoch 22, Loss: 137.1936\n",
      "Epoch 23, Loss: 137.4824\n",
      "Epoch 24, Loss: 137.5977\n",
      "Epoch 25, Loss: 137.6122\n",
      "Epoch 26, Loss: 137.7320\n",
      "Epoch 27, Loss: 137.7725\n",
      "Epoch 28, Loss: 137.7517\n",
      "Epoch 29, Loss: 137.8012\n",
      "Epoch 30, Loss: 137.8991\n",
      "Epoch 31, Loss: 137.9155\n",
      "Epoch 32, Loss: 138.0269\n",
      "Epoch 33, Loss: 138.0186\n",
      "Epoch 34, Loss: 138.0176\n",
      "Epoch 35, Loss: 137.8864\n",
      "Epoch 36, Loss: 137.9284\n",
      "Epoch 37, Loss: 137.8967\n",
      "Epoch 38, Loss: 137.9023\n",
      "Epoch 39, Loss: 137.7119\n",
      "Epoch 40, Loss: 137.8788\n",
      "Epoch 41, Loss: 137.8270\n",
      "Epoch 42, Loss: 137.7713\n",
      "Epoch 43, Loss: 137.7038\n",
      "Epoch 44, Loss: 137.5994\n",
      "Epoch 45, Loss: 137.5883\n",
      "Epoch 46, Loss: 137.6028\n",
      "Epoch 47, Loss: 137.6026\n",
      "Epoch 48, Loss: 137.8161\n",
      "Epoch 49, Loss: 137.5495\n",
      "Epoch 50, Loss: 137.5385\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw, neg_rw)  # negative samples are neg_rw\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "656a27b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_index.size(1):  860\n",
      "test_index.size(1):  861\n",
      "model.size(0):  5763\n",
      "tensor([[5324,  410, 1952,  ..., 5029, 2595, 5392],\n",
      "        [3062, 1280, 2041,  ..., 4222,  505, 3716]])\n",
      "neg_val_edge_index.shape:  torch.Size([2, 860])\n",
      "tensor([[2026,  113, 2386,  ...,  911,  296, 4730],\n",
      "        [ 850,  502, 4742,  ..., 3795, 5237, 2198]])\n",
      "neg_test_edge_index.shape:  torch.Size([2, 860])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "print(\"val_index.size(1): \", val_index.size(1))\n",
    "print(\"test_index.size(1): \", test_index.size(1))\n",
    "print(\"model.size(0): \", model.num_nodes)\n",
    "\n",
    "neg_val_index = negative_sampling(\n",
    "    edge_index=all_pos_edges, \n",
    "    num_nodes=model.num_nodes,\n",
    "    num_neg_samples=val_index.size(1)\n",
    ")\n",
    "\n",
    "neg_test_index = negative_sampling(\n",
    "    edge_index=all_pos_edges,\n",
    "    num_nodes=model.num_nodes,\n",
    "    num_neg_samples=test_index.size(1)\n",
    ")\n",
    "\n",
    "print(neg_val_index)\n",
    "print(\"neg_val_edge_index.shape: \", neg_val_index.shape)\n",
    "print(neg_test_index)\n",
    "print(\"neg_test_edge_index.shape: \", neg_val_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ef3d6e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_true_labels.shape:  torch.Size([1720])\n",
      "test_true_labels.shape:  torch.Size([1722])\n",
      "pos_val_pred.shape:  torch.Size([860])\n",
      "neg_val_pred.shape:  torch.Size([860])\n"
     ]
    }
   ],
   "source": [
    "embeddings = model()\n",
    "#gets actual link predictions \n",
    "def predict_links(node_embeddings, edge_index):\n",
    "    src, dst = edge_index\n",
    "    score = (node_embeddings[src] * node_embeddings[dst]).sum(dim=1)  # dot product of two node embeddings\n",
    "    #print(type(score))\n",
    "    #print(\"Score: \", score)\n",
    "    prob = torch.sigmoid(score) #make prob between 0 and 1\n",
    "    threshold = 0.7\n",
    "    pred = (prob > threshold).int()\n",
    "    return pred\n",
    "\n",
    "#gets scores from dot product of two node embeddings\n",
    "def get_scores(node_embeddings, edge_index):\n",
    "    src, dst = edge_index\n",
    "    scores = (node_embeddings[src] * node_embeddings[dst]).sum(dim=1)  # dot product of two node embeddings\n",
    "    return scores\n",
    "\n",
    "\n",
    "#assemble true label tensors\n",
    "val_true_labels = torch.cat([torch.ones(val_index.size(1)), torch.zeros(neg_val_index.size(1))])\n",
    "test_true_labels = torch.cat([torch.ones(test_index.size(1)), torch.zeros(neg_test_index.size(1))])\n",
    "print(\"val_true_labels.shape: \" , val_true_labels.size())\n",
    "print(\"test_true_labels.shape: \", test_true_labels.size())\n",
    "\n",
    "#get presence of link predictions for validation and test sets\n",
    "pos_val_pred = predict_links(embeddings, val_index)\n",
    "neg_val_pred = predict_links(embeddings, neg_val_index)\n",
    "#print(val_true_labels)\n",
    "print(\"pos_val_pred.shape: \", pos_val_pred.shape)\n",
    "print(\"neg_val_pred.shape: \", neg_val_pred.shape)\n",
    "pos_test_pred = predict_links(embeddings, test_index)\n",
    "neg_test_pred = predict_links(embeddings, neg_test_index)\n",
    "\n",
    "#assemble predicted label tensors\n",
    "val_pred_labels = torch.cat([pos_val_pred, neg_val_pred])\n",
    "test_pred_labels = torch.cat([pos_test_pred, neg_test_pred])\n",
    "\n",
    "#get score predictions for validation and test sets\n",
    "pos_val_scores = get_scores(embeddings, val_index)\n",
    "neg_val_scores = get_scores(embeddings, neg_val_index)\n",
    "\n",
    "pos_test_scores = get_scores(embeddings, test_index)\n",
    "neg_test_scores = get_scores(embeddings, neg_test_index)\n",
    "\n",
    "#assemble validation and test score tensors\n",
    "val_scores = torch.cat([pos_val_scores, neg_val_scores])\n",
    "test_scores = torch.cat([pos_test_scores, neg_test_scores])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "adaa88b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7058139534883721, Validation Recall: 0.46511627906976744, Validation f1-score: 0.6125574272588055\n",
      "Validation roc auc: 0.6513331530557058, Val Avg Precision: 0.761996519792042\n",
      "Test Accuracy: 0.6997677119628339, Test Recall: 0.4610917537746806, Test f1-score: 0.6056445461479787\n",
      "Test roc auc: 0.6515342206682395, Test Avg Precision: 0.7486561379752955\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, recall_score, f1_score\n",
    "validation_accuracy = accuracy_score(val_true_labels, val_pred_labels)\n",
    "validation_recall = recall_score(val_true_labels, val_pred_labels)\n",
    "validation_f1 = f1_score(val_true_labels, val_pred_labels)\n",
    "print(f\"Validation Accuracy: {validation_accuracy}, Validation Recall: {validation_recall}, Validation f1-score: {validation_f1}\")\n",
    "val_roc_auc = roc_auc_score(val_true_labels.cpu(), val_scores.detach().numpy())\n",
    "val_avg_prec = average_precision_score(val_true_labels.cpu(), val_scores.detach().numpy())\n",
    "print(f\"Validation roc auc: {val_roc_auc}, Val Avg Precision: {val_avg_prec}\")\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_pred_labels)\n",
    "test_recall = recall_score(test_true_labels, test_pred_labels)\n",
    "test_f1 = f1_score(test_true_labels, test_pred_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy}, Test Recall: {test_recall}, Test f1-score: {test_f1}\")\n",
    "test_roc_auc = roc_auc_score(test_true_labels.cpu(), test_scores.detach().numpy())\n",
    "test_avg_prec = average_precision_score(test_true_labels.cpu(), test_scores.detach().numpy())\n",
    "print(f\"Test roc auc: {test_roc_auc}, Test Avg Precision: {test_avg_prec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac4148",
   "metadata": {},
   "source": [
    "**#TODO: UPDATE Accuracy in predicting the presence of an edge was about 70% in the validation and test sets using the dot products of two node embeddings to get a score which was then passed through a sigmoid() function to get a probability between 0 and 1. Testing different thresholds, the best performance was found at a threshold of about 0.7. <br>\n",
    "The validation and test sets had ROC AUC scores of about 0.65 and 0.64, respectively. These scores indicate that the embeddings were better than randomly predicting a link which would give a score of 0.5. The average precision was 0.77 for the validation set and 0.76 for the test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376f921",
   "metadata": {},
   "source": [
    "### Method 2: Alternative Approach \n",
    "Task: Choose and implement another link prediction method. ○ Description: This method should not use embeddings. You can use any approach of your choice. Compare the performance of this method with the embedding-based method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e483b1a5",
   "metadata": {},
   "source": [
    "Going to use Jaccard's Coefficient to measure local neighborhood overlap and predict links between Datasets that have ScienceKeywords that don't exist in the graph. Rather than using common neighbors which doesn't consider the size of the neighborhood set, Jaccard's coefficient normalizes for node degree; therefore, having more mutual links relative to the total number of unique links will be more influential in determining whether there is a link. <br>\n",
    "For example, consider a Dataset (node A) that connects to 10 different science keywords. If you have a science keyword (node B) that is a subcategory of many other ScienceKeywords that this Dataset connects with, it is likely that the Dataset (node A) should be connected with node (node B)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3e48cd",
   "metadata": {},
   "source": [
    "https://networkx.org/documentation/stable/reference/classes/graph.html#networkx.Graph <br>\n",
    "https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_pandas_edgelist.html <br>\n",
    "https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_prediction.jaccard_coefficient.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8f664aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1720])\n",
      "torch.Size([2, 1722])\n",
      "Validation Accuracy: 0.8197674418604651, Validation Recall: 0.7116279069767442, Validation f1-score: 0.7979139504563233\n",
      "Validation roc auc: 0.794303677663602, Val Avg Precision: 0.686502708731353\n",
      "Test Accuracy: 0.8095238095238095, Test Recall: 0.7015098722415796, Test f1-score: 0.7864583333333334\n",
      "Test roc auc: 0.7836719855501194, Test Avg Precision: 0.6742436274034849\n"
     ]
    }
   ],
   "source": [
    "#Non-Embedding Method for link prediction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#print(edge_df.head())\n",
    "G = nx.from_pandas_edgelist(edge_df, source='source', target='target', edge_attr=\"relationship_type\", create_using=nx.Graph())\n",
    "\n",
    "all_val_edges = torch.cat([val_index, neg_val_index], dim=1) \n",
    "all_test_edges = torch.cat([test_index, neg_test_index], dim=1) \n",
    "print(all_val_edges.shape)\n",
    "print(all_test_edges.shape)\n",
    "\n",
    "\n",
    "def compute_jaccard(G, edges, threshold):\n",
    "    scores = []\n",
    "    edges = edges.t().tolist()\n",
    "    for u, v in edges:\n",
    "        try:\n",
    "            preds = list(nx.jaccard_coefficient(G, [(u, v)]))\n",
    "            scores.append(preds[0][2])\n",
    "        except nx.NetworkXError:\n",
    "            scores.append(0.0)\n",
    "\n",
    "    pred_labels = []\n",
    "    for score in scores: \n",
    "        if(score>threshold):\n",
    "            pred_labels.append(1)\n",
    "        else:\n",
    "            pred_labels.append(0)\n",
    "    return np.array(scores), np.array(pred_labels)\n",
    "\n",
    "\n",
    "val_scores, val_pred_labels_jaccard = compute_jaccard(G, all_val_edges, 0.001)\n",
    "test_scores, test_pred_labels_jaccard = compute_jaccard(G, all_test_edges, 0.001)\n",
    "\n",
    "val_acc = accuracy_score(val_true_labels, val_pred_labels_jaccard)\n",
    "val_recall = recall_score(val_true_labels, val_pred_labels_jaccard)\n",
    "val_f1 = f1_score(val_true_labels, val_pred_labels_jaccard)\n",
    "print(f\"Validation Accuracy: {val_acc}, Validation Recall: {val_recall}, Validation f1-score: {val_f1}\")\n",
    "val_auc = roc_auc_score(val_true_labels, val_scores)\n",
    "val_precision = average_precision_score(val_true_labels, val_scores)\n",
    "print(f\"Validation roc auc: {val_auc}, Val Avg Precision: {val_precision}\")\n",
    "\n",
    "\n",
    "test_acc = accuracy_score(test_true_labels, test_pred_labels_jaccard)\n",
    "test_recall = recall_score(test_true_labels, test_pred_labels_jaccard)\n",
    "test_f1 = f1_score(test_true_labels, test_pred_labels_jaccard)\n",
    "print(f\"Test Accuracy: {test_acc}, Test Recall: {test_recall}, Test f1-score: {test_f1}\")\n",
    "test_auc = roc_auc_score(test_true_labels, test_scores)\n",
    "test_precision = average_precision_score(test_true_labels, test_scores)\n",
    "print(f\"Test roc auc: {test_auc}, Test Avg Precision: {test_precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364689d6",
   "metadata": {},
   "source": [
    "## Part 3: Reflection and Analysis\n",
    "### Method #1: Embedding-Based Approach\n",
    "Task:Compare both methods. Description: Write a reflection on the performance of each method. Discuss any challenges and insights gained. Suggest improvements to the dataset or the methods used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
