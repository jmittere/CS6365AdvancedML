{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ad058d",
   "metadata": {},
   "source": [
    "# Homework 1. Link Prediction : CS6365 Fall 2025\n",
    "\n",
    "Justin Mittereder - G49843234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3922f1",
   "metadata": {},
   "source": [
    "## Part 1: Importing and Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35076694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57dd73a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'label'], dtype='object')\n",
      "   id    label\n",
      "0   0  Dataset\n",
      "1   1  Dataset\n",
      "2   2  Dataset\n",
      "3   3  Dataset\n",
      "4   4  Dataset\n",
      "\n",
      "Node Count:  5763\n",
      "Node Type Counts:  label\n",
      "Publication       2584\n",
      "ScienceKeyword    1609\n",
      "Dataset           1300\n",
      "Platform           142\n",
      "Instrument          83\n",
      "Project             44\n",
      "DataCenter           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Edge Type Counts:  relationship_type\n",
      "HAS_SCIENCEKEYWORD    4015\n",
      "USES_DATASET          3623\n",
      "SUBCATEGORY_OF        1823\n",
      "HAS_PLATFORM          1519\n",
      "OF_PROJECT            1325\n",
      "HAS_DATASET           1300\n",
      "HAS_INSTRUMENT         215\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of training examples:  13820\n",
      "Number of validation examples:  860\n",
      "Number of test examples:  861\n"
     ]
    }
   ],
   "source": [
    "#import nodes and edges\n",
    "node_df = pd.read_csv('data/nodes.csv')\n",
    "edge_df = pd.read_csv('data/train_edges.csv')\n",
    "val_links = pd.read_csv('data/val_links.csv')\n",
    "test_links = pd.read_csv('data/test_links.csv')\n",
    "\n",
    "#print(node_df.head())\n",
    "#print(node_df['label'].unique())\n",
    "#print(edge_df.head())\n",
    "#print(edge_df['relationship_type'].unique())\n",
    "\n",
    "#print(type(node_df['properties'].iloc[0]))\n",
    "\n",
    "#drop properties column because won't be used\n",
    "node_df = node_df.drop('properties', axis=1)\n",
    "#remove quotes and brackets so labels are simpler\n",
    "node_df['label'] = node_df['label'].str.replace(\"['\", \"\")\n",
    "node_df['label'] = node_df['label'].str.replace(\"']\", \"\")\n",
    "print(node_df.columns)\n",
    "print(node_df.head())\n",
    "print()\n",
    "print(\"Node Count: \", len(node_df))\n",
    "print(\"Node Type Counts: \", node_df['label'].value_counts())\n",
    "\n",
    "print()\n",
    "print(\"Edge Type Counts: \", edge_df['relationship_type'].value_counts())\n",
    "\n",
    "print()\n",
    "print(\"Number of training examples: \", len(edge_df))\n",
    "print(\"Number of validation examples: \", len(val_links))\n",
    "print(\"Number of test examples: \", len(test_links))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a7604",
   "metadata": {},
   "source": [
    "**Important: - `val_links.csv`: Contains `HAS_SCIENCEKEYWORD` edges for validation.`test_links.csv`: Contains `HAS_SCIENCEKEYWORD` edges for testing.** <br>\n",
    "So, the validation and test sets are only looking at relationship type Dataset -> ScienceKeyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd02e0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 860])\n",
      "torch.Size([2, 861])\n",
      "Data(x=[5763, 1], edge_index=[2, 13820])\n"
     ]
    }
   ],
   "source": [
    "# Map node IDs to contiguous indices for PyG\n",
    "node_df['idx'] = range(len(node_df))\n",
    "id_to_idx = dict(zip(node_df['id'], node_df['idx']))\n",
    "\n",
    "ones = torch.ones((len(node_df), 1))  # dummy node features for each node\n",
    "# Map node IDs to indices\n",
    "edge_df['source'] = edge_df['source'].map(id_to_idx)\n",
    "edge_df['target'] = edge_df['target'].map(id_to_idx)\n",
    "\n",
    "val_links['source'] = val_links['source'].map(id_to_idx)\n",
    "val_links['target'] = val_links['target'].map(id_to_idx)\n",
    "\n",
    "test_links['source'] = test_links['source'].map(id_to_idx)\n",
    "test_links['target'] = test_links['target'].map(id_to_idx)\n",
    "\n",
    "# Create edge_index tensor\n",
    "edge_index = torch.tensor(edge_df[['source', 'target']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "val_index = torch.tensor(val_links[['source', 'target']].values, dtype=torch.long).t().contiguous()\n",
    "test_index = torch.tensor(test_links[['source', 'target']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "all_pos_edges = torch.cat([edge_index, val_index, test_index], dim=1) #for neg sampling later\n",
    "\n",
    "#shape should be (2 , num_edges)\n",
    "print(val_index.size())\n",
    "print(test_index.size())\n",
    "\n",
    "data = Data(x=ones, edge_index=edge_index)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e39c0c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nodes:  5763\n",
      "Number of Node features:  1\n",
      "\n",
      "Number of Edges:  13820\n",
      "\n",
      "Has Isolated Nodes:  False\n",
      "Has Self Loops:  False\n"
     ]
    }
   ],
   "source": [
    "#Summary of Dataset Structure and Key Statistics for Part 1\n",
    "print(\"Number of Nodes: \", data.num_nodes)\n",
    "print(\"Number of Node features: \", data.num_node_features)\n",
    "print()\n",
    "print(\"Number of Edges: \", data.num_edges)\n",
    "print()\n",
    "print(\"Has Isolated Nodes: \" , data.has_isolated_nodes())\n",
    "print(\"Has Self Loops: \", data.has_self_loops())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240188c",
   "metadata": {},
   "source": [
    "## Part 2: Link Prediction\n",
    "### Method #1: Embedding-Based Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70bc828",
   "metadata": {},
   "source": [
    "*Task*: Apply an embedding-based method for link prediction. *Description*: Train a model that generates node embeddings, then use those embeddings to predict links. Print relevant metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c16c65",
   "metadata": {},
   "source": [
    "\"The primary goal of the NASA Knowledge Graph is to bridge scientific publications with the datasets they reference, facilitating deeper insights and research opportunities within NASA's scientific and data ecosystem. By organizing these interconnections within a graph structure, this dataset enables advanced analyses, such as discovering influential datasets, understanding research trends, and exploring scientific collaborations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b34057",
   "metadata": {},
   "source": [
    "https://pytorch-geometric.readthedocs.io/en/2.6.0/tutorial/shallow_node_embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721d7820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node2Vec(5763, 128)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import Node2Vec\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Node2Vec(data.edge_index, embedding_dim=128, walk_length=10, context_size=5, walks_per_node=10).to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "loader = model.loader(batch_size=32, shuffle=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43cd7fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1012.1948\n",
      "Epoch 2, Loss: 737.2280\n",
      "Epoch 3, Loss: 537.9211\n",
      "Epoch 4, Loss: 400.6344\n",
      "Epoch 5, Loss: 309.2363\n",
      "Epoch 6, Loss: 247.5649\n",
      "Epoch 7, Loss: 206.3209\n",
      "Epoch 8, Loss: 180.3357\n",
      "Epoch 9, Loss: 163.6973\n",
      "Epoch 10, Loss: 153.8190\n",
      "Epoch 11, Loss: 147.8310\n",
      "Epoch 12, Loss: 143.8490\n",
      "Epoch 13, Loss: 141.5399\n",
      "Epoch 14, Loss: 139.8101\n",
      "Epoch 15, Loss: 138.8957\n",
      "Epoch 16, Loss: 138.1704\n",
      "Epoch 17, Loss: 137.7518\n",
      "Epoch 18, Loss: 137.5592\n",
      "Epoch 19, Loss: 137.3433\n",
      "Epoch 20, Loss: 137.3409\n",
      "Epoch 21, Loss: 137.2219\n",
      "Epoch 22, Loss: 137.2628\n",
      "Epoch 23, Loss: 137.2513\n",
      "Epoch 24, Loss: 137.4517\n",
      "Epoch 25, Loss: 137.6578\n",
      "Epoch 26, Loss: 137.6989\n",
      "Epoch 27, Loss: 137.6433\n",
      "Epoch 28, Loss: 137.5943\n",
      "Epoch 29, Loss: 137.8565\n",
      "Epoch 30, Loss: 137.6991\n",
      "Epoch 31, Loss: 137.7848\n",
      "Epoch 32, Loss: 137.8357\n",
      "Epoch 33, Loss: 137.7349\n",
      "Epoch 34, Loss: 137.7529\n",
      "Epoch 35, Loss: 137.7550\n",
      "Epoch 36, Loss: 137.7638\n",
      "Epoch 37, Loss: 137.8042\n",
      "Epoch 38, Loss: 137.6565\n",
      "Epoch 39, Loss: 137.6357\n",
      "Epoch 40, Loss: 137.5778\n",
      "Epoch 41, Loss: 137.6432\n",
      "Epoch 42, Loss: 137.6368\n",
      "Epoch 43, Loss: 137.6878\n",
      "Epoch 44, Loss: 137.7270\n",
      "Epoch 45, Loss: 137.5941\n",
      "Epoch 46, Loss: 137.8404\n",
      "Epoch 47, Loss: 137.8156\n",
      "Epoch 48, Loss: 137.5405\n",
      "Epoch 49, Loss: 137.6796\n",
      "Epoch 50, Loss: 137.7038\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw, neg_rw)  # negative samples are neg_rw\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "656a27b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_index.size(1):  860\n",
      "test_index.size(1):  861\n",
      "model.size(0):  5763\n",
      "tensor([[  60,  334, 3576,  ..., 2152, 2855, 4210],\n",
      "        [2512,  974, 4610,  ...,  532,  680, 5609]])\n",
      "neg_val_edge_index.shape:  torch.Size([2, 860])\n",
      "tensor([[5535, 1363, 4188,  ..., 2220, 4556, 4670],\n",
      "        [4425, 3079, 3996,  ..., 3792, 5148, 3171]])\n",
      "neg_test_edge_index.shape:  torch.Size([2, 860])\n"
     ]
    }
   ],
   "source": [
    "#Generate negative samples for validation set and test set\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "print(\"val_index.size(1): \", val_index.size(1))\n",
    "print(\"test_index.size(1): \", test_index.size(1))\n",
    "print(\"model.size(0): \", model.num_nodes)\n",
    "\n",
    "neg_val_index = negative_sampling(\n",
    "    edge_index=all_pos_edges, \n",
    "    num_nodes=model.num_nodes,\n",
    "    num_neg_samples=val_index.size(1)\n",
    ")\n",
    "\n",
    "neg_test_index = negative_sampling(\n",
    "    edge_index=all_pos_edges,\n",
    "    num_nodes=model.num_nodes,\n",
    "    num_neg_samples=test_index.size(1)\n",
    ")\n",
    "\n",
    "print(neg_val_index)\n",
    "print(\"neg_val_edge_index.shape: \", neg_val_index.shape)\n",
    "print(neg_test_index)\n",
    "print(\"neg_test_edge_index.shape: \", neg_val_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef3d6e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_true_labels.shape:  torch.Size([1720])\n",
      "test_true_labels.shape:  torch.Size([1722])\n",
      "pos_val_pred.shape:  torch.Size([860])\n",
      "neg_val_pred.shape:  torch.Size([860])\n"
     ]
    }
   ],
   "source": [
    "embeddings = model()\n",
    "#gets actual link predictions \n",
    "def predict_links(node_embeddings, edge_index):\n",
    "    src, dst = edge_index\n",
    "    score = (node_embeddings[src] * node_embeddings[dst]).sum(dim=1)  # dot product of two node embeddings\n",
    "    #print(type(score))\n",
    "    #print(\"Score: \", score)\n",
    "    prob = torch.sigmoid(score) #make prob between 0 and 1\n",
    "    threshold = 0.6\n",
    "    pred = (prob > threshold).int()\n",
    "    return pred\n",
    "\n",
    "#gets scores from dot product of two node embeddings\n",
    "def get_scores(node_embeddings, edge_index):\n",
    "    src, dst = edge_index\n",
    "    scores = (node_embeddings[src] * node_embeddings[dst]).sum(dim=1)  # dot product of two node embeddings\n",
    "    return scores\n",
    "\n",
    "\n",
    "#assemble true label tensors\n",
    "val_true_labels = torch.cat([torch.ones(val_index.size(1)), torch.zeros(neg_val_index.size(1))])\n",
    "test_true_labels = torch.cat([torch.ones(test_index.size(1)), torch.zeros(neg_test_index.size(1))])\n",
    "print(\"val_true_labels.shape: \" , val_true_labels.size())\n",
    "print(\"test_true_labels.shape: \", test_true_labels.size())\n",
    "\n",
    "#get 'presence of link' predictions for validation and test sets\n",
    "pos_val_pred = predict_links(embeddings, val_index)\n",
    "neg_val_pred = predict_links(embeddings, neg_val_index)\n",
    "#print(val_true_labels)\n",
    "print(\"pos_val_pred.shape: \", pos_val_pred.shape)\n",
    "print(\"neg_val_pred.shape: \", neg_val_pred.shape)\n",
    "pos_test_pred = predict_links(embeddings, test_index)\n",
    "neg_test_pred = predict_links(embeddings, neg_test_index)\n",
    "\n",
    "#assemble predicted label tensors\n",
    "val_pred_labels = torch.cat([pos_val_pred, neg_val_pred])\n",
    "test_pred_labels = torch.cat([pos_test_pred, neg_test_pred])\n",
    "\n",
    "#get score predictions for validation and test sets\n",
    "pos_val_scores = get_scores(embeddings, val_index)\n",
    "neg_val_scores = get_scores(embeddings, neg_val_index)\n",
    "\n",
    "pos_test_scores = get_scores(embeddings, test_index)\n",
    "neg_test_scores = get_scores(embeddings, neg_test_index)\n",
    "\n",
    "#assemble validation and test score tensors\n",
    "val_scores = torch.cat([pos_val_scores, neg_val_scores])\n",
    "test_scores = torch.cat([pos_test_scores, neg_test_scores])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adaa88b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6970930232558139, Validation Recall: 0.5906976744186047, Validation f1-score: 0.6610279765777488\n",
      "Validation roc auc: 0.6781408869659276, Val Avg Precision: 0.7723695715689489\n",
      "\n",
      "Test Accuracy: 0.6945412311265969, Test Recall: 0.6039488966318235, Test f1-score: 0.6641123882503193\n",
      "Test roc auc: 0.6762778877166571, Test Avg Precision: 0.7699010561281736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, recall_score, f1_score\n",
    "validation_accuracy = accuracy_score(val_true_labels, val_pred_labels)\n",
    "validation_recall = recall_score(val_true_labels, val_pred_labels)\n",
    "validation_f1 = f1_score(val_true_labels, val_pred_labels)\n",
    "print(f\"Validation Accuracy: {validation_accuracy}, Validation Recall: {validation_recall}, Validation f1-score: {validation_f1}\")\n",
    "val_roc_auc = roc_auc_score(val_true_labels.cpu(), val_scores.detach().numpy())\n",
    "val_avg_prec = average_precision_score(val_true_labels.cpu(), val_scores.detach().numpy())\n",
    "print(f\"Validation roc auc: {val_roc_auc}, Val Avg Precision: {val_avg_prec}\")\n",
    "\n",
    "print()\n",
    "\n",
    "test_accuracy = accuracy_score(test_true_labels, test_pred_labels)\n",
    "test_recall = recall_score(test_true_labels, test_pred_labels)\n",
    "test_f1 = f1_score(test_true_labels, test_pred_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy}, Test Recall: {test_recall}, Test f1-score: {test_f1}\")\n",
    "test_roc_auc = roc_auc_score(test_true_labels.cpu(), test_scores.detach().numpy())\n",
    "test_avg_prec = average_precision_score(test_true_labels.cpu(), test_scores.detach().numpy())\n",
    "print(f\"Test roc auc: {test_roc_auc}, Test Avg Precision: {test_avg_prec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376f921",
   "metadata": {},
   "source": [
    "### Method 2: Alternative Approach \n",
    "*Task*: Choose and implement another link prediction method. *Description*: This method should not use embeddings. You can use any approach of your choice. Compare the performance of this method with the embedding-based method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3e48cd",
   "metadata": {},
   "source": [
    "https://networkx.org/documentation/stable/reference/classes/graph.html#networkx.Graph <br>\n",
    "https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_pandas_edgelist.html <br>\n",
    "https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_prediction.jaccard_coefficient.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f664aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracy: 0.8261627906976744, Validation Recall: 0.7116279069767442, Validation f1-score: 0.8036769533814839\n",
      "Validation roc auc: 0.8067212006489994, Val Avg Precision: 0.7102706604614362\n",
      "\n",
      "Test Accuracy: 0.8147502903600464, Test Recall: 0.7015098722415796, Test f1-score: 0.7910936476751801\n",
      "Test roc auc: 0.790084862023334, Test Avg Precision: 0.6830560086884887\n"
     ]
    }
   ],
   "source": [
    "#Non-Embedding Method for link prediction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#print(edge_df.head())\n",
    "G = nx.from_pandas_edgelist(edge_df, source='source', target='target', edge_attr=\"relationship_type\", create_using=nx.Graph())\n",
    "\n",
    "all_val_edges = torch.cat([val_index, neg_val_index], dim=1) \n",
    "all_test_edges = torch.cat([test_index, neg_test_index], dim=1) \n",
    "#print(all_val_edges.shape)\n",
    "#print(all_test_edges.shape)\n",
    "\n",
    "\n",
    "def compute_jaccard(G, edges, threshold):\n",
    "    scores = []\n",
    "    edges = edges.t().tolist()\n",
    "    for u, v in edges:\n",
    "        try:\n",
    "            preds = list(nx.jaccard_coefficient(G, [(u, v)]))\n",
    "            scores.append(preds[0][2])\n",
    "        except nx.NetworkXError:\n",
    "            scores.append(0.0)\n",
    "\n",
    "    pred_labels = []\n",
    "    for score in scores: \n",
    "        if(score>threshold):\n",
    "            pred_labels.append(1)\n",
    "        else:\n",
    "            pred_labels.append(0)\n",
    "    return np.array(scores), np.array(pred_labels)\n",
    "\n",
    "\n",
    "val_scores, val_pred_labels_jaccard = compute_jaccard(G, all_val_edges, 0.001)\n",
    "test_scores, test_pred_labels_jaccard = compute_jaccard(G, all_test_edges, 0.001)\n",
    "\n",
    "val_acc = accuracy_score(val_true_labels, val_pred_labels_jaccard)\n",
    "val_recall = recall_score(val_true_labels, val_pred_labels_jaccard)\n",
    "val_f1 = f1_score(val_true_labels, val_pred_labels_jaccard)\n",
    "print()\n",
    "print(f\"Validation Accuracy: {val_acc}, Validation Recall: {val_recall}, Validation f1-score: {val_f1}\")\n",
    "val_auc = roc_auc_score(val_true_labels, val_scores)\n",
    "val_precision = average_precision_score(val_true_labels, val_scores)\n",
    "print(f\"Validation roc auc: {val_auc}, Val Avg Precision: {val_precision}\")\n",
    "\n",
    "print()\n",
    "\n",
    "test_acc = accuracy_score(test_true_labels, test_pred_labels_jaccard)\n",
    "test_recall = recall_score(test_true_labels, test_pred_labels_jaccard)\n",
    "test_f1 = f1_score(test_true_labels, test_pred_labels_jaccard)\n",
    "print(f\"Test Accuracy: {test_acc}, Test Recall: {test_recall}, Test f1-score: {test_f1}\")\n",
    "test_auc = roc_auc_score(test_true_labels, test_scores)\n",
    "test_precision = average_precision_score(test_true_labels, test_scores)\n",
    "print(f\"Test roc auc: {test_auc}, Test Avg Precision: {test_precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364689d6",
   "metadata": {},
   "source": [
    "## Part 3: Reflection and Analysis\n",
    "*Task*: Compare both methods. *Description*: Write a reflection on the performance of each method. Discuss any challenges and insights gained. Suggest improvements to the dataset or the methods used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c80898",
   "metadata": {},
   "source": [
    "### Intro and Approach\n",
    "<p>The methods I used to predict the presence of links between Dataset and ScienceKeyword nodes in the nasa-gesdisc dataset were the Jaccard coefficient and Node2Vec. I predicted that Node2Vec would outperform the Jaccard coefficient because the Node2Vec method involves a shallow embedding where the model learns detailed embeddings for each node in the dataset. Since the dataset is only 5763 nodes, we are able to use shallow embeddings because we can store all of the embeddings. For the non-embedding method, I picked the Jaccard coefficient because it does better than common neighbors at accounting for the number of total neighbors a node has. I also chose the Jaccard coefficient because I wanted a local measure for link prediction. In contrast with the node embeddings from Node2Vec which are generated through random walks, the Jaccard coefficient only looks at direct neighbors for a node.\n",
    "</p>\n",
    "<p>The Node2Vec method was a more complex approach that involved training a model to optimize for nodes with similar embeddings appearing often on the same random walks. Prior to training, I dropped the properties column included in the nodes.csv file. In future iterations of this project, I would include the properties column within the embeddings for each of the nodes so that performance in link prediction would improve. Additionally, for future improvements to the model, I would treat the graph as a heterogeneous graph since its structure lends well to this design. By treating the graph as homogenous, it simplified the training process and interpretation of results, but performance of the link prediction suffered as a result.  \n",
    "</p>\n",
    "\n",
    "### Performance\n",
    "<p>Surprisingly, the method that used the Jaccard coefficient outperformed the Node2Vec embedding method. I used several metrics from sklearn.metrics to compare the performance of the two approaches. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4167416c",
   "metadata": {},
   "source": [
    "**Node2Vec Embedding Method Performance Metrics**\n",
    "\n",
    "| Validation Set Metrics | Value | \n",
    "| ------ | ------|\n",
    "| Accuracy | 0.70 |\n",
    "| Recall | 0.59 |\n",
    "| F1-Score | 0.66 |\n",
    "| ROC AUC Score | 0.68 |\n",
    "| Average Precision | 0.77 |\n",
    "\n",
    "<br>\n",
    "\n",
    "| Test Set Metrics | Value | \n",
    "| ------ | ------|\n",
    "| Accuracy | 0.69 |\n",
    "| Recall | 0.60 |\n",
    "| F1-Score | 0.66 |\n",
    "| ROC AUC Score | 0.68 |\n",
    "| Average Precision | 0.77 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648aaf31",
   "metadata": {},
   "source": [
    "**Jaccard Coefficient Method Performance Metrics**\n",
    "\n",
    "| Validation Set Metrics | Value | \n",
    "| ------ | ------|\n",
    "| Accuracy | 0.83 |\n",
    "| Recall | 0.71 |\n",
    "| F1-Score | 0.80 |\n",
    "| ROC AUC Score | 0.81 |\n",
    "| Average Precision | 0.71 |\n",
    "\n",
    "<br>\n",
    "\n",
    "| Test Set Metrics | Value | \n",
    "| ------ | ------|\n",
    "| Accuracy | 0.81 |\n",
    "| Recall | 0.70 |\n",
    "| F1-Score | 0.79 |\n",
    "| ROC AUC Score | 0.79 |\n",
    "| Average Precision | 0.68 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e2beb3",
   "metadata": {},
   "source": [
    "<p>I did not expect the accuracy of the Jaccard coefficient method to be better than the Node2Vec random walk embedding method. I think there were two main reasons for the underperformance of the Node2Vec method relative to the Jaccard Coefficient. First, I did not use any node features inherently tied to each of the nodes with the embedding method. By dropping the properties column, the Node2Vec method learned graph structure, but it didn’t learn the semantic differences between the heterogenous nodes and edges. Without utilizing the information included in each of the nodes, the embeddings lacked the semantic understanding to learn when a dataset and science keyword should have been connected.\n",
    "</p>\n",
    "<p>\n",
    "Second, I think this experiment reflects the predictive power of local neighborhood overlap. With the Jaccard coefficient that only takes into account the node degrees and the common neighbors, we are able to achieve relatively high accuracy in predicting the presence of a link between two nodes of different types. I assume that other local neighborhood overlap measures like common neighbors and Adamic-Adar index would perform similarly to this method, but I am curious how a global neighborhood measure like the Katz Index would perform. \n",
    "</p>\n",
    "\n",
    "### Future Optimizations and Dataset Improvements\n",
    "<p>In future link prediction tasks, I would like to try different hyperparameter combinations for the Node2Vec random walks. I did not try different combinations of the p and q parameters, but I hypothesize that by decreasing p and increasing q, I’d be able to bias the random walks to focus more on the local neighborhood for each node. This could result in improved performance similar to the Jaccard Coefficient results. I’d also like to try reducing the walk length parameter (which could help to focus on more local graph structure) and increase the embedding dimension. With bigger embeddings, it is possible we’d see better performance from the embedding method.\n",
    "</p>\n",
    "<p>As previously mentioned, I think my biggest improvement to the modeling approach would be to treat the graph as a heterogeneous graph and to include the properties column in my node embeddings so the model could use this information when predicting the presence of a link between two nodes. With limited link prediction and modeling experience, I did not have time to include these two improvements in my model and chose to use the relatively simple Node2Vec method to generate node embeddings.\n",
    "</p>\n",
    "<p>\n",
    "For the dataset, I think the validation set and test set should have more types of edge relationships that are included in the training set rather than only the Dataset HAS_SCIENCEKEYWORD edge. Additionally, I think there should be more edge types that link to the Publication node type. With more of these relationships, we’d be able to better link authors of publications with potential future datasets that could be of interest to them and other publications in a similar field. Lastly, a quality of life improvement would be to include the presence of negative edges for modeling, but these were easily generated. For a larger graph, this may have been a larger computational barrier, but with less than 6000 nodes, the negative sampling was a quick task.  \n",
    "</p>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
