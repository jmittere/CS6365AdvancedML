{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ad058d",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3922f1",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35076694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57dd73a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'label'], dtype='object')\n",
      "   id    label\n",
      "0   0  Dataset\n",
      "1   1  Dataset\n",
      "2   2  Dataset\n",
      "3   3  Dataset\n",
      "4   4  Dataset\n",
      "\n",
      "label\n",
      "ScienceKeyword    1609\n",
      "Dataset           1300\n",
      "Name: count, dtype: int64\n",
      "\n",
      "relationship_type\n",
      "HAS_SCIENCEKEYWORD    4015\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of training examples:  4015\n",
      "Number of validation examples:  860\n",
      "Number of test examples:  861\n"
     ]
    }
   ],
   "source": [
    "#import nodes and edges\n",
    "node_df = pd.read_csv('data/nodes.csv')\n",
    "edge_df = pd.read_csv('data/train_edges.csv')\n",
    "val_links = pd.read_csv('data/val_links.csv')\n",
    "test_links = pd.read_csv('data/test_links.csv')\n",
    "\n",
    "#print(node_df.head())\n",
    "#print(node_df['label'].unique())\n",
    "#print(edge_df.head())\n",
    "#print(edge_df['relationship_type'].unique())\n",
    "\n",
    "#node_df[\"properties\"] = node_df[\"properties\"].apply(ast.literal_eval)\n",
    "#print(type(node_df['properties'].iloc[0]))\n",
    "\n",
    "#drop properties column because won't be used\n",
    "node_df = node_df.drop('properties', axis=1)\n",
    "#remove quotes and brackets so labels are simpler\n",
    "node_df['label'] = node_df['label'].str.replace(\"['\", \"\")\n",
    "node_df['label'] = node_df['label'].str.replace(\"']\", \"\")\n",
    "print(node_df.columns)\n",
    "print(node_df.head())\n",
    "#Since Validation and Test sets only have Dataset and ScienceKeyword nodes and HAS_SCIENCEKEYWORD relationship_types, filter nodes.csv and train_edges.csv to only these node 'label's and this 'relationship_type'\n",
    "node_df = node_df[(node_df['label'] == 'Dataset') | (node_df['label'] == 'ScienceKeyword')]\n",
    "edge_df = edge_df[edge_df['relationship_type'] == 'HAS_SCIENCEKEYWORD']\n",
    "print()\n",
    "print(node_df['label'].value_counts())\n",
    "\n",
    "print()\n",
    "print(edge_df['relationship_type'].value_counts())\n",
    "\n",
    "print()\n",
    "print(\"Number of training examples: \", len(edge_df))\n",
    "print(\"Number of validation examples: \", len(val_links))\n",
    "print(\"Number of test examples: \", len(test_links))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a7604",
   "metadata": {},
   "source": [
    "**Important: - `val_links.csv`: Contains `HAS_SCIENCEKEYWORD` edges for validation.`test_links.csv`: Contains `HAS_SCIENCEKEYWORD` edges for testing.** <br>\n",
    "So, the validation and test sets are only looking at relationship type Dataset -> ScienceKeyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd02e0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2909, 1], edge_index=[2, 4015])\n"
     ]
    }
   ],
   "source": [
    "# Map node IDs to contiguous indices for PyG\n",
    "node_df['idx'] = range(len(node_df))\n",
    "id_to_idx = dict(zip(node_df['id'], node_df['idx']))\n",
    "\n",
    "ones = torch.ones((len(node_df), 1))  # dummy node features for each node\n",
    "# Map node IDs to indices\n",
    "edge_df['source'] = edge_df['source'].map(id_to_idx)\n",
    "edge_df['target'] = edge_df['target'].map(id_to_idx)\n",
    "\n",
    "used_nodes = pd.unique(edge_df[['source','target']].values.ravel())\n",
    "node_df = node_df[node_df['idx'].isin(used_nodes)].reset_index(drop=True)\n",
    "\n",
    "# Remap node IDs to contiguous indices\n",
    "node_df['idx'] = range(len(node_df))\n",
    "id_to_idx = dict(zip(node_df['id'], node_df['idx']))\n",
    "\n",
    "# Remap edges\n",
    "edge_df['source'] = edge_df['source'].map(id_to_idx)\n",
    "edge_df['target'] = edge_df['target'].map(id_to_idx)\n",
    "\n",
    "\n",
    "val_links['source'] = val_links['source'].map(id_to_idx)\n",
    "val_links['target'] = val_links['target'].map(id_to_idx)\n",
    "\n",
    "test_links['source'] = test_links['source'].map(id_to_idx)\n",
    "test_links['target'] = test_links['target'].map(id_to_idx)\n",
    "\n",
    "\n",
    "# Create edge_index tensor\n",
    "edge_index = torch.tensor(edge_df[['source', 'target']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "data = Data(x=ones, edge_index=edge_index)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e39c0c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nodes:  2909\n",
      "Number of Node features:  1\n",
      "\n",
      "Number of Edges:  4015\n",
      "\n",
      "Has Isolated Nodes:  True\n",
      "Has Self Loops:  False\n"
     ]
    }
   ],
   "source": [
    "#Summary of Dataset Structure and Key Statistics for Part 1\n",
    "print(\"Number of Nodes: \", data.num_nodes)\n",
    "print(\"Number of Node features: \", data.num_node_features)\n",
    "print()\n",
    "print(\"Number of Edges: \", data.num_edges)\n",
    "print()\n",
    "print(\"Has Isolated Nodes: \" , data.has_isolated_nodes())\n",
    "print(\"Has Self Loops: \", data.has_self_loops())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240188c",
   "metadata": {},
   "source": [
    "## Part 2: Link Prediction\n",
    "### Method #1: Embedding-Based Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70bc828",
   "metadata": {},
   "source": [
    "Task: Apply an embedding-based method for link prediction. ○ Description: Train a model that generates node embeddings, then use those embeddings to predict links. Print relevant metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c16c65",
   "metadata": {},
   "source": [
    "\"The primary goal of the NASA Knowledge Graph is to bridge scientific publications with the datasets they reference, facilitating deeper insights and research opportunities within NASA's scientific and data ecosystem. By organizing these interconnections within a graph structure, this dataset enables advanced analyses, such as discovering influential datasets, understanding research trends, and exploring scientific collaborations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b34057",
   "metadata": {},
   "source": [
    "https://pytorch-geometric.readthedocs.io/en/2.6.0/tutorial/shallow_node_embeddings.\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.MetaPath2Vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "721d7820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node2Vec(1225, 128)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import Node2Vec\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Node2Vec(data.edge_index, embedding_dim=128, walk_length=10, context_size=5, walks_per_node=10, num_nodes=edge_index.max().item() + 1).to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "loader = model.loader(batch_size=32, shuffle=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd7fcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos_rw, neg_rw \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m      4\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_rw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_rw\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# negative samples are neg_rw\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\justi\\dev\\.venv\\lib\\site-packages\\torch_geometric\\nn\\models\\node2vec.py:148\u001b[0m, in \u001b[0;36mNode2Vec.loss\u001b[1;34m(self, pos_rw, neg_rw)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Positive loss.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m start, rest \u001b[38;5;241m=\u001b[39m pos_rw[:, \u001b[38;5;241m0\u001b[39m], pos_rw[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m--> 148\u001b[0m h_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(pos_rw\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    149\u001b[0m                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dim)\n\u001b[0;32m    150\u001b[0m h_rest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(rest\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mview(pos_rw\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    151\u001b[0m                                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dim)\n\u001b[0;32m    153\u001b[0m out \u001b[38;5;241m=\u001b[39m (h_start \u001b[38;5;241m*\u001b[39m h_rest)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\justi\\dev\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\justi\\dev\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\justi\\dev\\.venv\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:192\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\justi\\dev\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:2546\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2540\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2541\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2542\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2543\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2544\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2545\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for epoch in range(25):\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw, neg_rw)  # negative samples are neg_rw\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3aec2ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2909\n",
      "1720\n",
      "1722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generate Negative Edges\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "num_nodes = data.num_nodes\n",
    "print(num_nodes)\n",
    "\n",
    "def gen_neg_edges(negative_edges_goal, edge_index, num_nodes):\n",
    "    existing_edges = set([tuple(e) for e in edge_index.t().tolist()])\n",
    "    neg_edges = set()\n",
    "    while len(neg_edges) < negative_edges_goal:\n",
    "        u = np.random.randint(0, num_nodes)\n",
    "        v = np.random.randint(0, num_nodes)\n",
    "        if u == v: \n",
    "            continue  # skip self-loops\n",
    "        if (u,v) in existing_edges or (v,u) in existing_edges:\n",
    "            continue\n",
    "        neg_edges.add((u,v))\n",
    "    return np.array(list(neg_edges))\n",
    "\n",
    "val_neg = gen_neg_edges(len(val_links), data.edge_index, num_nodes)\n",
    "test_neg = gen_neg_edges(len(test_links), data.edge_index, num_nodes)\n",
    "\n",
    "print(val_neg.size)\n",
    "print(test_neg.size)\n",
    "print()\n",
    "# Combine positive and negative edges\n",
    "val_pos = val_links[['source','target']].values\n",
    "val_edges = np.vstack([val_pos, val_neg])\n",
    "val_labels = np.hstack([np.ones(len(val_pos)), np.zeros(len(val_neg))])\n",
    "\n",
    "test_pos = test_links[['source','target']].values\n",
    "test_edges = np.vstack([test_pos, test_neg])\n",
    "test_labels = np.hstack([np.ones(len(test_pos)), np.zeros(len(test_neg))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28d1595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3440\n",
      "3444\n",
      "num_nodes: 2909\n",
      "max edge index: 2872\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2890 is out of bounds for dimension 0 with size 2873",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_nodes:\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_nodes)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax edge index:\u001b[39m\u001b[38;5;124m\"\u001b[39m, edge_index\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m---> 14\u001b[0m val_scores \u001b[38;5;241m=\u001b[39m [edge_score(u, v, embeddings) \u001b[38;5;28;01mfor\u001b[39;00m u,v \u001b[38;5;129;01min\u001b[39;00m val_edges]\n\u001b[0;32m     15\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m [edge_score(u, v, embeddings) \u001b[38;5;28;01mfor\u001b[39;00m u,v \u001b[38;5;129;01min\u001b[39;00m test_edges]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#Evaluate with AUC\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[44], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_nodes:\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_nodes)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax edge index:\u001b[39m\u001b[38;5;124m\"\u001b[39m, edge_index\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m---> 14\u001b[0m val_scores \u001b[38;5;241m=\u001b[39m [\u001b[43medge_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m u,v \u001b[38;5;129;01min\u001b[39;00m val_edges]\n\u001b[0;32m     15\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m [edge_score(u, v, embeddings) \u001b[38;5;28;01mfor\u001b[39;00m u,v \u001b[38;5;129;01min\u001b[39;00m test_edges]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#Evaluate with AUC\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[44], line 6\u001b[0m, in \u001b[0;36medge_score\u001b[1;34m(u, v, emb)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21medge_score\u001b[39m(u, v, emb):\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43memb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m emb[v])\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2890 is out of bounds for dimension 0 with size 2873"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "embeddings = model.embedding.weight.data\n",
    "\n",
    "def edge_score(u, v, emb):\n",
    "    return (emb[u] * emb[v]).sum().item()  # dot product\n",
    "\n",
    "print(val_edges.size)\n",
    "print(test_edges.size)\n",
    "\n",
    "print(\"num_nodes:\", num_nodes)\n",
    "print(\"max edge index:\", edge_index.max().item())\n",
    "\n",
    "val_scores = [edge_score(u, v, embeddings) for u,v in val_edges]\n",
    "test_scores = [edge_score(u, v, embeddings) for u,v in test_edges]\n",
    "\n",
    "#Evaluate with AUC\n",
    "val_auc = roc_auc_score(val_labels, val_scores)\n",
    "test_auc = roc_auc_score(test_labels, test_scores)\n",
    "\n",
    "print(\"Validation AUC:\", val_auc)\n",
    "print(\"Test AUC:\", test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376f921",
   "metadata": {},
   "source": [
    "### Method 2: Alternative Approach \n",
    "Task: Choose and implement another link prediction method. ○ Description: This method should not use embeddings. You can use any approach of your choice. Compare the performance of this method with the embedding-based method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f664aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Embedding Method for link prediction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
